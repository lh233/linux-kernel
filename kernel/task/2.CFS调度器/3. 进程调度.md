\_\_schedule()是调度器的核心函数，其作用是让调度器选择和切换到一个合适进程运行。调度的时机可以分为如下3种。

1.  阻塞操作:互斥量( mutex)、信号量(semaphore)、等待队列（ waitqueue）等。
2.  在中断返回前和系统调用返回用户空间时，去检查TIF_NEED_RESCHED标志位以判断是否需要调度。
3.  将要被唤醒的进程（ Wakeups）不会马上调用schedule()要求被调度，而是会被添加到CFS就绪队列中，并且设置TIF_NEED_RESCHED标志位。那么唤醒进程什么时候被调度呢?这要根据内核是否具有可抢占功能(CONFIG_PREEMPT=y)分两种情况。

如果内核可抢占，则:

-   如果唤醒动作发生在系统调用或者异常处理上下文中，在下一次调用preempt_enable()时会检查是否需要抢占调度;
-   如果唤醒动作发生在硬中断处理上下文中，硬件中断处理返回前夕会检查是否要抢占当前进程。

如果内核不可抢占，则:

-   当前进程调用cond_resched()时会检查是否要调度;
-   主动调度调用schedule();
-   系统调用或者异常处理返回用户空间时;
-   中断处理完成返回用户空间时。

前文提到的硬件中断返回前夕和硬件中断返回用户空间前夕是两个不同的概念。前者是每次硬件中断返回前夕都会检查是否有进程需要被抢占调度，不管中断发生点是在内核空间，还是用户空间;后者是只有中断发生点在用户空间才会检查。

```
static void __sched __schedule(void)
{
	struct task_struct *prev, *next;
	unsigned long *switch_count;
	struct rq *rq;
	int cpu;

	preempt_disable();
	cpu = smp_processor_id();
	rq = cpu_rq(cpu);
	rcu_note_context_switch();
	prev = rq->curr;

	schedule_debug(prev);

	if (sched_feat(HRTICK))
		hrtick_clear(rq);

	/*
	 * Make sure that signal_pending_state()->signal_pending() below
	 * can't be reordered with __set_current_state(TASK_INTERRUPTIBLE)
	 * done by the caller to avoid the race with signal_wake_up().
	 */
	smp_mb__before_spinlock();
	raw_spin_lock_irq(&rq->lock);

	rq->clock_skip_update <<= 1; /* promote REQ to ACT */

	switch_count = &prev->nivcsw;
	if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
		if (unlikely(signal_pending_state(prev->state, prev))) {
			prev->state = TASK_RUNNING;
		} else {
			deactivate_task(rq, prev, DEQUEUE_SLEEP);
			prev->on_rq = 0;

			/*
			 * If a worker went to sleep, notify and ask workqueue
			 * whether it wants to wake up a task to maintain
			 * concurrency.
			 */
			if (prev->flags & PF_WQ_WORKER) {
				struct task_struct *to_wakeup;

				to_wakeup = wq_worker_sleeping(prev, cpu);
				if (to_wakeup)
					try_to_wake_up_local(to_wakeup);
			}
		}
		switch_count = &prev->nvcsw;
	}

	if (task_on_rq_queued(prev))
		update_rq_clock(rq);

	next = pick_next_task(rq, prev);
	clear_tsk_need_resched(prev);
	clear_preempt_need_resched();
	rq->clock_skip_update = 0;

	if (likely(prev != next)) {
		rq->nr_switches++;
		rq->curr = next;
		++*switch_count;

		rq = context_switch(rq, prev, next); /* unlocks the rq */
		cpu = cpu_of(rq);
	} else
		raw_spin_unlock_irq(&rq->lock);

	post_schedule(rq);

	sched_preempt_enable_no_resched();
}
```

\_\_schedule()函数调用pick_next_task()让进程调度器从就绪队列中选择一个最合适的进程next，然后context_switch()切换到next进程运行。

prev指当前进程。Thread_info数据结构中的preempt_count成员用于判断当前进程是否可以被抢占，preempt_count的低8位用于存放抢占引用计数( preemption count)，除此之外，还有一个比特位用于PREEMPT_ACTIVE，它只有在内核抢占调度中会被置位，详见preempt_schedule()函数。

```
[preempt_schedule()->preempt_schedule_common()]
static void __sched notrace preempt_schedule_common(void)
{
	do {
		__preempt_count_add(PREEMPT_ACTIVE);
		__schedule();
		__preempt_count_sub(PREEMPT_ACTIVE);

		/*
		 * Check again in case we missed a preemption opportunity
		 * between schedule and now.
		 */
		barrier();
	} while (need_resched());
}
```

第30行代码中的判断语句基于以下两种情况来考虑。

-   把不处于正在运行状态下的当前进程清除出就绪队列。TASK_RUNNING 的状态值为0，其他状态值都非0。
-   中断返回前夕的抢占调度的情况。

如果当前进程在之前发生过抢占调度preempt_schedule()，那么在preempt_schedule()->schedule()时它不应该被清除出运行队列。为什么这里做这样的判断呢?下面以睡眠等待函数 wait_event()为例，当前进程调用wait_event函数，当条件(condition）不满足时，就会把当前进程加入到睡眠等待队列wq中,然后schedule()调度其他进程直到满足condition。wait_event()函数等价于如下代码片段:

```
#define __wait_event(wq, conditon)	\
do {								\
	DEFINE_WAIT(_wait);				\
	for(;;) {						\
		wait->private = current;	\
		list_add(&_wait->task_list, &wq->task_list);\
		set_current_state(TASK_UNINTERRUPIBLE);		\
		if(condition)								\
			break;									\
		schedule();									\
	}	\
	set_current_state(TASK_RUNNING);				\
	list_del_init(&_wait->task_list);				\
}while(0);
```

这里需要考虑以下两种情况。

-   进程p在 for循环中等待condition条件发生，另外一个进程A设置condition条件来唤醒进程p，假设系统中只触发一次condition条件。第7行代码设置当前进程p的状态为TASK_UNINTERRUPTIBLE 之后发生了一个中断，并且中断处理返回前夕判断当前进程p是可被抢占的。如果当前进程p的thread_info的preempt_count中没有置位PREEMPT ACTIVE,那么根据\_\_schedule()函数中第29～51行代码的判断逻辑，当前进程会被清除出运行队列。如果此后再也没有进程来唤醒进程p,那么进程p再也没有机会被唤醒了。

-   若进程p在添加到唤醒队列之前发生了中断，即在第4行和第5行代码之间发生了中断，中断处理返回前夕进程p被抢占调度。若 preempt_count中没有置位PREEMPT_ACTIVE，那么当前进程会被清除出运行队列，由于还没有添加到唤醒队列中，因此进程p再也回不来了。

下面继续看\_\_schedule()函数第33行代码中的pick_next_task()函数。

```
static inline struct task_struct *
pick_next_task(struct rq *rq, struct task_struct *prev)
{
	const struct sched_class *class = &fair_sched_class;
	struct task_struct *p;

	/*
	 * Optimization: we know that if all tasks are in
	 * the fair class we can call that function directly:
	 */
	if (likely(prev->sched_class == class &&
		   rq->nr_running == rq->cfs.h_nr_running)) {
		p = fair_sched_class.pick_next_task(rq, prev);
		if (unlikely(p == RETRY_TASK))
			goto again;

		/* assumes fair_sched_class->next == idle_sched_class */
		if (unlikely(!p))
			p = idle_sched_class.pick_next_task(rq, prev);

		return p;
	}

again:
	for_each_class(class) {
		p = class->pick_next_task(rq, prev);
		if (p) {
			if (unlikely(p == RETRY_TASK))
				goto again;
			return p;
		}
	}

	BUG(); /* the idle class will always have a runnable task */
}
```

pick_next_task()调用调度类中的 pick_next_task()方法。第11～22行代码中有一个小的优化，如果当前进程prev的调度类是CFS，并且该CPU整个就绪队列rq中的进程数量等于CFS 就绪队列中进程数量，那么说明该CPU就绪队列中只有普通进程没有其他调度类进程;否则需要遍历整个调度类。调度类的优先级为stop_sched_class-> dl_sched_class->rt_sched_class-> fair_sched_class-> idle_sched_class。stop_sched_class类用于关闭CPU，接下来是dl_sched_class和 rt_sched_class类，它们是实时性进程，所以当系统有实时进程时，它们总是优先执行。

```
static struct task_struct *
pick_next_task_fair(struct rq *rq, struct task_struct *prev)
{
	struct cfs_rq *cfs_rq = &rq->cfs;
	struct sched_entity *se;
	struct task_struct *p;
	int new_tasks;
again:
	if (!cfs_rq->nr_running)
		goto idle;
	do {
		se = pick_next_entity(cfs_rq, NULL);
		set_next_entity(cfs_rq, se);
		cfs_rq = group_cfs_rq(se);
	} while (cfs_rq);
	p = task_of(se);
	return p;
}
```

如果CFS 就绪队列上没有进程（ cfs_rq->nr_running = 0)，那么选择idle进程。pick_next_entity()选择CFS就绪队列中的红黑树中最左边进程。

接下来看进程是如何切换的，这部分内容涉及ARM体系结构。

```
[_schedule() ->context_switch()]
static inline struct rq *
context_switch(struct rq *rq, struct task_struct *prev,
	       struct task_struct *next)
{
	struct mm_struct *mm, *oldmm;

	prepare_task_switch(rq, prev, next);

	mm = next->mm;
	oldmm = prev->active_mm;
	/*
	 * For paravirt, this is coupled with an exit in switch_to to
	 * combine the page table reload and the switch backend into
	 * one hypercall.
	 */
	arch_start_context_switch(prev);

	if (!mm) {
		next->active_mm = oldmm;
		atomic_inc(&oldmm->mm_count);
		enter_lazy_tlb(oldmm, next);
	} else
		switch_mm(oldmm, mm, next);

	if (!prev->mm) {
		prev->active_mm = NULL;
		rq->prev_mm = oldmm;
	}
	/*
	 * Since the runqueue lock will be released by the next
	 * task (which is an invalid locking op but in the case
	 * of the scheduler it's an obvious special-case), so we
	 * do an early lockdep release here:
	 */
	spin_release(&rq->lock.dep_map, 1, _THIS_IP_);

	context_tracking_task_switch(prev, next);
	/* Here we just switch the register state and the stack. */
	switch_to(prev, next, prev);
	barrier();

	return finish_task_switch(prev);
}
```

该函数涉及3个参数，其中rq表示进程切换所在的就绪队列，prev指将要被换出的进程，next指将要被换入执行的进程。

第8行代码，prepare_task_switch()->prepare_lock_switch()函数设置next进程的 task_struct结构中的on_cpu成员为1,表示next进程马上进入执行状态。on_cpu成员会在Mutex和读写信号量的自旋等待机制中用到，详见第4章。

第10～12行代码，变量mm指向next进程的地址空间描述符struct mm_struct，变量oldmm指向 prev进程正在使用的地址空间描述符（ prev->active_mm)。对于普通进程来说，task_struct数据结构中的mm成员和active_mm 成员都指向进程的地址空间描述符mm_struct;但是对于内核线程来说是没有进程地址空间的(mm = NULL)，但是因为进程调度的需要，需要借用一个进程的地址空间，因此有了active_mm成员。

第20～23行代码，next进程的mm成员为空，则说明这是一个内核线程，需要借用prev进程的活跃进程地址空间active_mm。为什么这里要借用prev->active_mm而不是prev->mm呢? prev进程也有可能是一个内核线程。第22行代码增加prev->active_mm 的mm_count引用计数，保证“债主”不会释放mm，那什么时候递减引用计数呢﹖详见第26行代码。第23行代码进入 lazy tlb模式，对于ARM处理器来说这是一个空函数。

第24行代码，对于普通进程，需要调用switch_mm()函数来做一些进程地址空间切换的处理，稍后会详细分析。

在 finish_task_switch()函数中会递减第21行增加的 mm_count的引用计数。另外finish_task_switch()->finish_lock_switch()会设置prev进程的 task_struct 数据结构的on_cpu成员为0，表示prev进程已经退出执行状态，相当于由next进程来收拾prev进程的“残局”。

我们再思考另外一个问题，当被调度出去的“prev进程”再次被调度运行时，它有可能在原来的CPU上，也有可能被迁移到其他CPU上运行，总之是在switch_to()函数切换完进程后开始执行的。

总而言之，switch_to()函数是新旧进程的切换点。所有进程在受到调度时的切入点都在switch_to()函数中，即完成next进程堆栈切换后开始执行next进程。next进程一直运行，直到下一次执行switch _to()函数，并且把 next进程的堆栈保存到硬件上下文为止。ARM版本的 switch_to()函数会在后续内容中介绍。特殊情况是新创建的进程，其第一次执行的切入点是在 copy thread()函数中指定的ret_from_fork汇编函数，pc指针指向该汇编函数，因此当switch_to()函数切换到新创建进程时，新进程从ret_from_fork汇编函数开始执行。

switch_mm()和 switch_to()函数都和体系结构密切相关。**switch_mm()函数实质是把新进程的页表基地址设置到页目录表基地址寄存器中**。下面来看基于ARMv7-A架构的处理器switch_mm()函数的实现。

```
[__schedule()->context_switch()->switch_mm()]
static inline void
switch_mm(struct mm_struct *prev, struct mm_struct *next,
	  struct task_struct *tsk)
{
	unsigned int cpu = smp_processor_id();
	if (!cpumask_test_and_set_cpu(cpu, mm_cpumask(next)) || prev != next)
		check_and_switch_context(next, tsk);
	...
}
```

switch_mm()首先把当前CPU设置到下一个进程的 cpumask位图中，然后调用check_and_switch_context()函数来完成ARM体系结构相关的硬件设置，例如 flush TLB

在运行进程时，除了cache会缓存进程的数据外，CPU 内部还有一个叫作TLB(Translation Lookasid Buffer)的硬件单元，它为了加快虚拟地址到物理的转换速度而将部分的页表项内容缓存起来，避免频繁的访问页表。当一个prev进程运行时，CPU内部的TLB和 cache会缓存prev进程的数据。如果进程切换到next进程时没有清空(flush) prev进程的数据，那么因TLB和 cache缓存了prev进程的数据，有可能导致next进程访问的虚拟地址被翻译成prev进程缓存的数据，造成数据不一致且系统不稳定，因此进程切换时需要对TLB进行flush操作(在ARM体系结构中也被称为invalidate操作)。但是这种方法显得很粗鲁，对整个TLB进行flush操作后，next进程面对一个空白的TLB，因此刚开始执行时会出现很严重的TLB miss和 Cache Miss，导致系统性能下降。

如何提高TLB的性能?这是最近几十年来芯片设计和操作系统设计人员共同努力的方向。从Linux内核角度看，地址空间可以划分为内核地址空间和用户空间，对于TLB来说可以分成Gobal和 Process-Specific。

-   Gobal类型的 TLB内核空间是所有进程共享的空间，因此这部分空间的虚拟地址到物理地址的翻译是不会变化的，可以理解为Global的。
-   Process-Specific类型的TLB:用户地址空间是每个进程独立的地址空间。prev进程切换到next进程时，TLB中缓存的prev进程的相关数据对于next进程是无用的，因此可以冲刷掉，这就是所谓的process-specific的 TLB。

为了支持 Process-Specific类型的TLB，ARM体系结构提出了一种硬件解决方案，叫作ASID (Address Space ID)，这样 TLB可以识别哪些TLB entry是属于某个进程的。ASID方案让每个TLB entry包含一个 ASID号，ASID号用于每个进程分配标识进程地址空间，TLB命中查询的标准由原来的虚拟地址判断再加上ASID条件。因此有了ASID硬件机制的支持，进程切换不需要flush TLB，即使next进程访问了相同的虚拟地址，prev进程缓存的TLB enty也不会影响到next进程，因为ASID机制从硬件上保证了prev进程和next进程的TLB不会产生冲突。

对于基于ARMv7-A架构的处理器来说，页表PTE entry中第11个比特位nG为1时，表示该页对应TLB是属于进程的而不是全局(non-global)的，在进行进程切换时，只需要切换属于该进程的TLB，不需要冲刷整个TLB。只有进程用户地址空间才会设置 nG标志位，详见set_pte_at()函数。

```
static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,
			      pte_t *ptep, pte_t pte)
{
	if (pte_valid_user(pte)) {
		if (!pte_special(pte) && pte_exec(pte))
			__sync_icache_dcache(pte, addr);
		if (pte_dirty(pte) && pte_write(pte))
			pte_val(pte) &= ~PTE_RDONLY;
		else
			pte_val(pte) |= PTE_RDONLY;
	}

	set_pte(ptep, pte);
}
```

当使用short-descriptor格式的页表时，硬件 ASID存储在CONTEXTIDR寄存器低8位，也就是说最大支持256个ID。当系统中所有CPU的硬件 ASID加起来超过256时会发生溢出，需要把全部TLB 冲刷掉，然后重新分配硬件 ASID，这个过程还需要软件来协同处理。

硬件 ASID号的分配通过位图来管理，分配时通过asid_map位图变量来记录。另外还有一个全局原子变量 asid_generation,其中 bit[8~31]用于存放软件管理用的软件generation计数。软件generation 从ASID_FIRST_VERSION开始计数，每当硬件ASID号溢出时，软件generation计数要加上ASID_FIRST_VERSION(ASID_FIRST_VERSION,其实是1<<8)。

-   硬件ASID:指存放在CONTEXTIDR寄存器低8位的硬件ASID号。
-   软件ASID:这是ARM Linux软件提出的概念，存放在进程的mm->context.id 中，它包括两个域，低8位是硬件ASID，剩余的比特位是软件generation计数。

```
#define ASID_BITS	8

#define ASID_FIRST_VERSION	(1ULL << ASID_BITS)
#define NUM_USER_ASIDS		ASID_FIRST_VERSION
static atomic64_t asid_generation = ATOMIC64_INIT(ASID_FIRST_VERSION);
static DECLARE_BITMAP(asid_map, NUM_USER_ASIDS)
```

ASID只有8bit，当这些比特位都分配完毕后需要冲刷TLB，同时增加软件 generation计数，然后重新分配 ASID。asid_generation存放在mm->context.id的 bit[8~31]位中，调度该进程时需要判断asid_generation是否有变化,从而判断mm->context.id存放的ASID是否还有效。

下面继续看switch_mm()->check_and_switch_context()函数，来看ARM Linux 如何使用ASID。

```
[_schedule() ->context_switch() ->switch_mm() ->check_and_switch_context()]
void check_and_switch_context(struct mm_struct *mm, struct task_struct *tsk)
{
	unsigned long flags;
	unsigned int cpu = smp_processor_id();
	u64 asid;

	if (unlikely(mm->context.vmalloc_seq != init_mm.context.vmalloc_seq))
		__check_vmalloc_seq(mm);

	/*
	 * We cannot update the pgd and the ASID atomicly with classic
	 * MMU, so switch exclusively to global mappings to avoid
	 * speculative page table walking with the wrong TTBR.
	 */
	cpu_set_reserved_ttbr0();

	asid = atomic64_read(&mm->context.id);
	if (!((asid ^ atomic64_read(&asid_generation)) >> ASID_BITS)
	    && atomic64_xchg(&per_cpu(active_asids, cpu), asid))
		goto switch_mm_fastpath;

	raw_spin_lock_irqsave(&cpu_asid_lock, flags);
	/* Check that our ASID belongs to the current generation. */
	asid = atomic64_read(&mm->context.id);
	if ((asid ^ atomic64_read(&asid_generation)) >> ASID_BITS) {
		asid = new_context(mm, cpu);
		atomic64_set(&mm->context.id, asid);
	}

	if (cpumask_test_and_clear_cpu(cpu, &tlb_flush_pending)) {
		local_flush_bp_all();
		local_flush_tlb_all();
	}

	atomic64_set(&per_cpu(active_asids, cpu), asid);
	cpumask_set_cpu(cpu, mm_cpumask(mm));
	raw_spin_unlock_irqrestore(&cpu_asid_lock, flags);

switch_mm_fastpath:
	cpu_switch_mm(mm->pgd, mm);
}
```

第18行代码，进程的软件 ASID通常存放在mm->context.id变量中，这里通过原子变量的读函数atomic64_read()读取软件ASID。

第19行代码,软件 generation计数相同,说明换入进程的ASID还依然属于同一个批次，也就是说还没有发生ASID硬件溢出，因此切换进程不需要任何的TLB冲刷操作，直接跳转到cpu_switch_mm()函数中进行地址切换。另外还需要通过 atomic64_xchg()原子交换指令来设置ASID 到Per-CPU变量active_asids中。

第25～29行代码，如果软件 generation计数不相同，说明至少发生了一次ASID硬件溢出，需要分配一个新的软件ASID，并且设置到mm->context.id中。稍后会详细介绍new_context()函数。

第31～33行代码，硬件ASID发生溢出需要将本地的 TLB冲刷掉。

```
static u64 new_context(struct mm_struct *mm, unsigned int cpu)
{
	static u32 cur_idx = 1;
	u64 asid = atomic64_read(&mm->context.id);
	u64 generation = atomic64_read(&asid_generation);

	if (asid != 0) {
		/*
		 * If our current ASID was active during a rollover, we
		 * can continue to use it and this was just a false alarm.
		 */
		if (is_reserved_asid(asid))
			return generation | (asid & ~ASID_MASK);

		/*
		 * We had a valid ASID in a previous life, so try to re-use
		 * it if possible.,
		 */
		asid &= ~ASID_MASK;
		if (!__test_and_set_bit(asid, asid_map))
			goto bump_gen;
	}

	/*
	 * Allocate a free ASID. If we can't find one, take a note of the
	 * currently active ASIDs and mark the TLBs as requiring flushes.
	 * We always count from ASID #1, as we reserve ASID #0 to switch
	 * via TTBR0 and to avoid speculative page table walks from hitting
	 * in any partial walk caches, which could be populated from
	 * overlapping level-1 descriptors used to map both the module
	 * area and the userspace stack.
	 */
	asid = find_next_zero_bit(asid_map, NUM_USER_ASIDS, cur_idx);
	if (asid == NUM_USER_ASIDS) {
		generation = atomic64_add_return(ASID_FIRST_VERSION,
						 &asid_generation);
		flush_context(cpu);
		asid = find_next_zero_bit(asid_map, NUM_USER_ASIDS, 1);
	}

	__set_bit(asid, asid_map);
	cur_idx = asid;

bump_gen:
	asid |= generation;
	cpumask_clear(mm_cpumask(mm));
	return asid;
}
```

第7～33行代码，刚创建进程时，mm->context.id值初始化为0,如果这时asid值不为0，说明该进程之前分配过 ASID。如果原来的 ASID还有效，那么只需要再加上新的generation值即可组成一个新的软件ASID

第33行代码，如果之前的硬件 ASID不能使用，那么就从asid_map位图中查找第一个空闲的比特位用在这次的硬件ASID。

第34～38行代码,如果找不到一个空闲的比特位,说明发生了溢出,那么只能提升generation值，并调用flush_context()函数把所有CPU上的TLB都冲刷掉，同时把位图asid_map清0。

最后new_context()函数返回一个新的软件ASID。

下面继续看check_and_switch_context()->cpu_switch_mm()函数。

```
#define cpu_switch_mm(pgd,mm) cpu_do_switch_mm(virt_to_phys(pgd),mm)
#define cpu_do_switch_mm		processor.switch_mm
```

对于基于ARMv7-A架构的处理器来说，最终会调用到cpu_v7_switch_mm()函数中。其中，参数pgd phys 指next进程的页表基地址，tsk 指next进程的struct task_struct 数据结构。

```
[arch/arm/mm/proc-v7-21eve1.S]
ENTRY(cpu_v7_switch_mm)
#ifdef CONFIG_MMU
	mov	r2, #0
	mmid	r1, r1				@ get mm->context.id
	ALT_SMP(orr	r0, r0, #TTB_FLAGS_SMP)
	ALT_UP(orr	r0, r0, #TTB_FLAGS_UP)
#ifdef CONFIG_ARM_ERRATA_430973
	mcr	p15, 0, r2, c7, c5, 6		@ flush BTAC/BTB
#endif
#ifdef CONFIG_PID_IN_CONTEXTIDR
	mrc	p15, 0, r2, c13, c0, 1		@ read current context ID
	lsr	r2, r2, #8			@ extract the PID
	bfi	r1, r2, #8, #24			@ insert into new context ID
#endif
#ifdef CONFIG_ARM_ERRATA_754322
	dsb
#endif
	mcr	p15, 0, r1, c13, c0, 1		@ set context ID
	isb
	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
	isb
#endif
	bx	lr
ENDPROC(cpu_v7_switch_mm)
```

cpu_v7_switch_mm()函数除了会设置页表基地址TTB (Translation Table Base) 寄存器之外，还会设置硬件ASID，即把进程 mm->context.id存储的硬件ASID设置到CONTEXTIDR寄存器的低8位，见第19行代码。

处理完TLB和页表基地址后，还需要进行栈空间的切换，next进程才能开始运行。下面来看context_switch()->switch_to()函数。

```
#define switch_to(prev,next,last)					\
do {									\
	last = __switch_to(prev,task_thread_info(prev), task_thread_info(next));	\
} while (0)
```

switch_to()函数最终调用\_\_switch_to汇编函数。

```
/*
 * Register switch for ARMv3 and ARMv4 processors
 * r0 = previous task_struct, r1 = previous thread_info, r2 = next thread_info
 * previous and next are guaranteed not to be the same.
 */
ENTRY(__switch_to)
 UNWIND(.fnstart	)
 UNWIND(.cantunwind	)
	add	ip, r1, #TI_CPU_SAVE
 ARM(	stmia	ip!, {r4 - sl, fp, sp, lr} )	@ Store most regs on stack
 THUMB(	stmia	ip!, {r4 - sl, fp}	   )	@ Store most regs on stack
 THUMB(	str	sp, [ip], #4		   )
 THUMB(	str	lr, [ip], #4		   )
	ldr	r4, [r2, #TI_TP_VALUE]
	ldr	r5, [r2, #TI_TP_VALUE + 4]
#ifdef CONFIG_CPU_USE_DOMAINS
	ldr	r6, [r2, #TI_CPU_DOMAIN]
#endif
	switch_tls r1, r4, r5, r3, r7
#if defined(CONFIG_CC_STACKPROTECTOR) && !defined(CONFIG_SMP)
	ldr	r7, [r2, #TI_TASK]
	ldr	r8, =__stack_chk_guard
	ldr	r7, [r7, #TSK_STACK_CANARY]
#endif
#ifdef CONFIG_CPU_USE_DOMAINS
	mcr	p15, 0, r6, c3, c0, 0		@ Set domain register
#endif
	mov	r5, r0
	add	r4, r2, #TI_CPU_SAVE
	ldr	r0, =thread_notify_head
	mov	r1, #THREAD_NOTIFY_SWITCH
	bl	atomic_notifier_call_chain
#if defined(CONFIG_CC_STACKPROTECTOR) && !defined(CONFIG_SMP)
	str	r7, [r8]
#endif
 THUMB(	mov	ip, r4			   )
	mov	r0, r5
 ARM(	ldmia	r4, {r4 - sl, fp, sp, pc}  )	@ Load all regs saved previously
 THUMB(	ldmia	ip!, {r4 - sl, fp}	   )	@ Load all regs saved previously
 THUMB(	ldr	sp, [ip], #4		   )
 THUMB(	ldr	pc, [ip]		   )
 UNWIND(.fnend		)
ENDPROC(__switch_to)
```

\_\_switch_to()函数带有3个参数，r0是移出进程(prev进程）的 task_struct结构，r1是移出进程（prev进程）的thread_info结构，r2是移入进程(next进程）的thread_info结构。这里把 prev进程的相关寄存器上下文保存到该进程的thread_info->cpu_context结构体中，然后再把next进程的thread_info->cpu_context结构体中的值设置到物理CPU的寄存器中，从而实现进程的堆栈切换。


