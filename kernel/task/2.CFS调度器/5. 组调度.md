前文所提到的CFS调度器的调度粒度是进程，但是在某些应用场景中，用户希望调度的粒度是用户组，例如在一台服务器中有N个用户登录，希望这N个用户都可以平均分配到CPU时间。这在调度粒度为进程的CFS调度器里是很难做到的，拥有进程数量多的登录用户将会被分配到比较多的CPU资源，组调度可以解决这方面的应用需求。

CFS调度器定义一个数据结构来抽象组调度struct task_group。

```
      [kernelschedsched.h]

       task group related information 
      struct task_group {
          struct cgroup_subsys_state css;

      #ifdef CONFIG_FAIR_GROUP_SCHED
           schedulable entities of this group on each cpu 
          struct sched_entity se;
           runqueue owned by this group on each cpu 
          struct cfs_rq cfs_rq;
          unsigned long shares;

      #ifdef     CONFIG_SMP
          atomic_long_t load_avg;
          atomic_t runnable_avg;
      #endif
      #endif

      #ifdef CONFIG_RT_GROUP_SCHED
          ...
      #endif
          struct rcu_head rcu;
          struct list_head list;

          struct task_group parent;
          struct list_head siblings;
          struct list_head children;
      };
```

组调度属于cgroup架构中的cpu子系统，在系统配置时需要打开CONFIG_CGROUP_SCHED和CONFIG_FAIR_GROUP_SCHED。我们直接从sched_create_group()函数来看如何创建和组织一个组调度。

```
      [cpu_cgroup_css_alloc()-sched_create_group()]

      0 struct task_group sched_create_group(struct task_group parent)
      1 {
      2    struct task_group tg;
      3
      4    tg = kzalloc(sizeof(tg), GFP_KERNEL);
      5     if (! alloc_fair_sched_group(tg, parent))
      6            goto err;
      7
      8     if (! alloc_rt_sched_group(tg, parent))
      9            goto err;
      10    return tg;
      11}
```

参数parent指上一级的组调度节点，系统中有一个组调度的根，命名为root_task_group。首先分配一个struct task_group数据结构实例tg，然后调用alloc_fair_sched_group()函数创建CFS调度器需要的组调度数据结构，alloc_rt_sched_group()函数创建RT调度器需要的组调度数据结构。这里我们只看CFS里的组调度。

```
      [sched_create_group()-alloc_fair_sched_group()]

      0 int alloc_fair_sched_group(struct task_group tg, struct task_group parent)
      1 {
      2    struct cfs_rq cfs_rq;
      3    struct sched_entity se;
      4     int i;
      5
      6    tg-cfs_rq = kzalloc(sizeof(cfs_rq)  nr_cpu_ids, GFP_KERNEL);
      7    tg-se = kzalloc(sizeof(se)  nr_cpu_ids, GFP_KERNEL);
      8
      9     tg-shares = NICE_0_LOAD;
      10
      11    init_cfs_bandwidth(tg_cfs_bandwidth(tg));
      12
      13    for_each_possible_cpu(i) {
      14        cfs_rq = kzalloc_node(sizeof(struct cfs_rq),
      15                          GFP_KERNEL, cpu_to_node(i));
      16
      17        se = kzalloc_node(sizeof(struct sched_entity),
      18                     GFP_KERNEL, cpu_to_node(i));
      19        init_cfs_rq(cfs_rq);
      20        init_tg_cfs_entry(tg, cfs_rq, se, i, parent-se[i]);
      21    }
      22
      23    return 1;
      24}
```

第6行代码，cfs_rq其实是一个指针数组，分配nr_cpu_ids个struct cfs数据结构并存放到该指针数组中，第7行代码亦是如此。struct task_group数据结构中share成员通常用于表示该组的权重，这里暂时初始化为NICE值为0进程的权重。init_cfs_bandwidth()函数初始化CFS带宽控制相关信息。第13～21行代码，for循环遍历系统中所有的CPU，为每个CPU分配一个struct cfs_rq调度队列和struct sched_entity调度实体。init_cfs_rq()初始化cfs_rq调度队列中的tasks_timeline和min_vruntime等信息。init_tg_cfs_entry()函数用于构建组调度结构的关键函数。

```
      [sched_create_group()-alloc_fair_sched_group()-init_tg_cfs_entry()]

      0 void init_tg_cfs_entry(struct task_group tg, struct cfs_rq cfs_rq,
      1              struct sched_entity se, int cpu,
      2              struct sched_entity parent)
      3 {
      4    struct rq rq = cpu_rq(cpu);
      5
      6     cfs_rq-tg = tg;
      7     cfs_rq-rq = rq;
      8     init_cfs_rq_runtime(cfs_rq);
      9
      10    tg-cfs_rq[cpu] = cfs_rq;
      11    tg-se[cpu] = se;
      12
      13    se could be NULL for root_task_group 
      14    if (! se)
      15           return;
      16
      17    if (! parent) {
      18         se-cfs_rq = &rq-cfs;
      19           se-depth = 0;
      20    } else {
      21           se-cfs_rq = parent-my_q;
      22           se-depth = parent-depth + 1;
      23    }
      24
      25    se-my_q = cfs_rq;
      26    guarantee group entities always have weight 
      27   update_load_set(&se-load, NICE_0_LOAD);
      28    se-parent = parent;
      29}
```

init_tg_cfs_entry()函数对组调度的相关数据结构进行初始化，如图3.7所示是在一个双核处理器系统中的组调度的数据结构关系图。组调度里初始化了2个CFS调度队列，2个调度实体，其中调度实体se的cfs_rq成员指向系统中的CFS调度队列，my_q成员指向组调度里自身的CFS调度队列。

![image](httpsimg2024.cnblogs.comblog811006202505811006-20250512111852556-845781443.png)

图3.7 CFS调度器组调度数据结构关系图下面来看进程加入到组调度的情况，调用cgroup里的接口函数cpu_cgroup_attach()。

```
      static void cpu_cgroup_attach(struct cgroup_subsys_state css,
                          struct cgroup_taskset tset)
      {
            struct task_struct task;

            cgroup_taskset_for_each(task, tset)
                sched_move_task(task);
      }
```

cgroup_taskset_for_each()函数遍历tset包含的进程链表，调用sched_move_task()函数将迁移进程到组调度中。

```
      [cpu_cgroup_attach()-sched_move_task()]

      0 void sched_move_task(struct task_struct tsk)
      1 {
      2    struct task_group tg;
      3     int queued, running;
      4     unsigned long flags;
      5    struct rq rq;
      6
      7    rq = task_rq_lock(tsk, &flags);
      8     running = task_current(rq, tsk);
      9     queued = task_on_rq_queued(tsk);
      10
      11    if (queued)
      12           dequeue_task(rq, tsk, 0);
      13    if (unlikely(running))
      14           put_prev_task(rq, tsk);
      15
      16    tg = container_of(task_css_check(tsk, cpu_cgrp_id, true),
      17                 struct task_group, css);
      18    tsk-sched_task_group = tg;
      19
      20    if (tsk-sched_class-task_move_group)
      21           tsk-sched_class-task_move_group(tsk, queued);
      22
      23    if (unlikely(running))
      24          tsk-sched_class-set_curr_task(rq);
      25    if (queued)
      26          enqueue_task(rq, tsk, 0);
      27   task_rq_unlock(rq, tsk, &flags);
      28}
```

首先task_current()函数判断该进程是否正在运行，task_on_rq_queued()函数判断该进程是否在就绪队列里。进程PCB数据结构task_struct中on_rq成员表示该进程的状态， TASK_ON_RQ_QUEUED表示该进程在就绪队列中，TASK_ON_RQ_MIGRATING表示该进程正在迁移过程中。如果该进程在就绪队列中，那么要让该进程暂时先退出就绪队列。如果该进程正在运行中，刚才已经调用dequeue_task()函数把进程退出就绪队列，现在只能继续添加回到就绪队列中。第21行代码，调用CFS调度类中的操作方法集中的task_move_group方法，该方法主要调用set_task_rq()函数设置进程调度实体中cfs_rq成员和parent成员，cfs_rq成员指向组调度中自身的CFS就绪队列，parent成员指向组调度中se调度实体

```
      static inline void set_task_rq(struct task_struct p, unsigned int cpu)
      {
            struct task_group tg = task_group(p);
            p-se.cfs_rq = tg-cfs_rq[cpu];
            p-se.parent = tg-se[cpu];
      }
```

for_each_sched_entity()宏在使能了CONFIG_FAIR_GROUP_SCHED功能后，变得与之前不一样了，现在需要遍历进程调度实体和它的上一级的调度实体，例如组调度。

```
      #ifdef CONFIG_FAIR_GROUP_SCHED
       Walk up scheduling entities hierarchy 
      #define for_each_sched_entity(se) 
              for (; se; se = se-parent)
      #else
      #define for_each_sched_entity(se) 
                for (; se; se = NULL)
      #endif
```

第一次遍历是进程本身的调度实体p-se，它对应的cfs_rq是组调度中的就绪队列，因此进程加入了组调度中的就绪队列中。第二次遍历是组调度自身的调度实体tg-se[]，它对应的cfs_rq是系统本身的CFS就绪队列。注意CFS的组调度机制可以支持N多级，这里只以简单的2级为例。因此可以看到组调度的基本策略如下。

❑ 在创建组调度tg时，tg为每个CPU同时创建组调度内部使用的cfs_rq就绪队列。

❑ 组调度作为一个调度实体加入到系统的CFS就绪队列rq-cfs_rq中。

❑ 进程加入到一个组中后，进程就脱离了系统的CFS就绪队列，并且加入到组调度里的CFS就绪队列tg-cfs_rq[]中。

❑ 在选择下一个进程时，从系统的CFS就绪队列开始，如果选中的调度实体是组调度tg，那么还需要继续遍历tg中的就绪队列，从中选择一个进程来运行。