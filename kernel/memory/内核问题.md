## 处理器体系结构

### 请简述精简指令集RISC和复杂指令集CISC的区别。

20 世纪70年代，IBM 的John Cocke研究发现，处理器提供的大量指令集和复杂寻址方式并不会被编译器生成的代码用到:20%的简单指令经常被用到，占程序总指令数的80%，而指令集里其余80%的复杂指令很少被用到，只占程序总指令数的20%。基于这种思想，将指令集和处理器进行重新设计，在新的设计中只保留了常用的简单指令，这样处理器不需要浪费太多的晶体管去做那些很复杂又很少使用的复杂指令。通常，简单指令大部分时间都能在一个cycle内完成，基于这种思想的指令集叫作RISC (Reduced Instruction Set Computer）指令集，以前的指令集叫作CISC (Complex Instruction Set Computer）指令集。

IBM 和加州大学伯克利分校的 David Patterson以及斯坦福大学的John Hennessy是RISC研究的先驱。Power处理器来自IBM，ARM/SPARC处理器受到伯克利RISC的影响，MIPS来自斯坦福。当下还在使用的最出名的CISC指令集是Intel/AMD 的x86指令集。

RISC 处理器通过更合理的微架构在性能上超越了当时传统的 CISC 处理器，在最初的较量中，Intel 处理器败下阵来，服务器市场的处理器大部分被 RISC阵营占据。Intel的 DavidPapworth和他的同事一起设计了Pentium Pro处理器, x86指令集被解码成类似RISC指令的微操作指令(micro-operations，简称uops)，以后执行的过程采用RISC内核的方式。CISC这 个古老的架构通过巧妙的设计,又一次焕发生机, Intel的x86处理器的性能逐渐超过同期的RISC处理器，抢占了服务器市场，导致其他的处理器厂商只能向低功耗或者嵌入式方向发展。

RISC和 CISC都是时代的产物，RISC在很多思想上更为先进。Intel 的 CSIC指令集也凭借向前兼容这一利器，打败所有的RISC厂商，包括DEC、SUN、Motorola和 IBM，一统PC和服务器领域。不过最近在手机移动业务方面，以ARM为首的厂商占得先机。

### 请简述数值0x12345678在大小端字节序处理器的存储器中的存储方式。

在计算机系统中是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8个比特位。但在32位处理器中，C语言中除了8比特的char类型之外，还有16比特的short型，32bit的int型。另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着如何安排多个字节的问题，因此导致了大端存储模式（Big-endian)和小端存储模式(Little-endian)。例如一个16比特的short型变量X，在内存中的地址为0x0010，X的值为0x1122，那么0x11为高字节，0x22为低字节。对于大端模式，就将0x11放在低地址中;0x22放在高地址中。小端模式则刚好相反。很多的ARM处理器默认使用小端模式，有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。Cortex-A系列的处理器可以通过软件来配置大小端模式。大小端模式是在处理器Load/Store 访问内存时用于描述寄存器的字节顺序和内存中的字节顺序之间的关系。

大端模式:指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中。例如:

![image](https://img2023.cnblogs.com/blog/811006/202309/811006-20230929190307608-761291052.png)

在大端模式下，前32位应该这样读: 12 34 56 78。

因此，大端模式下地址的增长顺序与值的增长顺序相同。

小端模式:指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中。例如:

![image](https://img2023.cnblogs.com/blog/811006/202309/811006-20230929213204705-988771248.png)
![image](https://img2023.cnblogs.com/blog/811006/202309/811006-20230929213231539-1003252140.png)

在小端模式下，前32位应该这样读:12 34 56 78。

因此，小端模式下地址的增长顺序与值的增长顺序相反。

如何检查处理器是大端模式还是小端模式?联合体Union的存放顺序是所有成员都从低地址开始存放的，利用该特性可以轻松获取CPU对内存采用大端模式还是小端

模式读写。

```
int checkCPU(void){
    union w{
        int a;char b;} c ;
        c.a=1;
        return (c.b == 1);
    }
}
```

如果输出结果是true，则是小端模式，否则是大端模式。

### 请简述在你所熟悉的处理器（比如双核Cortex-A9）中一条存储读写指令的执行全过程

经典处理器架构的流水线是五级流水线:取指、译码、发射、执行和写回。

现代处理器在设计上都采用了超标量体系结构(Superscalar Architecture）和乱序执行( out-of-order)技术，极大地提高了处理器计算能力。超标量技术能够在一个时钟周期内执行多个指令，实现指令级的并行，有效提高了ILP (Instruction Level Parallelism）指令级的并行效率，同时也增加了整个cache和 memory层次结构的实现难度。

一条存储读写指令的执行全过程很难用一句话来回答。在一个支持超标量和乱序执行技术的处理器当中，一条存储读写指令的执行过程被分解为若干步骤。指令首先进入流水线(pipeline)的前端(Front-End)，包括预取(fetch)和译码(decode)，经过分发(dispatch)和调度( scheduler）后进入执行单元，最后提交执行结果。所有的指令采用顺序方式(In-Order)通过前端，并采用乱序的方式(Out-of-Order，OOO)进行发射，然后乱序执行，最后用顺序方式提交结果，并将最终结果更新到LSQ (Load-Store Queue）部件。LSQ部件是指令流水线的一个执行部件，可以理解为存储子系统的最高层，其上接收来自CPU的存储器指令，其下连接着存储器子系统。其主要功能是将来自CPU的存储器请求发送到存储器子系统，并处理其下存储器子系统的应答数据和消息。

很多程序员对乱序执行的理解有误差。对于一串给定的指令序列，为了提高效率，处理器会找出非真正数据依赖和地址依赖的指令，让它们并行执行。但是在提交执行结果时，是按照指令次序的。总的来说，顺序提交指令，乱序执行，最后顺序提交结果。例如有两条没有数据依赖的数据指令，后面那条指令的读数据先被返回，它的结果也不能先写回到最终寄存器，而是必须等到前一条指令完成之后才可以。

对于读指令，当处理器在等待数据从缓存或者内存返回时，它处于什么状态呢?是等在那不动，还是继续执行别的指令?对于乱序执行的处理器，可以执行后面的指令;对于顺序执行的处理器，会使流水线停顿，直到读取的数据返回。

如图1.1所示，在x86微处理器经典架构中，存储指令从Ll指令cache 中读取指令，Ll指令cache会做指令加载、指令预取、指令预解码，以及分支预测。然后进入 Fetch &Decode单元，会把指令解码成macro-ops微操作指令，然后由 Dispatch部件分发到 IntegerUnit或者FloatPoint Unit。Integer Unit 由Integer Scheduler和 Execution Unit组成，ExecutionUnit包含算术逻辑单元(arithmetic-logic unit,ALU)和地址生成单元(address generation unit,AGU)，在ALU计算完成之后进入AGU，计算有效地址完毕后，将结果发送到LSQ部件。LSQ部件首先根据处理器系统要求的内存一致性( memory consistency)模型确定访问时序，另外LSQ还需要处理存储器指令间的依赖关系，最后LSQ需要准备L1 cache使用的地址，包括有效地址的计算和虚实地址转换，将地址发送到L1 Data Cache 中。

![image](https://img2023.cnblogs.com/blog/811006/202309/811006-20230929215311618-1363245121.png)

如图1.2所示,在ARM Cortex-A9处理器中,存储指令首先通过主存储器或者L2 cache加载到L1指令cache中。在指令预取阶段(instruction prefetch stage)，主要是做指令预取和分支预测，然后指令通过Instruction Queue队列被送到解码器进行指令的解码工作。解码器(decode)支持两路解码，可以同时解码两条指令。在寄存器重名阶段(Register renamestage）会做寄存器重命名，避免机器指令不必要的顺序化操作，提高处理器的指令级并行能力。在指令分发阶段(Dispatch stage)，这里支持4路猜测发射和乱序执行（Out-of-OrderMulti-Issue with Speculation)，然后在执行单元（ALU/MULFPU/NEON）中乱序执行。存储指令会计算有效地址并发射到内存系统中的LSU部件（Load Store Unit)，最终LSU部件会去访问Ll数据cache。在ARM 中，只有cacheable的内存地址才需要访问cache。

![image](https://img2023.cnblogs.com/blog/811006/202309/811006-20230930112108888-675463730.png)

在多处理器环境下，还需要考虑Cache的一致性问题。L1和L2 Cache控制器需要保证cache 的一致性，在 Cortex-A9中 cache 的一致性是由MESI 协议来实现的。Cortex-A9处理器内置了Ll Cache模块，由SCU(Snoop Control Unit）单元来实现Cache的一致性管理。L2 Cache需要外接芯片（例如PL310)。在最糟糕情况下需要访问主存储器，并将数据重新传递给LSQ，完成一次存储器读写的全过程。

### 超标量体系结构

超标量体系结构（Superscalar Architecture):早期的单发射结构微处理器的流水线设计目标是做到每个周期能平均执行一条指令，但这一目标不能满足处理器性能增长的要求，为了提高处理器的性能，要求处理器具有每个周期能发射执行多条指令的能力。因此超标量体系结构是描述一种微处理器设计理念，它能够在一个时钟周期执行多个指令。

### 乱序执行

乱序执行（Out-of-order Execution):指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理的技术，避免处理器在计算对象不可获取时的等待，从而导致流水线停顿。

### 为什么CPU 乱序执行，变量不会经常异常

CPU乱序执行是一种优化技术，它可以提高CPU的执行效率。在乱序执行的情况下，CPU不会按照源代码的顺序执行指令，而是根据指令之间的依赖关系和其他因素来进行调度和执行。

尽管CPU乱序执行可能会导致某些指令的顺序被打乱，但现代的CPU有很多机制来确保程序的正确执行，这些机制可以保证变量的一致性和正确性。具体来说，CPU乱序执行的机制包括：

1. 指令重排序：CPU可以根据指令之间的依赖关系和其他因素来优化指令的执行顺序。在重排序的过程中，CPU会确保对变量的修改在之后的读取之前完成，以确保一致性。
2. 内存屏障：CPU提供了内存屏障指令，可以在适当的位置插入屏障来确保内存的读写顺序。通过使用内存屏障，CPU可以限制指令重排的范围，确保指令的顺序性，从而保证变量的正确性。
3. 缓存一致性机制：现代的CPU都具有缓存一致性机制，它可以确保不同CPU之间共享的变量值是一致的。当一个CPU修改了某个变量的值，它会将修改后的值写入内存并通知其他CPU失效相应的缓存行，从而保证其他CPU获取到的是最新的值。
4. 原子操作：CPU提供了原子操作指令，可以保证某个操作是不可中断的，从而避免了并发访问共享变量时可能产生的竞态条件和不一致性问题。

综合以上机制，尽管CPU乱序执行可能会导致指令的顺序被打乱，但可以保证程序的正确执行。因此，变量在CPU乱序执行的情况下不会经常出现异常。然而，对于特定的多线程场景，仍然需要开发者进行合理的并发控制和同步操作，以确保变量的一致性和正确性。

### CPU名词

#### 寄存器重命名

寄存器重命名（Register Rename):现代处理器的一种技术，用来避免机器指令或者微操作的不必要的顺序化执行，从而提高处理器的指令级并行的能力。它在乱序执行的流水线中有两个作用，一是消除指令之间的寄存器读后写相关(Write-after-Read，WAR）和写后写相关（Write-after-Write，WAW);二是当指令执行发生例外或者转移指令猜测错误而取消后面的指令时，可用来保证现场的精确。其思路为当一条指令写一个结果寄存器时不直接写到这个结果寄存器，而是先写到一个中间寄存器过渡，当这条指令提交时再写到结果寄存器中。

#### 分支预测

寄存器重命名（Register Rename):现代处理器的一种技术，用来避免机器指令或者微操作的不必要的顺序化执行，从而提高处理器的指令级并行的能力。它在乱序执行的流水线中有两个作用，一是消除指令之间的寄存器读后写相关(Write-after-Read，WAR）和写后写相关（Write-after-Write，WAW);二是当指令执行发生例外或者转移指令猜测错误而取消后面的指令时，可用来保证现场的精确。其思路为当一条指令写一个结果寄存器时不直接写到这个结果寄存器，而是先写到一个中间寄存器过渡，当这条指令提交时再写到结果寄存器中。

#### 指令译码器

指令译码器(Instruction Decode):指令由操作码和地址码组成。操作码表示要执行的操作性质，即执行什么操作;地址码是操作码执行时的操作对象的地址。计算机执行一条指定的指令时，必须首先分析这条指令的操作码是什么，以决定操作的性质和方法，然后才能控制计算机其他各部件协同完成指令表达的功能，这个分析工作由译码器来完成。例如，Cortex-A57可以支持3路译码器，即同时执行3条指令译码，而 Cortex-A9处理器只能同时译码2条指令。

#### 调度单元

调度单元(Dispatch):调度器负责把指令或微操作指令派发到相应的执行单元去执行，例如，Cortex-A9处理器的调度器单元有4个接口和执行单元连接，因此每个周期可以同时派发4条指令。

#### ALU 算术逻辑单元

ALU算术逻辑单元:ALU是处理器的执行单元，主要是进行算术运算，逻辑运算和关系运算的部件。

#### LSQ/LSU部件（Load Store Queue/Unit）

LSQ部件是指令流水线的一个执行部件,其主要功能是将来自CPU的存储器请求发送到存储器子系统，并处理其下存储器子系统的应答数据和消息。

### 请简述内存屏障的产生的原因

程序在运行时的实际内存访问顺序和程序代码编写的访问顺序不一致，会导致内存乱序访问。内存乱序访问的出现是为了提高程序运行时的性能。内存乱序访问主要发生在如下两个阶段。

（1）编译时，编译器优化导致内存乱序访问。

（2）运行时，多 CPU间交互引起的内存乱序访问。

编译器会把符合人类思考的逻辑代码(例如C语言)翻译成CPU运算规则的汇编指令，编译器了解底层CPU的思维逻辑，因此它会在翻译成汇编时进行优化。例如内存访问指令的重新排序，提高指令级并行效率。然而，这些优化可能会违背程序员原始的代码逻辑，导致发生一些错误。编译时的乱序访问可以通过volatile关键字来规避。

```
#define barrier() __asm__  __volatile__( ".":: : "memory")
```

barrier()函数告诉编译器，不要为了性能优化而将这些代码重排。

由于现代处理器普遍采用超标量技术、乱序发射以及乱序执行等技术来提高指令级并行的效率，因此指令的执行序列在处理器的流水线中有可能被打乱，与程序代码编写时序列的不一致。另外现代处理器采用多级存储结构，如何保证处理器对存储子系统访问的正确性也是一大挑战。

例如，在一个系统中含有n个处理器P,～P，假设每个处理器包含S;个存储器操作，那么从全局来看可能的存储器访问序列有多种组合。为了保证内存访问的一致性，需要按照某种规则来选出合适的组合，这个规则叫做内存一致性模型（Memory Consistency Model)。这个规则需要保证正确性的前提，同时也要保证多处理器访问较高的并行度。

在一个单核处理器系统中，访问内存的正确性比较简单。每次存储器读操作所获得的结果是最近写入的结果，但是在多处理器并发访问存储器的情况下就很难保证其正确性了。我们很容易想到使用一个全局时间比例部件(Global Time Scale）来决定存储器访问时序，从而判断最近访问的数据。这种内存一致性访问模型是严格一致性（Strict Consistency）内存模型，也称为Atomic Consistency。全局时间比例方法实现的代价比较大，那么退而求其次，采用每一个处理器的本地时间比例部件（Local Time Scale)的方法来确定最新数据的方法被称为顺序一致性内存模型(Sequential Consistency)。处理器一致性内存模型（Processor Consistency）是进一步弱化，仅要求来自同一个处理器的写操作具有一致性的访问即可。

以上这些内存一致性模型是针对存储器读写指令展开的，还有一类目前广泛使用的模型，这些模型使用内存同步指令，也称为内存屏障指令。在这种模型下，存储器访问指令被分成数据指令和同步指令两大类，弱一致性内存模型(weak consistency）就是基于这种思想的。

1986年，Dubois 等发表的论文描述了弱一致性内存模型的定义。

- 对同步变量的访问是顺序一致的。
- 在所有之前的写操作完成之前,不能访问同步变量。
- 在所有之前同步变量的访问完成之前，不能访问（读或者写）数据。

弱一致性内存模型要求同步访问是顺序一致的，在一个同步访问可以被执行之前，所有之前的数据访问必须完成。在一个正常的数据访问可以被执行之前，所有之前的同步访问必须完成。这实质上把一致性问题留给了程序员来决定。

ARM的Cortex-A系列处理器实现弱一致性内存模型，同时也提供了3条内存屏障指令。

### ARM有几条memory barrier的指令?分别有什么区别？

从ARMv7指令集开始，ARM提供3条内存屏障指令。

(1）数据存储屏障（Data Memory Barrier，DMB)

数据存储器隔离。DMB指令保证:仅当所有在它前面的存储器访问操作都执行完毕后，才提交(commit）在它后面的存取访问操作指令。当位于此指令前的所有内存访问均完成时，DMB指令才会完成。

(2）数据同步屏障(Data synchronization Barrier，DSB)

数据同步隔离。比 DMB要严格一些，仅当所有在它前面的存储访问操作指令都执行完毕后，才会执行在它后面的指令，即任何指令都要等待 DSB前面的存储访问完成。位于此指令前的所有缓存，如分支预测和TLB (Translation Look-aside Buffer）维护操作全部完成。

(3）指令同步屏障（Instruction synchronization Barrier，ISB)

指令同步隔离。它最严格，冲洗流水线(Flush Pipeline）和预取 buffers ( pretcLbuffers)后，才会从cache或者内存中预取ISB指令之后的指令。ISB通常用来保证上下文切换的效果，例如更改ASID (Address Space Identifier)、TLB维护操作和C15寄存器的修改等。

内存屏障指令的使用例子如下。

例1:假设有两个CPU核A和B，同时访问Addr1和Addr2地址。

```
Core A:
STR R0,[Addr1]
LDR R1,[Addr2]
Core B:
STR R2，[Addr2]
LDR R3,[Addr1]
```

对于上面代码片段，没有任何的同步措施。对于Core A、寄存器R1、CoreB和寄存器R3，可能得到如下4种不同的结果。

- A得到旧的值,B也得到旧的值。
- A得到旧的值,B得到新的值。
- A得到新的值,B得到旧的值。
- A得到新的值,B得到新的值。

例2:假设CoreA写入新数据到Msg地址，CoreB需要判断flag标志后才读入新数据。

```
Core A:
STR RO,[Msg] @写新数据到Msg地址
STR R1,[Flag] @Flag标志新数据可以读
Core B:
Po1l_loop:
LDR R1，[Flag]
CMP R1，#0 @判断flag有没有置位
BEQ Poll_loop
LDR R0，[Msg] @读取新数据
```

在上面的代码片段中，Core B可能读不到最新的数据，因为Core B可能因为乱序执行的原因先读入Msg，然后读取Flag。在弱一致性内存模型中，处理器不知道Msg 和Flag存在数据依赖性，所以程序员必须使用内存屏障指令来显式地告诉处理器这两个变量有数据依赖关系。Core A需要在两个存储指令之间插入DMB指令来保证两个store存储指令的执行顺序。Core B需要在“LDR R0,[Msg]”之前插入 DMB指令来保证直到Flag置位才读入Msg.

例3:在一个设备驱动中，写入一个命令到一个外设寄存器中，然后等待状态的变化。

```DSB
STR R0，[Addr] @写一个命令到外设寄存器
DSB
Poll_loop:
LDRR1，[Flag]
CMP R1，#0 @等待状态寄存器的变化
BEQ Poll_loop
```

### 请简述 cache的工作方式

处理器访问主存储器使用地址编码方式。cache也使用类似的地址编码方式，因此处理器使用这些编码地址可以访问各级cache。如图1.3所示，是一个经典的cache架构图。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001114611728-198599022.png)

处理器在访问存储器时，会把地址同时传递给TLB(Translation Lookaside Buffer）和cache。TLB是一个用于存储虚拟地址到物理地址转换的小缓存，处理器先使用 EPN( effective page number）在TLB中进行查找最终的RPN (Real Page Number)。如果这期间发生TLB miss,将会带来一系列严重的系统惩罚,处理器需要查询页表。假设这里TLB Hit,此时很快获得合适的RPN，并得到相应的物理地址（Physical Address，PA)。

同时,处理器通过cache编码地址的索引域(Cache Line Index)可以很快找到相应的cache line组。但是这里的cache block的数据不一定是处理器所需要的，因此有必要进行一些检查，将cache line 中存放的地址和通过虚实地址转换得到的物理地址进行比较。如果相同并且状态位匹配,那么就会发生cache命中(Cache Hit),那么处理器经过字节选择和偏移(Byte Selectand Align）部件，最终就可以获取所需要的数据。如果发生cache miss，处理器需要用物理地址进一步访问主存储器来获得最终数据，数据也会填充到相应的cache line中。上述描述的是VIPT (virtual Index phg sical Tag)的cache组织方式，将会在问题9中详细介绍。

如图1.4所示，是cache的基本的结构图。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001143356700-1843139283.png)

- cache地址编码:处理器访问cache时的地址编码，分成3个部分，分别是偏移域(Offset)、索引域( Index）和标记域（Tag)。
- Cache Line: cache中最小的访问单元,包含一小段主存储器中的数据,常见的cacheline大小是32Byte或64Byte等。
- 索引域(Index): cache地址编码的一部分，用于索引和查找是在cache中的哪一行。
- 组( Set):相同索引域的cache line组成一个组。
- 路( Way):在组相联的cache中，cache被分成大小相同的几个块。
- 标记（Tag): cache地址编码的一部分，用于判断cache line存放的数据是否和处理器想要的一致。

### cache的映射方式有full-associative （全关联)、direct-mapping(直接映射）和set-associative （组相联)3种方式，请简述它们之间的区别。为什么现代的处理器都使用组相联的cache映射方式?

(1)直接映射(Direct-mapping）

根据每个组( set）的高速缓存行数，cache可以分成不同的类。当每个组只有一行cache line时，称为直接映射高速缓存。

如图1.5所示，下面用一个简单小巧的cache来说明，这个cache 只有4行cache line,每行有4个字(word，一个字是4个 Byte)，共64 Byte。这个cache控制器可以使用两个比特位(bits[3:2]）来选择cache line中的字，以及使用另外两个比特位（bits[5:4]〉作为索引(Index)，选择4个cache line 中的一个，其余的比特位用于存储标记值（Tag）。

在这个 cache 中查询，当索引域和标记域的值和查询的地址相等，并且有效位显示这个cache line包含有效数据时，则发生cache命中，那么可以使用偏移域来寻址cache line中的数据。如果cache line包含有效数据，但是标记域是其他地址的值，那么这个cache line需要被替换。因此，在这个cache中，主存储器中所有bit[5:4]相同值的地址都会映射到同一个cache line中，并且同一时刻只有一个cache line，因为cache line被频繁换入换出，会导致严重的cache颠簸(cache thrashing)。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001151537014-968652926.png)

假设在下面的代码片段中，result、datal和 data2分别指向0x00、0x40和0x80地址,它们都会使用同一个cache line。

```
void add_array(int *data1, int *data2，int *result, int size)
{
    int i;
    for (i=0 ; i<size ; i++){
        result[i] = datal[i] + data2 [i];
    }
}
```

- 当第一次读data1即 0x40地址时，因为不在cache里面，所以读取从0x40 到0x4f地址的数据填充到cache line 中。
- 当读data2即 0x80地址的数据时，数据不在cache line中，需要把从0x80到0x8f地址的数据填充到cache line 中，因为地址0x80和0x40映射到同一个cache line,所以cache line 发生替换操作。
- result写入到0x00地址时，同样发生了cache line替换操作。
- 所以这个代码片段发生严重的cache颠簸，性能会很糟糕。

(2）组相联（set associative)

为了解决直接映射高速缓存中的cache颠簸问题,组相联的cache结构在现代处理器中得到广泛应用。

如图1.6所示，下面以一个2路组相联的cache为例,每个路(way)包括4个cache line,那么每个组（set）有两个cache line可以提供 cache line替换。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001223710516-1478193122.png)

地址0x00、0x40或者0x80的数据可以映射到同一个组中任意一个cache line。当cache line要发生替换操作时，就有50%的概率可以不被替换，从而减小了cache颠簸。

### 在一个32KB的4路组相联的cache 中，其中 cache line为 32Byte，请画出这个cache的cache line、way和set的示意图。

在Cortex-A7和Cortex-A9的处理器上可以看到32KB 大小的4路组相联cache。下面来分析这个cache的结构图。

cache的总大小为32KB，并且是4路( way)，所以每一路的大小为8KB：

way_size=32/4=8(KB)

cache Line的大小为32Byte，所以每一路包含的cache line数量为:

num_cache_line=8KB/32B= 256

所以在cache编码地址 Address 中，bit[4:0]用于选择cache line中的数据，其中 bit [4:2]可以用于寻址8个字，bit [ 1:0]可以用于寻址每个字中的字节。bit [12:5]用于索引(Index)选择每一路上 cache line，其余的bit [31:13]用作标记位（Tag)，如图1.7所示。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001224528164-2034087423.png)

### ARM9 处理器的Data Cache组织方式使用的VIVT，即虚拟Index虚拟Tag，而在Cortex-A7处理器中使用PIPT，即物理Index物理Tag，请简述PIPT比VIVT有什么优势?

处理器在进行存储器访问时，处理器访问地址是虚拟地址（virtual address，VA)，经过TLB和 MMU的映射，最终变成了物理地址（physical address，PA)。那么查询cache组是用虚拟地址，还是物理地址的索引域(Index）呢? 当找到cache组时，我们是用虚拟地址，还是物理地址的标记域(Tag）来匹配cache line呢?

cache可以设计成通过虚拟地址或者物理地址来访问,这个在处理器设计时就确定下来了，并且对cache 的管理有很大的影响。cache可以分成如下3类。

- VIVT ( Virtual Index Virtual Tag):使用虚拟地址索引域和虚拟地址的标记域。
- VIPT ( Virtual Index Physical Tag):使用虚拟地址索引域和物理地址的标记域。
- PIPT (Physical Index Physical Tag):使用物理地址索引域和物理地址的标记域。

在早期的ARM处理器中（比如ARM9处理器）采用VIVT的方式，不用经过MMU的翻译，直接使用虚拟地址的索引域和标记域来查找cache line，这种方式会导致高速缓存别名(cache alias）问题。例如一个物理地址的内容可以出现在多个cache line中，当系统改变了虚拟地址到物理地址映射时，需要清洗(clean)和无效（invalidate)这些cache，导致系统性能下降。

ARM11系列处理器采用VIPT 方式，即处理器输出的虚拟地址同时会发送到TLB/MMU单元进行地址翻译，以及在cache中进行索引和查询cache组。这样cache和TLB/MMU可以同时工作，当TLB/MMU完成地址翻译后，再用物理标记域来匹配 cache line。采用VIPT方式的好处之一是在多任务操作系统中，修改了虚拟地址到物理地址映射关系，不需要把相应的cache进行无效（ invalidate）操作。

ARM Cortex-A系列处理器的数据cache开始采用PIPT的方式。对于PIPT方式，索引域和标记域都采用物理地址，cache中只有一个cache组与之对应，不会产生高速缓存别名的问题。PIPT的方式在芯片设计里的逻辑比VIPT 要复杂得多。

采用VIPT 方式也有可能导致高速缓存别名的问题。在VIPT中，使用虚拟地址的索引域来查找cache组,这时有可能导致多个cache组映射到同一个物理地址上。以Linux kernel为例,它是以4KB大小为一个页面进行管理的,那么对于一个页来说,虚拟地址和物理地址的低 12bit（bit [11:0]）是一样的。因此，不同的虚拟地址映射到同一个物理地址，这些虚拟页面的低12位是一样的。如果索引域位于bit [11:0]范围内，那么就不会发生高速缓存别名。例如, cache line是32Byte，那么数据偏移域offset占5bit，有128个cache组，那么索引域占Tbit，这种情况下刚好不会发生别名。另外，对于ARM Cortex-A系列处理器来说，cache 总大小是可以在芯片集成中配置的。如表1.1所示，列举出了Cortex-A系列处理器的cache配置情况。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001230046935-1773163752.png)

### 请画出在二级页表架构中虚拟地址到物理地址查询页表的过程。

如图1.8所示，ARM处理器的内存管理单元(Memory Management Unit, MMU）包括TLB和Table Walk Unit两个部件。TLB是一块高速缓存，用于缓存页表转换的结果，从而减少内存访问的时间。一个完整的页表翻．维护需要软件来完成。页表查询是一个相对耗时的过程，理想的状态下是TLB里存有页表相关信息。当TLB Miss时，才会去查询页表，并且开始读入页表的内容。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231001233409056-364138827.png)

(1）ARMv7-A 架构的⻚表

ARMv7-A 架构支持安全扩展 (Security Extensions)，其中Cortex-A15 开始支持大物 理地址扩展 ( Large Physical Address Extension, LPAE)和虚拟化扩展，使得MMU 的实现比以前的 ARM 处理器要复杂得多。

如图 1.9所示，如果使能 了安全扩展， ARMv7-A 处理器分成安全世界(Secure World)和非安全世界(Non-secureWorld, 也称为Normal World)。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007160252506-1108703759.png)

如果处理器使能 了虚拟化扩展，那么处理器会在非安全世界中增加一个hyp 模式

在非安全世界中，运行特权被划分为PLA、 FL1和PL2。

- PL0等级 :这 个特权等级运行在用户空间（user mode），用于运行用户程序，它是没有系统特权的，比如没有权限访问处理器内部的硬件资源。
- PL1等级:这个等级包括ARMv6架构中的System模式、SVC模式、FIQ模式、IRQ模式、Undef模式，以及 Abort模式。Linux内核运行在PL1等级，应用程序运行在PL0等级。如果使能了安全扩展，那么安全模式里有一个Monitor模式也是运行在secure PL1等级，管理安全世界和非安全世界的状态转换。
- PL2等级:如果使能了虚拟化扩展，那么超级管理程序（Hypervisor）就运行这个等级，它运行在Hyp模式，管理 GuestOS之间的切换。

当处理器使能了虚拟化扩展，MMU的工作会变得更复杂。我们这里只讨论处理器没有使能安全扩展和虚拟化扩展的情况。ARMv7处理器的二级页表根据最终页的大小可以分为如下4种情况。

- 超级大段（SuperSection):支持16MB大小的超级大块。
- 段(section):支持1MB大小的段。
- 大页面(Large page):支持64KB大小的大页。
- 页面(page):4KB的页，Linux内核默认使用4KB的页。

如果只需要支持超级大段和段映射，那么只需要一级页表即可。如果要支持4KB页面或64KB大页映射，那么需要用到二级页表。不同大小的映射，一级或二级页表中的页表项的内容也不一样。如图1.10所示，以4KB页的映射为例。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007162112817-1845731093.png)

当TLB Miss时，处理器查询页表的过程如下。

- 处理器根据页表基地址控制寄存器TTBCR和虚拟地址来判断使用哪个页表基地址寄存器，是TTBR0还是TTBR1。页表基地址寄存器中存放着一级页表的基地址。
- 处理器根据虚拟地址的 bit[31:20]作为索引值，在一级页表中找到页表项，一级页表一共有4096个页表项。
- 第一级页表的表项中存放有二级页表的物理基地址。处理器根据虚拟地址的bit[19:12]作为索引值,在二级页表中找到相应的页表项，二级页表有256个页表项。
- 二级页表的页表项里存放有4KB页的物理基地址，因此处理器就完成了页表的查询和翻译工作。

如图1.11所示的 4KB映射的一级页表的表项，bit[1:0]表示是一个页映射的表项，bit[31:10]指向二级页表的物理基地址。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007163645884-304103762.png)

如图1.12所示的4KB映射的二级页表的表项，bit[31:12]指向4KB大小的页面的物理基地址。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007163934582-340830188.png)

（2）ARMv8-A架构的页表

ARMv8-A架构开始支持64bit操作系统。从ARMv8-A架构的处理器可以同时支持64bit和32bit应用程序，为了兼容ARMv7-A指令集，从架构上定义了AArch64架构和 AArch32架构。

AArch64架构和 ARMv7-A架构一样支持安全扩展和虚拟化扩展。安全扩展把ARM的世界分成了安全世界和非安全世界。AArch64架构的异常等级（Exception Levels）确定其运行特权级别，类似ARMv7架构中特权等级，如图1.13所示。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007164350713-2083826503.png)

- EL0:用户特权，用于运行普通用户程序。
- EL1:系统特权，通常用于运行操作系统。
- EL2:运行虚拟化扩展的Hypervisor。

在AArch64架构中的MMU支持单一阶段的地址页表转换，同样也支持虚拟化扩展中的两阶段的页表转换。

- 单一阶段页表:虚拟地址（VA）翻译成物理地址（PA)。
- 两阶段页表（虚拟化扩展)：
    - 阶段1——虚拟地址翻译成中间物理地址（Intermediate Physical Address，IPA)。
    - 阶段2——中间物理地址IPA翻译成最终物理地址 PA。

在AArch64架构中，因为地址总线带宽最多48位，所以虚拟地址VA被划分为两个空间，每个空间最大支持256TB。

- 低位的虚拟地址空间位于0x0000_0000_0000_0000到0x0000_FFFF_FFFF_FFFF。如果虚拟地址最高位 bit63等于0，那么就使用这个虚拟地址空间，并且使用TTBR0(Translation Table Base Register）来存放页表的基地址。
- 高位的虚拟地址空间位于0xFFFF_0000_0000_0000到0xFFFF_FFFF_FFFF_FFFF。如果虚拟地址最高位bit63等于1，那么就使用这个虚拟地址空间，并且使用TTBR1来存放页表的基地址。

如图1.14所示，AArch64架构处理地址映射图，其中页面是4KB的小页面。AArch64架构中的页表支持如下特性。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231007170349291-18093801.png)

- 最多可以支持4级页表。
- 输入地址最大有效位宽48bit。
- 输出地址最大有效位宽48bit。
- 翻译的最小粒度可以是4KB、16KB 或64KB。

### 在多核处理器中，cache的一致性是如何实现的?请简述MESI协议的含义。

高速缓存一致性(cache coherency)产生的原因是在一个处理器系统中不同CPU核上的数据cache和内存可能具有同一个数据的多个副本，在仅有一个CPU核的系统中不存在一致性问题。维护cache一致性的关键是跟踪每一个cache line的状态，并根据处理器的读写操作和总线上的相应传输来更新cache line在不同CPU核上的数据cache 中的状态,从而维护cache一致性。cache一致性有软件和硬件两种方式,有的处理器架构提供显式操作cache的指令,例如PowerPC,不过现在大多数处理器架构采用硬件方式来维护。在处理器中通过cache一致性协议来实现，这些协议维护一个有限状态机(Finite State Machine，FSM),根据存储器读写指令或总线上的传输,进行状态迁移和相应的cache操作来保证cache一致性，不需要软件介入。

cache一致性协议主要有两大类别，一类是监听协议(Snooping Protocol)，每个cache都要被监听或者监听其他cache的总线活动;另外一类是目录协议（Directory Protocol),全局统一管理cache状态。

1983年，James Goodman提出 Write-Once总线监听协议，后来演变成目前最流行的MESI协议。总线监听协议依赖于这样的事实，即所有的总线传输事务对于系统内所有的其他单元是可见的，因为总线是一个基于广播通信的介质，因而可以由每个处理器的 cache来进行监听。这些年来人们已经提出了数十种协议，这些协议基本上都是 write-once协议的变种。不同的协议需要不同的通信量，要求太多的通信量会浪费总线带宽，使总线争用变多，留下来给其他部件使用的带宽就减少。因此，芯片设计人员尝试将保持一致性的协议所需要的总线通信量减少到最小，或者尝试优化某些频繁执行的操作。

目前，ARM或x86等处理器广泛使用类似 MESI 协议来维护cache一致性。MESI协议的得名源于该协议使用的修改态(Modified)、独占态（Exclusive)、共享态(Shared）和失效态(Invalid）这4个状态。cache line中的状态必须是上述4种状态中的一种。MESI 协议还有一些变种，例如MOESI协议等，部分的ARMv7-A和ARMv8-A处理器使用该变种。

cache line中有两个标志:dirty和 valid。它们很好地描述了cache和内存之间的数据关系，例如数据是否有效、数据是否被修改过。在 MESI协议中，每个cache line有4个状态，可用2bit 来表示。

MESI 协议定义：

| 状态        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| M（修改态） | 这行数据有效，数据被修改，和内存中的数据不一致，数据只存在本cache中 |
| E（独占态） | 这行数据有效，数据和内存中数据一致，数据只存在于本cache中    |
| S（共享态） | 这行数据有效，数据和内存中数据一致，多个cache有这个数据副本  |
| I（无效态） | 这行数据无效                                                 |

MESI 状态说明：

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231008232400244-612096424.png)

- 修改和独占状态的cache line，数据都是独有的，不同点在于修改状态的数据是脏的，和内存不一致，而独占态的数据是干净的和内存一致。拥有修改态的cache line会在某个合适的时候把该cache line写回内存中，其后的状态变成共享态。
- 共享状态的cache line,数据和其他cache共享,只有干净的数据才能被多个cache共享。
- I的状态表示这个cache line无效。

MOESI协议增加了一个O(Owned）状态，并在 MESI协议的基础上重新定义了S状态，而E、M和Ⅰ状态与MESI 协议的对应状态相同。

- O位。O位为1，表示在当前cache行中包含的数据是当前处理器系统最新的数据复制，而且在其他CPU中可能具有该cache行的副本，状态为S。如果主存储器的数据在多个CPU的cache中都具有副本时，有且仅有一个CPU的Cache行状态为o，其他CPU的cache行状态只能为S。与 MESI 协议中的S状态不同，状态为O的 cache行中的数据与存储器中的数据并不一致。
- S位。在 MOESI 协议中，S状态的定义发生了细微的变化。当一个cache行状态为S时，其包含的数据并不一定与存储器一致。如果在其他CPU的cache 中不存在状态为O的副本时,该cache行中的数据与存储器一致;如果在其他CPU的cache中存在状态为O的副本时,cache行中的数据与存储器不一致。

### cache在linux内核中有哪些应用？

cache line的空间都很小，一般也就32 Byte。CPU 的cache是线性排列的也就是说一个32 Byte的 cache line与32 Byte的地址对齐，另外相邻的地址会在不同的cache line中错开,这里是指32*n的相邻地址。

cache在 linux内核中有很多巧妙的应用，读者可以在阅读本书后面章节遇到类似的情况时细细体会，暂时先总结归纳如下。

(1)内核中常用的数据结构通常是和L1 cache对齐的。例如，mm_struct、fs_cache等数据结构使用“SLAB_HWCACHE_ALIGN”标志位来创建slab缓存描述符，见 proc_caches_ init())函数。

(2)一些常用的数据结构在定义时就约定数据结构以L1 Cache对齐，使用“\__cacheline_internodealigned_in_smp”和“__cacheline_aligned_in_smp”等宏来定义数据结构，例如 struct zone、struct irqaction、softirq vec[ ]、irq stat[ ]、struct worker pool等。

cache和内存交换的最小单位是cache line，若结构体没有和cache line对齐，那么一个结构体有可能占用多个cache line。假设cache line的大小是32 Byte，一个本身小于32 Byte的结构体有可能横跨了两条cache line，在SMP中会对系统性能有不小的影响。举个例子，现在有结构体C1和结构体C2，缓存到L1 Cache时没有按照cache line对齐,因此它们有可能同时占用了一条cache line，即C1的后半部和C2的前半部在一条cache line中。根据cache一致性协议，CPUO修改结构体C1的时会导致CPU1的cache line失效，同理,CPU1对结构体C2修改也会导致 CPU0的cache line失效。如果CPUO和 CPU1反复修改，那么会导致系统性能下降。这种现象叫做“cache line伪共享”，两个CPU原本没有共享访问，因为要共同访问同一个cache line，产生了事实上的共享。解决上述问题的一个方法是让结构体按照 cache line对齐,典型地以空间换时间。include/linux/cache.h文件定义了有关cache相关的操作，其中 \____cacheline_aligned_in_smp的定义也在这个文件中，它和L1_CACHE_BYTES 对齐。

```
[include/linux/cache.h]
#define SMP_CACHE_BYTES L1_CACHE_BYTES
#define __cacheline_aligned __attribute_ ((__aligned__ (SMP_CACHE_BYTES)))
#define __cacheline_aligned_in_smp __cacheline_aligned

#ifndef __cacheline_aligned
#define __cacheline_aligned
_attribute_((_aligned(SMP_CACHE_ BYTES),__section__(" .data..cacheline_aligned" )))
#endif/*__cacheline_aligned*/

#define __cacheline_aligned_in_smp __cacheline_aligned
#define __cacheline_internodealigned_in_smp \
	__attribute__ ((__aligned__ (1<<(INTERNODE_CACHE_SHIFT))))
```

(3）数据结构中频繁访问的成员可以单独占用一个 cache line，或者相关的成员在cache line中彼此错开,以提高访问效率。例如, struct zone数据结构中zone->lock和zone->lru_lock这两个频繁被访问的锁，可以让它们各自使用不同的cache line，以提高获取锁的效率。

再比如struct worker pool数据结构中的nr running成员就独占了一个cache line，避免多CPU同时读写该成员时引发其他临近的成员“颠簸”现象，见第5.3节。

(4）slab的着色区，见第2.5节。

(5）自旋锁的实现。在多CPU系统中，自旋锁的激烈争用过程导致严重的CPU cacheline bouncing现象，见第4章关于自旋锁的部分内容。

### cache line为什么一般是64字节

Cache line一般是64字节，是因为这个大小能够充分利用现代处理器的高速缓存系统。以下是几个原因：

- 块大小：Cache line的大小决定了从主内存读取数据时，一次可以加载到缓存中的数据量。64字节的大小适中而且效率高，能够在一次读取中加载多个数据项，降低内存访问的延迟。
- 缓存一致性：当一个数据项发生改变时，处理器会将整个缓存行标记为无效，需要重新加载数据项。如果Cache line的大小过小，很容易导致无效的数据项过多，增加了缓存一致性的开销。
- 写回和写分配：当处理器需要写入数据时，它一般会先将数据写入缓存，然后再由缓存写回到主内存。Cache line的大小决定了一次写回的数据量，过小的大小会造成频繁的写回操作，降低效率。
- Cache与内存页对齐：Cache line的大小通常与内存页的大小相等，这样可以提高内存的访问效率。因为内存页是操作系统进行内存管理的基本单位，如果缓存行大小和内存页大小一致，就可以最大限度地减少内存访问的次数。

综上所述，64字节的缓存行大小在充分利用高速缓存系统、减少内存访问延迟以及提高处理器性能方面具有良好的折中效果。

### 请简述ARM big.LITTLE架构，包括总线连接和 cache管理等。

ARM提出大小核概念，即 big.LITTLE 架构，针对性能优化过的处理器内核称为大核，针对低功耗待机优化过的处理器内核称为小核。

如图1.15所示,在典型 big.LITTLE 架构中包含了一个由大核组成的集群(Cortex-A57)和小核（Cortex-A53）组成的集群，每个集群都属于传统的同步频率架构，工作在相同的频率和电压下。大核为高性能核心，工作在较高的电压和频率下，消耗更多的能耗，适用于计算繁重的任务。常见的大核处理器有Cortex-A15、Cortex-A57、Cortex-A72和Cortex-A73。小核性能虽然较低，但功耗比较低，在一些计算负载不大的任务中，不用开启大核，直接用小核即可，常见的小核处理器有Cortex-A7和 Cortex-A53。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231011170535513-663953800.jpg)



如图1.16所示是4核Cortex-A15和4核Cortex-A7的系统总线框图。

-   Quad Cortex-A15:大核 CPU 镞。
-   Quad Cortex-A7:小核CPU 族。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231011171151084-202688307.jpg)

-   CCI-400模块:用于管理大小核架构中缓存一致性的互连模块。CCI-400只能支持两个CPU簇（cluster)，而最新款的CCI-550可以支持6个CPU 簇。
-   DMC-400:内存控制器。
-   NIC-400:用于AMBA总线协议的连接，可以支持AXI、AHB和 APB总线的连接。
-   MMU-400 :系统内存管理单元。
-   Mali-T604:图形加速控制器。
-   GIC-400:中断控制器。

ARM CoreLink CCI-400模块用于维护大小核集群的数据互联和cache一致性。大小核集群作为主设备(Master)，通过支持ACE 协议的从设备接口(Slave）连接到CCI-400 上，它可以管理大小核集群中的 cache一致性和实现处理器间的数据共享。

此外它还支持3个 ACE-Lite从设备接口（ACE-Lite Slave Interface)，可以支持一些IO主设备，例如GPU Mali-T604。通过 ACE-Lite协议，GPU可以监听处理器的cache。CCI-400还支持3个ACE-Lite主设备接口，例如通过 DMC-400来连接LP-DDR2/3或 DDR内存设备，以及通过NIC-400总线来连接一些外设，例如 DMA 设备和LCD等。

ACE协议，全称为AMBA-AXI Coherency Extension协议，是AX4协议的扩展协议，增加了很多特性来支持系统级硬件一致性。模块之间共享内存不需要软件干预，硬件直接管理和维护各个cache之间的一致性,这可以大大减少软件的负载,最大效率地使用cache,减少对内存的访问，进而降低系统功耗。

### cache coherency和 memory consistency 有什么区别?

cache coherency高速缓存一致性关注的是同一个数据在多个cache和内存中的一致性问题，解决高速缓存一致性的方法主要是总线监听协议，例如 MESI协议等。而 memoryconsistency 关注的是处理器系统对多个地址进行存储器访问序列的正确性,学术上对内存访问模型提出了很多，例如严格一致性内存模型、处理器一致性内存模型,以及弱一致性内存模型等。弱内存访问模型在现在处理器中得到广泛应用，因此内存屏障指令也得到广泛应用。

### 请简述cache的write back有哪些策略。

在处理器内核中，一条存储器读写指令经过取指、译码、发射和执行等一系列操作之后,率先到达LSU部件。LSU 部件包括Load Queue和 Store Queue,是指令流水线的一个执行部件，是处理器存储子系统的最顶层,连接指令流水线和cache的一个支点。存储器读写指令通过LSU之后，会到达L1 cache控制器。L1 cache控制器首先发起探测(Probe）操作，对于读操作发起cache读探测操作并将带回数据，写操作发起cache写探测操作。写探测操作之前需要准备好待写的cache line，探测工作返回时将会带回数据。当存储器写指令获得最终数据并进行提交操作之后才会将数据写入，这个写入可以 Write Through 或者Write Back。

对于写操作，在上述的探测过程中，如果没有找到相应的cache block，那么就是WriteMiss，否则就是Write Hit。对于Write Miss的处理策略是Write-Allocate，即 L1 cache控制器将分配一个新的cache line，之后和获取的数据进行合并，然后写入L1 cache 中。

-   Write Through(直写模式):进行写操作时，数据同时写入当前的cache、下一级cache或主存储器中。Write Through策略可以降低 cache一致性的实现难度，其最大的缺点是消耗比较多的总线带宽。
-   Write Back（回写模式):在进行写操作时，数据直接写入当前cache，而不会继续传递，当该Cache Line被替换出去时，被改写的数据才会更新到下一级cache或主存储器中。该策略增加了cache一致性的实现难度，但是有效降低了总线带宽需求。

### 请简述cache line的替换策略。

由于cache 的容量远小于主存储器，当Cache Miss发生时，不仅仅意味着处理器需要从主存储器中获取数据，而且需要将cache的某个cache line替换出去。在cache的Tag阵列中，除了具有地址信息之外还有cache block的状态信息。不同的cache一致性策略使用的cache状态信息并不相同。在MESI协议中，一个cache block通常含有M、E、S和I这4个状态位。

cache的替换策略有随机法（Random policy)、先进先出法(FIFO）和最近最少使用算法（LRU)。

-   随机法:随机地确定替换的cache block，由一个随机数产生器来生成随机数确定替换块，这种方法简单，易于实现，但命中率比较低。
-   先进先出法:选择最先调入的那个cache block进行替换，最先调入的块有可能被多次命中,但是被优先替换，因而不符合局部性规律。
-   最近最少使用算法:LRU 算法根据各块使用的情况，总是选择最近最少使用的块来替换,这种算法较好地反映了程序局部性规律。

在Cortex-A57处理器中，L1 cache采用LRU算法，而L2 cache采用随机算法。在最新的Cortex-A72处理器中，L2 cache采有伪随机算法(pseudo-random policy)或伪LRU算法（pseudo-least-recently-used policy）。

### 异构核RISC-V和ARM通讯如何通讯

CCI (Coherent Component Interconnect) 是一种用于处理器和其他外设之间进行高速、一致性通信的协议。它通过提供一组标准化的通信接口和协议，使得不同类型的处理器核能够在同一个系统中实现一致性共享内存和缓存的功能。
在异构RISC-V和ARM核之间通信的时候，CCI通信原理是通过以下步骤实现的：

1.  首先，RISC-V和ARM核需要通过CCI接口进行初始化和配置。这涉及到选择合适的通信模式和参数设置，以确保通信的一致性和正确性。
2.  接下来，当RISC-V核需要与ARM核进行通信时，它会使用CCI接口发出一个请求。
3.  当ARM核收到请求后，它会根据请求的类型和参数进行相应的处理，并将处理结果返回给RISC-V核。
4.  在处理请求的过程中，CCI协议通过一致性协议保证了共享内存和缓存的一致性。这意味着在RISC-V和ARM核之间进行通信时，它们可以正确地读取和更新共享的内存和缓存数据，而不会出现数据冲突或不一致的情况。

总的来说，CCI通过提供一致性的通信接口和协议，使得异构RISC-V和ARM核能够有效地进行通信，并且保证共享的内存和缓存数据的一致性。这对于提高系统性能和效率非常重要。

### 多进程间频繁切换对TLB有什么影响?现代的处理器是如何面对这个问题的

在现代处理器中，软件使用虚拟地址访问内存，而处理器的MMU单元负责把虚拟地址转换成物理地址，为了完成这个映射过程，软件和硬件共同来维护一个多级映射的页表。当处理器发现页表中无法映射到对应的物理地址时，会触发一个缺页异常，挂起出错的进程，操作系统软件需要处理这个缺页异常。我们之前有提到过二级页表的查询过程，为了完成虚拟地址到物理地址的转换，查询页表需要两次访问内存，即一级页表和二级页表都是存放在内存中的。

TLB(Translation Look-aside Buffer）专门用于缓存内存中的页表项，一般在 MMU单元内部。TLB是一个很小的cache，TLB表项(TLB entry）数量比较少，每个TLB表项包含一个页面的相关信息，例如有效位、虚拟页号、修改位、物理页帧号等。当处理器要访问一个虚拟地址时，首先会在TLB中查询。如果TLB表项中没有相应的表项，称为TLB Miss，那么就需要访问页表来计算出相应的物理地址。如果TLB表项中有相应的表项，那么直接从TLB表项中获取物理地址，称为TLB命中。

TLB内部存放的基本单位是TLB表项，TLB容量越大，所能存放的TLB表项就越多,TLB命中率就越高，但是TLB的容量是有限的。目前Linux内核默认采用4KB大小的小页面，如果一个程序使用512个小页面，即2MB大小，那么至少需要512个TLB表项才能保证不会出现TLB Miss 的情况。但是如果使用2MB大小的大页，那么只需要一个TLB表项就可以保证不会出现TLB Miss的情况。对于消耗内存以GB为单位的大型应用程序，还可以使用以1GB为单位的大页，从而减少TLB Miss情况。

### 请简述NUMA 架构的特点。

现在绝大数ARM系统都采用UMA 的内存架构（Uniform Memory Architechture)，即内存是统一结构和统一寻址。对称多处理器(Symmetric Multiple Processing，SMP）系统大部分都采用UMA内存架构。因此在UMA架构的系统中有如下特点。

-   所有硬件资源都是共享的，每个处理器都能访问到系统中的内存和外设资源。
-   所有处理器都是平等关系。
-   统一寻址访问内存。
-   处理器和内存通过内部的一条总线连接在一起。

如图1.17所示，SMP系统相对比较简洁，但是缺点也很明显。因为所有对等的处理器都通过一条总线连接在一起，随着处理器数量的增多，系统总线成为系统的最大瓶颈。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231013103703023-1597205701.jpg)

NUMA系统是从SMP系统演化过来的。如图1.18所示，NUMA系统由多个内存节点组成，整个内存体系可以作为一个整体，任何处理器都可以访问，只是处理器访问本地内存节点拥有更小的延迟和更大的带宽，处理器访问远程内存节点速度要慢一些。每个处理器除了拥有本地的内存之外，还可以拥有本地总线，例如 PCIE、STAT等。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231013103709694-1137088652.jpg)

现在的x86阵营的服务器芯片早已支持NUMA架构了，例如Intel的至强服务器。对于ARM 阵营，2016年Cavium公司发布的基于ARMv8-A 架构设计的服务器芯片"ThunderX2”也开始支持NUMA 架构。

### ARM 从 Cortex系列开始性能有了质的飞越，比如 Cortex-A8/A15/A53/A72，请说说 Cortex系列在芯片设计方面做了哪些重大改进?

计算机体系结构是一个权衡的艺术，尺有所短，寸有所长。在处理器领域经历多年的优胜劣汰，市面上流行的处理器内核在技术上日渐趋同。

ARM处理器在Cortex系列之后，加入了很多现代处理器的一些新技术和特性，已经具备了和 Intel一较高下的能力，例如2016年发布的Cortex-A73处理器。

2005年发布的 Cortex-A8内核是第一个引入超标量技术的ARM处理器，它在每个时钟周期内可以并行发射两条指令，但依然使用静态调度的流水线和顺序执行方式。Cortex-A8内核采用13级整型指令流水线和10 级 NEON 指令流水线。分支目标缓冲器(Branch Target Buffer，BTB)使用的条目数增加到512，同时设置了全局历史缓冲器(GlobalHistory Buffer，GHB）和返回堆栈（Return Stack，RS）部件，这些措施极大地提高了指令分支预测的成功率。另外，还加入了way-prediction部件。

2007年 Cortex-A9发布，引入了乱序执行和猜测执行机制以及扩大L2 cache的容量。

2010年Cortex-A15发布，最高主频可以到2.5GHz，最多支持8个处理器核心，单个cluster最多支持4个处理器核心，采有超标量流水线技术，具有1TB物理地址空间，支持虚拟化技术等新技术。指令预取总线宽度为128bit，一次可以预取4~8条指令，和 Cortex-A9相比，提高了一倍。Decode部件一次可以译码3条指令。Cortex-A15引入了Micro-Ops概念。Micro-ops指令和X86的uops指令想法较为类似。在x86处理器中，指令译码单元把复杂的CISC指令转换成等长的upos 指令，再进入到指令流水线中;而 Cortex-A15，指令译码单元把RISC指令进一步细化为Micro-ops 指令，以充分利用指令流水线中的多个并发执行单元。指令译码单元为3路指令译码，在一个时钟周期可以同时译码3条指令。

2012年发布64位的Cortex-A53和 Cortex-A57，ARM开始进军服务器领域。Cortex-A57是首款支持64位的ARM处理器内核，采用3发乱序执行流水线(Out-of-Order pipeline),并且增加数据预取功能。

2015年发布Cortex-A57的升级版本Cortex-A72，如图1.19所示。A72在A57架构的基础上做了大量优化工作，包括新的分支预测单元，改善解码流水线设计等。在指令分发单元（Dispatch）也做了很大优化，由原来A57架构的3发射变成了5发射，同时发射5条指令，并且还支持并行执行8条微操作指令，从而提高解码器的吞吐量。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231013202216570-1045778991.jpg)

## 内存管理篇：

### 在系统启动时，ARM Linux内核如何知道系统中有多大的内存空间?

在ARM Vexpress平台中，内存的定义在vexpress-v2p-ca9.dts文件中。该DTS文件定义了内存的起始地址为0x60000000，大小为0x40000000，即1GB大小内存空间。

```
[arch/arm/boot/dts/vexpress-v2p-ca9.dts]
memory@60000000 {
	device_type = "memory";
	reg = <0x60000000 0x40000000>;
};
```

内核在启动的过程中,需要解析这些DTS文件,实现代码在early_init_dt_scan_memory()函数中。代码调用关系为: start_kernel()->setup_arch()->setup_machine_fdt()->early_init_dt_scan_nodes()->early_init_dt_scan_memory()。

```
[drivers/of/fdt.c]int __init_early_init_dt_scan_memory(unsigned long node，const char *uname,int depth, void *data){	const char *type = of_get_flat_dt_prop(node，"device_type"，NULL);	const _be32 *reg,*endp;	int l;	if (strcmp(type, "memory") != 0 )		return 0 ;	reg = of_get_f1at_dt _prop (node, "reg" , &1);	endp = reg + (l / sizeof(_be32));		while ((endp - reg) >= (dt_root_addr_cells + dt_root_size_cells)){		u64 base, size;				base = dt_mem_next_cell(dt_root_addr_cells，&reg);		size = dt_mem_next_cell(dt_root_size_cells，&reg);				if (size == 0)			continue;		early_init_dt_add_memory_arch(base, size);		return o;	}}
```

解析“memory”描述的信息从而得到内存的base_address和 size信息，最后内存块信息通过early_init_dt_add_memory_arch()->memblock_add()函数添加到memblock子系统中。



### 在32bit Linux中，用户空间和内核空间的比例通常是3:1,可以修改为2:2吗？

在32bit Linux 中，一共能使用的虚拟地址空间是4GB，用户空间和内核空间的划分通常是按照3:1来划分，也可以按照2:2来划分。

在arch/arm/Kconfig中：

	choice	prompt "Memory split"	depends on MMU	default VMSPLIT_3G	help	  Select the desired split between kernel and user memory.If you are not absolutely sure what you are doing, leave this  option alone!config VMSPLIT_3G	bool "3G/1G user/kernel split"config VMSPLIT_2G	bool "2G/2G user/kernel split"config VMSPLIT_1G	bool "1G/3G user/kernel split"endchoice

在ARM Linux 中有一个配置选项“memory split"，可以用于调整内核空间和用户空间的大小划分。通常使用“VMSPLIT_3G”选项，用户空间大小是3GB，内核空间大小是1GB,那么PAGE _OFFSET 描述内核空间的偏移量就等于0xC000_0000。也可以选择“VMSPLIT_2G”选项，这时内核空间和用户空间的大小都是2GB，PAGE_OFFSET 就等于0x8000_0000。

内核中通常会使用PAGE_OFFSET 这个宏来计算内核线性映射中虚拟地址和物理地址的转换。

```
/* PAGE_OFFSET - the virtual address of the start of the kernel image */#define PAGE_OFFSET UL(CONFIG_PAGE_OFFSET)
```

例如，内核中用于计算线性映射的物理地址和虚拟地址的转换关系。线性映射的物理地址等于虚拟地址vaddr减去 PAGE_OFFSET (0xC000_0000）再减去PHYS_OFFSET (在部分ARM 系统中该值为0)。



### 物理内存页面如何添加到伙伴系统中，是一页一页添加，还是以2的几次幂来加入呢?

是以2的几次幂来加入的

在 free_low_memory_core_early)函数中，通过 for_each_free_mem_range()函数来遍历所有的memblock内存块，找出内存块的起始地址和结束地址。

```
[start_kernel-> mm_init-> mem_init-> free_all_bootmem-> free_low_memory_core_early]static unsigned long _init free_low_memory_core_early(void){	unsigned long count = 0;	phys_addr_t start, end;	u64 i;		memblock_clear_hotplug(0，-1);	for_each_free_mem_range(i,NUMA_NO_NODE,&start,&end，NULL)		count +=_free_memory_core (start, end) ;	return count;}
```

把内存块传递到__free_pages_memory()函数中，该函数定义如下:

```
void _init_free_pages_bootmem(struct page *page，unsigned int order){	unsigned int nr_pages = 1 << order;	struct page *p = page;		page_zone(page)->managed_pages += nr_pages;	set_page_refcounted(page);	__free_pages(page, order) ;}
```

\__free_pages()函数是伙伴系统的核心函数，这里按照 order的方式添加到伙伴系统中，

下面是向系统中添加一段内存的情况，页帧号范围为[0x8800e,0xaecea]，以 start为起始来计算其order，一开始order 的数值还比较凌乱，等到start和0x400对齐，以后基本上order都取值为10了，也就是都挂入order为10的free_list链表中。

```
__free_pages_memory: start=0x8800e, end=0xaecea__free pages_memory: start=0x8800e，order=1，__ffs()=1， ffs()=2__free_pages_memory: start=0x88010，order=4，__ffs()=4, ffs ()=5__free pages_memory: start=0x88020，order=5,__ffs()=5， ffs ()=6__free pages_memory: start=0x88040, order=6，__ffs()=6, ffs()=7__free_pages_memory: start=0x88080，order=7，__ffs()=7，ffs()=8__free_pages_memory: start=0x88100，order=8，__ffs()=8, ffs()=9__free pages_memory: start=0x88200, order=9, __ffs()=9， ffs()=10__free pages_memory: start=0x88400，order=10，__ffs()=10，ffs()=11__free pages_memory: start=0x88800，order=10，_ffs()=11，ffs()=12__free_pages_memory: start=0x88c00，order=10，_ffs()=10， ffs()=11__free_pages_memory: start=0x89000, order=10，_ffs ()=12， ffs()=13__free_pages_memory: start=0x89400, order=10，_ffs()=10， ffs()=11__free_pages_memory: start=0x89800, order=10，_ffs()=11，ffs()=12__free pages_memory: start=0x89c00，order=10，_ffs()=10，ffs()=11
```



### 内核空间的页表存放在什么地方?

内核空间的页表存放在内存中。具体来说，在x86架构的计算机上，内核空间的页表存放在内核的虚拟地址空间中的一块特殊区域，在Linux操作系统中这个区域通常被称为高端内存（High Memory）。这个区域的起始地址是内核虚拟地址空间中的最高地址，通常是3GB或4GB。内核页表包含用于映射内核虚拟地址到物理地址的页表项，从而允许内核访问和操作系统底层的硬件资源。这些页表项存放在内核虚拟地址空间的高端内存区域，并由内核使用和管理。



### 在ARM32系统中,页表是如何映射的?在ARM64系统中,页表又是如何映射的?

在ARM32系统中，页表的映射使用的是两级页表结构。整个地址空间被分成多个页表项，每个页表项对应一个页表数据结构。页表项包含了虚拟地址和物理地址之间的映射关系。

具体而言，在ARM32系统中，页表的映射过程如下：

虚拟地址被分成三个部分：高10位表示页目录索引，中10位表示页表索引，低12位表示页内偏移。

1.  通过虚拟地址的高10位，从页目录中找到对应的页表项。
2.  通过虚拟地址的中10位，从页表中找到对应的页表项。
3.  通过虚拟地址的低12位，获取页内偏移。
4.  根据页表项中的物理地址和页内偏移，得到最终的物理地址。

在ARM64系统中，页表映射的结构是采用了多级页表的形式。ARM64架构中，一般使用4级页表结构来管理虚拟地址和物理地址之间的映射关系。
ARM64的四级页表结构由PGD（Page Global Directory）、PUD（Page Upper Directory）、PMD（Page Middle Directory）和PTE（Page Table Entry）四级组成。

-   首先，PGD是一个存储PGD项的数组，每个PGD项指向一个PUD。
-   接下来，PUD也是一个存储PUD项的数组，每个PUD项指向一个PMD。
-   然后，PMD也是一个存储PMD项的数组，每个PMD项指向一个PTE。
-   最后，PTE是一个存储页面相关信息的数据结构，其中包含了指向物理地址的指针。

通过这种多级页表的结构，ARM64系统可以将虚拟地址转换为物理地址。当进程访问内存空间时，首先通过PGD找到对应的PUD，然后通过PUD找到对应的PMD，接着通过PMD找到对应的PTE，最后从PTE中获取物理地址。
需要注意的是，ARM64系统的页表结构可以根据具体的需求进行调整。例如，可以根据内存大小和虚拟地址空间的需求，调整页表的级数和每级的索引位数。这样可以灵活地适应不同的系统配置和应用场景。

### 在32bit Linux 中，内核空间的线性映射的虚拟地址和物理地址是如何换算的?

在32位Linux中，内核空间的线性映射虚拟地址和物理地址之间的换算可以使用内核的页表进行。Linux使用两级页表的结构来管理虚拟地址和物理地址之间的映射关系。
首先，内核使用一个称为PGD（Page Global Directory）的二级页表来进行虚拟地址到物理地址的转换。PGD是一个存储PGD项的数组，每个PGD项指向一个称为PMD（Page Middle Directory）的二级页表。
接下来，PMD也是一个存储PMD项的数组，每个PMD项指向一个称为PTE（Page Table Entry）的一级页表。PTE是一个存储页面相关信息的数据结构，其中包含了指向物理地址的指针。
通过这种两级页表的结构，可以将虚拟地址转换为物理地址。当进程访问内核空间时，首先通过PGD找到对应的PMD，然后通过PMD找到对应的PTE，最后从PTE中获取物理地址。
需要注意的是，由于32位系统的地址空间有限，所以内核空间的线性映射通常只占用一部分虚拟地址空间。这部分虚拟地址空间与物理地址空间之间的映射关系是通过启动时的内核初始化代码来建立的。

### 在32bit Linux 中，高端内存的起始地址是如计算出来的?

在32位Linux中，高端内存的起始地址是通过计算和配置来确定的。在32位系统中，总的虚拟地址空间为4GB（2^32）。
其中，最高的1GB被保留给内核空间，即内核虚拟地址空间的起始地址为3GB（0xC0000000）。
因此，高端内存的起始地址可以通过以下方式计算得出：
高端内存起始地址 = 总的虚拟地址空间大小 - 内核虚拟地址空间大小
即高端内存起始地址 = 4GB - 1GB = 3GB（0xC0000000）

### 请画出ARM32 linux内存布局图

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231020160349740-1530995633.jpg)

### 请画出ARM64 linux内存布局图

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231021154401182-1494057514.png)

(1）用户空间:0x0000_0000 0000_0000到0x0000_ffff_ffff_ffff，一共有256TB。

(2）非规范区域。

(3）内核空间:0xffff_0000_0000_0000到0xffff_ffff__ffff，一共有256TB。内核空间又做了如下细分。

- vmalloc区域: 0xffff_0000_0000_000到0xffff_7bff_bfff_000，大小为126974GB。
- vmemmap区域:0xfflf_7bffc_0000_000到0xffff_7fffc_0000_000，大小为4096GB。
- PCI EO区域: 0xffff_7ffff_ae00_000到0xffff_7ffff_be00_000，大小为16MB。
- Modules 区域:0xffff_7ffff_c0000_00到0xffff8_0000_0000_000，大小为64MB。
- normal memory线性映射区:0xffff_8000_0000_0000到0xfffffffffff,大小为128TB。



### 请简述Linux内核在理想情况下页面分配器( page allocator )是如何分配出连续物理页面的。

在理想情况下，Linux内核页面分配器（page allocator）通过以下步骤分配连续的物理页面：

1. 内核维护一个物理页面的位图，每个位表示一个物理页面的状态（可用或已分配）。
2. 当应用程序或内核需要分配物理页面时，页面分配器会搜索位图以找到连续且足够大小的空闲物理页面。
3. 页面分配器使用伙伴系统算法将空闲物理页面分割为不同的块大小，以满足不同大小的内存分配请求。伙伴系统算法将空闲物理页面分为等大小的块，每个块有两个伙伴。
4. 页面分配器根据要分配的物理页面大小选择合适的块大小。如果没有完全匹配的块大小，分配器会尽量分割较大的块来满足请求。
5. 页面分配器更新位图，将已分配的页面标记为不可用状态。
6. 分配完成后，页面分配器返回分配的页面的物理地址给调用者，使其可以将其用于存储数据。

这样，Linux内核页面分配器就能够在理想情况下分配出连续的物理页面，并满足应用程序或内核的内存需求。



### 在页面分配器中，如何从分配掩码(gfp_mask )中确定可以从哪些zone中分配内存?

分配掩码是在内核代码中分成两类，一类叫zone modifiers，另一类是action modifiers。zone modifiers指定从哪一个zone中分配所需的页面。zone modifiers由分配掩码的最低4位来定义，分别是`___GFP_DMA`、`___GFP_HIGHMEM`、`___GFP_DMA32`和`___GFP_MOVABLE`。

```
/* If the above are modified, __GFP_BITS_SHIFT may need updating *//* * GFP bitmasks.. * * Zone modifiers (see linux/mmzone.h - low three bits) * * Do not put any conditional on these. If necessary modify the definitions * without the underscores and use them consistently. The definitions here may * be used in bit comparisons. */#define __GFP_DMA	((__force gfp_t)___GFP_DMA)#define __GFP_HIGHMEM	((__force gfp_t)___GFP_HIGHMEM)#define __GFP_DMA32	((__force gfp_t)___GFP_DMA32)#define __GFP_MOVABLE	((__force gfp_t)___GFP_MOVABLE)  /* Page is movable */#define GFP_ZONEMASK	(__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE)
```

GFP_KERNEL分配掩码定义在gfp.h头文件上，是一个分配掩码的组合。详情参考伙伴分配内存的内容；



### 在Linux内核启动汇编代码中，为什么要建立恒等映射的?

在Linux内核启动汇编代码中，建立恒等映射（identity mapping）的目的是确保内核可以在启动过程中正确访问和操作物理内存。

恒等映射将物理内存的地址与逻辑地址（虚拟地址）一一对应，这样内核就可以使用逻辑地址来访问物理内存，而无需考虑地址转换和映射的复杂性。

在Linux内核启动的早期阶段，操作系统尚未启动页表等内存管理机制，因此无法使用虚拟地址访问物理内存。通过建立恒等映射，内核可以使用虚拟地址来直接访问物理内存，从而进行初始化、加载代码和数据等操作。

建立恒等映射还可以简化内核的启动过程，避免出现因为地址转换和映射错误导致的问题。这样可以确保内核在启动阶段可以正确地操作物理内存并完成必要的初始化工作，为后续的内存管理和其他功能提供基础。



### 从Uboot跳转到内核时，为什么指令高速缓存可以打开而数据高速缓存必须关闭？

指令高速缓存和数据高速缓存在处理器中起着不同的作用。指令高速缓存存储的是处理器执行的指令，而数据高速缓存存储的是处理器读取和写入数据的临时存储区域。

当从U-Boot跳转到内核时，由于内核中的代码是不同于U-Boot的代码的，处理器不能保证从U-Boot缓存中读取的指令在内核中仍然有效。因此，打开指令高速缓存可以提高指令的执行效率，因为大部分指令是在内核中执行的。

然而，数据高速缓存在从U-Boot跳转到内核时，由于数据可能已经改变，原先缓存的数据可能会出现错误的读取或写入。因此，为了保证数据的一致性，需要关闭数据高速缓存，确保在内核中对存储器的读取和写入都是直接操作存储器而不是缓存。

综上所述，指令高速缓存可以打开是因为内核中的指令不会被修改，而数据高速缓存必须关闭是为了保证数据的一致性。



### 为用户进程分配物理内存,分配掩码应该选用GFP_KERNEL,还是GFP_HIGHUSERMOVABLE呢?

对于为用户进程分配物理内存，我们通常会使用GFP_KERNEL分配掩码。GFP_KERNEL是用于内核分配的标志，它表示分配的内存将用于内核线程或用户进程。这意味着分配的内存既可以由内核访问，也可以由用户空间进程访问。

相比之下，GFP_HIGHUSERMOVABLE是用于可动态迁移的用户空间内存分配的标志。它用于分配能够在运行时被迁移到其他物理页面上的内存。这主要用于具有NUMA架构的系统，以便更好地利用内存并提高性能。

然而，GFP_HIGHUSERMOVABLE并不适用于所有用户进程。它有一些限制，如不能与GFP_ATOMIC标志一起使用，且分配的内存需要支持动态迁移。因此，对于大多数普通的用户进程，使用GFP_KERNEL是更常见和适用的选择。

在大多数情况下，确实如此。然而，有些特殊情况可能要使用GFP_HIGHUSERMOVABLE来为用户进程分配物理内存。

例如，在具有NUMA架构的系统上，使用GFP_HIGHUSERMOVABLE可以更好地利用内存并提高性能。此外，如果分配的内存在运行时需要动态迁移到其他物理页面上，也应该使用GFP_HIGHUSERMOVABLE标志。

因此，虽然大多数用户进程分配物理内存时使用GFP_KERNEL是常见和适用的，但某些特殊情况下可能需要使用GFP_HIGHUSERMOVABLE。最终选择取决于系统的具体要求和设计。



### 内核中有多少个分配内存的函数，都列举出来，并且举出场景及区别

在内核中，有多个用于分配内存的函数。以下是常见的几个函数及其场景和区别：

1. kmalloc：用于分配较小的内存块，通常用于分配少量的连续物理内存。它的场景包括数据结构的动态分配、驱动程序中的缓冲区分配等。与其他函数相比，kmalloc的分配速度较快，但可用的连续内存空间有限。
2. vmalloc：用于分配大块内存，适用于需要大量内存的场景。vmalloc在虚拟地址空间中分配内存，然后通过页表将虚拟内存映射到物理内存。与kmalloc相比，vmalloc的分配速度较慢，但可以分配更大的内存空间。
3. kzalloc：类似于kmalloc，用于分配较小的内存块。与kmalloc的区别在于，kzalloc会将分配的内存块全部清零。
4. get_free_pages：用于分配多个页框（4KB的内存页）。适用于需要连续内存的场景，如DMA缓冲区的分配。
5. alloc_pages：类似于get_free_pages，用于分配多个页框。与get_free_pages的区别在于，alloc_pages会尝试从内存高端开始分配页框，以提高内存分配的效率。

这些函数在分配内存的方式和用途上都有所不同，开发者在选择使用时需要根据具体的场景和需求进行选择



### slab分配器是如何分配和释放小内存块的?

slab分配小内存块时用kmem_cache_alloc，从函数的名称、参数、返回值、注释中，我们很容易知道kmem_cache_alloc()函数从给定的slab高速缓存中获取一个指向空闲对象的指针。实际上，进行获取空闲对象的时候，会先从per-CPU缓存中也就是array_cache中查找空闲对象，如果没有则会从kmem_cache_node中获取空闲对象，如果也没有则需要利用伙伴算法分配新的连续页框，然后从新的页框中获取空闲对象。从kmem_cache_alloc()到大致的调用链如下：

```
kmem_cache_alloc()——>slab_alloc()——>__do_cache_alloc()——>____cache_alloc()——>cpu_cache_get()（这里实际上是从array_cache中获取空闲对象）——>cache_alloc_refill()（这里会在array_cache中没有空闲对象时执行）——>cpu_cache_get()（经过cache_alloc_refill()的执行基本保证array_cache中有空闲对象）——>返回可用空闲对象
```

对cache_alloc_refill()函数执行步骤分解如下：

```
cache_alloc_refill()——>尝试从被一个NUMA节点所有CPU共享的缓冲中获取空闲对象（源代码注释中写道：See if we can refill from the shared array），如果有则返回可用对象，refill结束——>从kmem_cache_node中的slab中获取空闲对象，有则返回，没有就执行下一步——>kmem_getpages()
```

释放小内存块：

当应用程序释放一个小内存块时，slab分配器将内存块标记为可用，并将其添加回对应的slab中。如果slab中的所有内存块都被释放，则将整个slab从链表中移除，并释放其内存回操作系统。

slab分配器通过维护内存块和slab之间的映射关系来实现高效的内存分配和释放。这种方式减少了频繁的malloc和free操作的开销，提高了内存分配效率。



### slab分配器中有一个着色的概念( cache color )，着色有什么作用?

同一硬件高速缓存行可以映射RAM中很多不同的内存块。相同大小的对象倾向于存放在硬件高速缓存内相同的偏移量处。在不同的SLAB内具有相同偏移量的度下行最终很有可能映射在同一硬件高速缓存行中。高速缓存的硬件可能因此而花费内存周期在同一高速缓存行与RAM内存单元之间来来往往传送这两个对象，而其他的硬件高速缓存行并未充分使用（以上语句出自《深入理解Linux内核》第三版第334页）。SLAB分配器为了降低硬件高速缓存的这种行为，采用了SLAB着色（slab coloring）的策略。所谓着色，简单来说就是给各个slab增加不同的偏移量，设置偏移量的过程就是着色的过程。通过着色尽量使得不同的对象对应到硬件不同的高速缓存行上，以最大限度的利用硬件高速缓存，提升系统效率。



### slab分配器中的slab对象有没有根据Per-CPU做一些优化？

是的，slab分配器中的slab对象根据Per-CPU进行了一些优化。这意味着每个CPU都有自己的本地cache，用于分配和释放slab对象，而不需要访问共享的全局数据结构。这样可以减少竞争和锁开销，提高了分配和释放的性能。此外，Per-CPU的优化还可以减少内存片段的分配和释放，提高内存的局部性，从而提高了缓存命中率和整体系统性能。

### 使用用户态的API函数malloc()分配内存时，会马上为其分配物理内存吗?

不一定。在使用用户态的API函数malloc()分配内存时，操作系统会在适当的时候为其分配物理内存。通常情况下，操作系统会在有需要的时候进行内存分配。这意味着尽管用户代码调用了malloc()函数来请求分配内存，但是实际的物理内存分配可能会被推迟到稍后的某个时间点。这是因为操作系统需要考虑内存的管理和调度，以便最大化利用内存资源。



### 假设不考虑libc的因素，malloc分配100Byte，那么实际上内核是为其分配100Byte吗?

实际上，malloc()函数分配的内存块可能会比请求的大小大一些。这是由于内存管理的需要和算法。例如，malloc()函数可能会在分配的内存块之前和之后添加一些额外的元数据信息，以便在释放内存时能够正确处理。此外，为了对齐内存和提高性能，一些系统可能会将分配的内存大小调整为内存分配单元的倍数。
具体来说，内核在为malloc分配内存时可能会分配大于100字节的内存，以满足对齐和元数据等需求。这个实际分配的大小可能会略微超过请求的大小，但不会显著增加。具体的行为可能因操作系统和配置而异。



### 假设两个用户进程打印的malloc()分配的虚拟地址是一样的，那么在内核中这两块虚拟内存是否打架了呢?

在理论上，两个用户进程打印的malloc()分配的虚拟地址是不会相同的。这是因为虚拟地址是每个进程独立的，并且由内核负责管理和分配的。不同的进程具有不同的虚拟地址空间，且每个进程的虚拟地址空间是相互隔离的。
然而，如果两个进程的虚拟地址相同，这可能是由于某种错误或者异常情况导致的。在这种情况下，在内核中可能会出现冲突或者竞争条件，导致内存访问错误、数据损坏或者程序崩溃等问题。
所以，两个进程的虚拟地址相同是不正常的，应该进行调查和修复。具体的解决方法可能因系统和上下文而异，可以考虑重新编译程序、检查进程间的隔离性、重新分配虚拟地址空间等。



###  为什么多级页表可以节省空间

- 二级页表的内存占用



做个简单的数学计算，假设虚拟地址空间为32位（即4GB）。

<img src="https://picx.zhimg.com/50/v2-c735fe62ca8684b83d94de95703a677c_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="429" data-rawheight="182" data-original-token="v2-c735fe62ca8684b83d94de95703a677c" data-default-watermark-src="https://pic1.zhimg.com/50/v2-e588f74ba5b0638692d8031c1f4799d1_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="429" data-original="https://picx.zhimg.com/v2-c735fe62ca8684b83d94de95703a677c_r.jpg?source=1940ef5c"/>

每个页面映射4KB以及每条页表项占4B：

- 一级页表：进程需要1M个页表项（4GB / 4KB = 1M, 2^20个页表项），即页表（每个进程都有一个页表）占用4MB（1M * 4B = 4MB）的内存空间。
- 二级页表：一级页表映射4MB（2^22）、二级页表映射4KB，则需要1K个一级页表项（4GB / 4MB = 1K, 2^10个一级页表项）、每个一级页表项对应1K个二级页表项（4MB / 4KB = 1K），这样页表占用4.004MB（1K * 4B + 1K * 1K * 4B = 4.004MB）的内存空间。

多级页表的内存空间占用反而变大了。





- 二级页表可以不存在

我们反过来想，每个进程都有4GB的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到4GB，何必去映射不可能用到的空间呢？也就是说，一级页表覆盖了整个4GB虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有20%的一级页表项被用到了，那么页表占用的内存空间就只有0.804MB（1K * 4B + 0.2 * 1K * 1K * 4B = 0.804MB），对比单级页表的4M是不是一个巨大的节约？那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在主存中的页表承担的职责是将虚拟地址翻译成物理地址；假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有1M个页表项来映射，而二级页表则最少只需要1K个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。



### linux内核中请简述get_user_page()函数的作用和实现流程。

在Linux内核中，get_user_page()函数的作用是从用户空间获取页框并将其映射到内核空间。

实现流程如下：

1. 首先，该函数会接收一个用户空间的虚拟地址（或用户空间的页表项）作为参数。
2. 然后，通过虚拟地址的页表项信息，获取相关的页框号（物理地址）。
3. 接着，通过页框号，通过调用相关的页框管理函数，来获取对应的物理内存页。
4. 最后，将获取到的物理页映射到内核空间中，并返回映射后的内核空间虚拟地址。

总结起来，get_user_page()函数在Linux内核中实现了从用户空间获取页框并将其映射到内核空间的功能



### linux内核中请简述follow_page()函数的作用的实现流程。

follow_page()函数的作用是根据给定的虚拟地址查找对应的Page Table 条目。实现流程如下：

1. 首先，follow_page()函数从当前CPU的页表基址（cr3寄存器）获取页表的起始地址，并将虚拟地址左移12位（偏移12位实际上是页内偏移的位数），然后将其加上页表基址，得到要访问的页面目录项的地址。
2. 然后，follow_page()函数从页面目录项的地址中读取该项的内容，即包含页面表的地址和一些控制位的值。如果页面目录项为空，即页面不存在，则返回NULL。
3. 如果页面目录项有效（非空），则继续计算页表的地址。先将页面目录项的内容进行掩码操作，提取出页表的基地址，并将虚拟地址的中间10位（对应于页表项的索引）左移3位（偏移3位实际上是页表项内偏移的位数），然后将其加上页表的基址，得到要访问的页表项的地址。
4. 接下来，follow_page()函数从页表项的地址中读取该项的内容，即包含物理页面的地址和一些控制位的值。如果页表项为空，即页表项对应的物理页面不存在，则返回NULL。
5. 如果页表项有效（非空），则将页表项的内容进行掩码操作，提取出物理页面的基地址，并将其与虚拟地址的低12位进行按位或操作，得到最终的物理地址。最后，返回物理地址。

需要注意的是，虚拟地址到物理地址的转换有多级页表的概念，不同的平台和版本可能有一些细节上的差异，但总体的实现流程是类似的。



### 请简述私有映射和共享映射的区别。

私有映射和共享映射是在计算机系统中用于分配内存的两种不同的方式。

私有映射是指在内存中为每个进程分配独立的虚拟内存空间。每个进程拥有自己独立的地址空间，这意味着它们不能直接访问其他进程的内存。私有映射保证了每个进程的数据的隔离性和安全性，一个进程无法修改或访问其他进程的私有映射。

相反，共享映射是指多个进程可以共享同一块内存区域。多个进程可以同时访问和修改共享映射的数据，这样可以提高进程间的通信效率。共享映射可以用于进程间的数据共享、进程间的同步和通信等。

总而言之，私有映射和共享映射的主要区别在于是否允许多个进程访问和修改同一块内存区域。私有映射为每个进程提供独立的地址空间，而共享映射允许多个进程共享同一块内存。



### 为什么第二次调用mmap时，Linux内核没有捕捉到地址重叠并返回失败呢?

在Linux中，第二次调用mmap时，Linux内核没有捕捉到地址重叠并返回失败的原因是，Linux内核默认情况下允许相同的文件映射到不同的内存区域，即允许多次映射同一个文件。这种情况下，即使两次映射的起始地址相同，内核也不会返回失败。

这个特性有一些实际应用。有时候，我们可能希望在同一进程中多次映射同一个文件，以便在不同的位置访问文件数据。此外，允许多次映射同一个文件还有助于共享内存和进程间通信。

但需要注意的是，如果要避免地址重叠的问题，我们可以使用MAP_FIXED标志来强制内核使用指定的地址。如果指定的地址已经被占用，内核会返回失败。所以如果你希望第二次调用mmap时，内核捕捉到地址重叠并返回失败，你可以在调用mmap时指定MAP_FIXED标志并指定一个尚未被使用的地址。



### struct page数据结构中的\_count和\_mapcount有什么区别?

在Linux内核中的struct page数据结构是用于描述物理页面的数据结构，通过这个结构体可以获取页面的各种信息。其中，\_count和\_mapcount是用于统计页面的引用计数的两个成员变量。

\_count表示页面的被引用次数，也就是有多少指针指向这个页面。当\_count为0时，表示该页面没有被引用，可以被释放。当页面被引用时，\_count会增加。

\_mapcount表示页面的映射计数，也就是有多少映射页表指向这个页面。当\_mapcount为0时，表示该页面没有被映射到任何虚拟地址空间中。当页面被映射到虚拟地址空间时，\_mapcount会增加。

可以看出，\_count主要用于统计页面的普通引用计数，即页面的指针引用个数；而\_mapcount主要用于统计页面的映射计数，即页面被映射到虚拟地址空间的次数。这两个计数可以互相独立地增加和减少，它们的和等于页面的总引用计数。



### 匿名页面和page cache页面有什么区别?

匿名页面和page cache页面是两种不同类型的页面。

匿名页面是指用于存储进程的栈、堆和全局数据等私有数据的页面。它们通常存储着进程的运行时状态信息。匿名页面没有对应的磁盘文件，只存在于内存中，所以也称为匿名内存。

相反，page cache页面是指用于缓存已读取的磁盘文件数据的页面。当程序需要访问某个文件的内容时，文件的数据会被读取到内存中，并被缓存在page cache中。这样，在后续访问该文件时，就可以直接从page cache中获取数据，而无需再次从磁盘读取。

因此，主要区别在于数据来源和存在形式。匿名页面的数据来自进程的私有数据，而page cache页面的数据来自磁盘文件。匿名页面仅存在于内存中，而page cache页面既可以存在于内存中，也可以存在于磁盘上。此外，匿名页面一般不会被其他进程访问，而page cache页面可以被其他进程共享。



### struct page数据结构中有一个锁，请问trylock_page()和 lock_page()有什么区别?

在Linux内核的struct page数据结构中，有一个用于保护页面的锁。trylock_page()和lock_page()是用于获取页面锁的两个函数，它们的区别如下：

1. trylock_page()是一个非阻塞的函数，用于尝试获取页面锁。如果获取成功，函数会返回0；如果页面已经被其他进程锁定，函数会立即返回一个非零值表示获取失败。trylock_page()适用于不希望被锁住的情况，例如读操作。
2. lock_page()是一个阻塞的函数，用于获取页面锁。如果页面已经被其他进程锁定，函数会将当前进程置于睡眠状态，直到页面锁可用并成功获取锁为止。lock_page()适用于需要独占访问页面的情况，例如写操作。

在使用trylock_page()和lock_page()时需要根据具体情况决定使用哪个函数。如果希望非阻塞地尝试获取页面锁，可以使用trylock_page()；如果希望在获取锁之前等待页面锁可用，可以使用lock_page()。



### ARM64进程虚拟空间有多大？

在Arm64架构下，每个进程的虚拟大小通常是相当大的，可以达到128TB（特例除外）。这是由于Arm64架构使用了48位的虚拟地址空间，其中47位用于用户空间，1位用于内核空间。虚拟地址空间的大小由2^47决定，即128TB。

然而，需要注意的是，虚拟地址空间的大小并不表示实际可用内存的大小。进程的实际可用内存受到多种因素的限制，包括物理内存大小、虚拟内存管理机制、操作系统的限制等等。一般情况下，进程的实际可用虚拟内存空间会根据需要进行动态分配，而不是预先分配整个128TB的空间。具体的虚拟内存大小取决于操作系统的设置和硬件的支持能力。



### 在Linux 2.4.x内核中，如何从一个 page找到所有映射该页面的VMA?反向映射可以带来哪些便利?

在Linux 2.4.x内核中，可以通过vm_normal_page()函数从一个page找到所有映射该页面的VMA。这个函数会返回VMA的指针。

反向映射可以带来以下便利：

1. 查找页面的映射：通过反向映射，可以很容易地找到一个物理页面在虚拟地址空间中的映射情况。这对于进行页面管理和内存分配非常有用。

2. 统计页面引用：反向映射表可以用来统计一个页面有多少个VMA映射，这对于性能分析和内存使用统计很有帮助。

3. 页面迁移：反向映射可以在页面迁移过程中提供必要的信息。在进行页面迁移时，需要知道一个页面所有的映射，以便正确地更新映射关系。

总的来说，反向映射提供了一种管理和使用虚拟内存的便利方式，可以更高效地进行内存管理和页面迁移。



### 阅读Linux 4.0内核RMAP机制的代码，画出父子进程之间VMA、AVC、anon_vma和page等数据结构之间的关系图。

Linux 2.6.34内核对RMAP反向映射系统进行了优化、模型和现在 Linux 4.0内核中的模型相似，如图2.26所示，新增加了AVC数据结构( struct anon_vma_chain)，父进程和子进程都有各自的AV数据结构且都有一棵红黑树〈简称AV红黑树)，此外，父进程和子进程都有各自的AVC挂入进程的AV红黑树中。还有一个AVC作为纽带来联系父进程和子进程，我们暂且称它为AVC枢纽。AVC枢纽挂入父进程的AV红黑树中，因此所有子进程都有一个AVC枢纽用于挂入父进程的AV红黑树。需要反向映射遍历时，只需要扫描父进程中的AV红黑树即可。当子进程VMA发生 COW时，新分配的匿名页面 cow_page->mapping 指向子进程自己的AV数据结构，而不是指向父进程的AV数据结构，因此在反向映射遍历时不需要扫描所有的子进程。

![image](https://img2023.cnblogs.com/blog/811006/202310/811006-20231030202724934-587793041.jpg)



### kswapd内核线程何时会被唤醒?

分配内存时，当在zone的WMARK_LOW水位分配失败时，会去唤醒kswapd 内核线程来回收页面。



### 当 page加入 lru链表中，被其他线程释放了这个 page，那么lru链表如何知道这个page已经被释放了?

当一个page被其他线程释放后，通常会通过一些方式通知LRU链表（或者管理该page的数据结构）该page已经被释放了。具体的实现方式可能因操作系统和应用程序的不同而有所不同，下面是一些可能的实现方式：

1.  直接通知：释放page的线程可以直接通知LRU链表，告知该page已经被释放。这可以通过函数调用、消息传递等方式实现。
2.  标记位：在page或其他管理该page的数据结构中，设置一个标记位，用于表示该page是否已经被释放。当其他线程尝试访问该page时，可以先检查该标记位，如果已经被释放，则可以从LRU链表中移除该page。
3.  引用计数：在page或其他管理该page的数据结构中，维护一个引用计数。当page被其他线程释放时，引用计数减少。LRU链表在访问page时，首先检查引用计数，如果计数为零，则可以从LRU链表中移除该page。


通过上述方式，LRU链表可以检测到该page的释放，从而避免继续操作已被释放的page。具体实现方式可能因操作系统和应用程序的不同而有所不同，建议查阅相关文档或资料来了解具体的实现细节。



### LRU链表如何知道page的活动频繁程度?

LRU链表按照先进先出的逻辑，页面首先进入LRU 链表头，然后慢慢挪动到链表尾，这有一个老化的过程。另外，page 中有PG_reference/PG_active标志位和页表的PTE YOUNG位来实现第二次机会法。



### kswapd按照什么原则来换出页面?

页面在活跃LRU链表，需要从链表头到链表尾的一个老化过程才能迁移到不活跃LRU链表。在不活跃LRU链表中又经过一个老化过程后，首先剔除那些脏页面或者正在回写的页面,然后那些在不活跃LRU链表老化过程中没有被访问引用的页面是最佳的被换出的候选者，具体请看shrink_page_list()函数。



### kswapd 以什么标准来退出扫描LRU?

kswapd 是 Linux 内核中的一个守护进程，用于在系统内存紧张时进行页面换出。它不负责退出扫描 LRU（Least Recently Used，最近最少使用）队列，而是负责扫描 LRU 并决定哪些页面应该被换出以释放内存。在 Linux 内核中，kswapd 进程使用一系列算法来决定页面是否应该被换出，这些算法包括但不限于以下几个标准：

1.  页面是否被频繁访问：如果一个页面在最近的时间段内被频繁访问，kswapd 将优先选择其他不频繁访问的页面进行换出。
2.  页面是否属于脏页（Dirty Pages）：脏页是指被修改过但还没有写回到磁盘的页面。kswapd 倾向于将脏页换出，以确保数据的一致性。
3.  页面是否属于匿名页（Anonymous Pages）：匿名页是指不映射到任何磁盘文件的页面，常见于进程的堆栈、堆内存等。kswapd 倾向于将匿名页换出，因为它们可以从其他进程的内存中重新分配而不需要从磁盘中读取。
4.  页面是否被锁住：如果一个页面被锁住（例如，被其他进程持有引用），kswapd 将尝试换出其他可更容易释放的页面。
5.  页面的使用频率：kswapd 会根据页面在 LRU 队列中的位置和使用频率来判断页面是否应该被换出，通常会选择较久没有被使用的页面进行换出。


这些标准是根据内核的使用经验以及系统负载情况来决定的，并且可以通过调整内核参数进行配置。不同的系统和内核版本可能会有不同的算法和标准。



### swappiness的含义是什么? kswapd如何计算匿名页面和page cache之间的扫描比重?

swappiness是一个系统参数，用来控制内核在内存紧张时，选择使用交换空间（swap space）还是丢弃缓存页（page cache）。
kswapd是Linux内核中的一个守护进程，负责在内存不足时触发页回收并将页面移动到交换空间。kswapd通过计算匿名页面和page cache之间的扫描比重来确定页回收的优先级。
具体计算方法如下：

1.  kswapd会先评估当前系统的内存压力，如果内存使用率很低，就不会触发页回收。
2.  kswapd会按照一个固定的时间间隔去扫描整个LRU（Least Recently Used）链表，该链表保存了最近访问的页面。
3.  在扫描链表过程中，kswapd会计算匿名页面和page cache之间的比重。匿名页面是指一些进程堆栈、匿名映射等页面，而page cache是指被缓存的文件页面。
4.  kswapd会根据比重决定回收哪一种页面。如果匿名页面比重较高，就会优先回收匿名页面，并将它们移到交换空间。如果page cache比重较高，就会优先回收page cache，并释放内存。

通过调整swappiness参数可以改变匿名页面和page cache之间的扫描比重，从而影响页回收的优先级。值得注意的是，swappiness的取值范围是0到100，其中0表示避免使用交换空间，而100表示尽量使用交换空间。中间的取值则表示两者之间的权衡。



### 当系统充斥着大量只访问一次的文件访问（ use-one streaming IO)时，kswapd 如何来规避这种风暴?

kswapd 是 Linux 系统中的一个守护进程，用于管理虚拟内存的换页操作。当系统内存不足时，kswapd 会将一些不常用的页面从内存中交换到磁盘上，以释放更多的内存供其他进程使用。
当系统充斥着大量只访问一次的文件访问时，这可能导致大量的文件页面被加载到内存中，而这些页面在后续的访问中几乎不会被再次使用。这会导致内存中出现大量的不常用页面，而 kswapd 会频繁地将这些页面交换到磁盘上，造成 I/O 压力过大，也称为 "IO 风暴"。
为了规避这种风暴，可以进行以下操作：

1.  调整虚拟内存策略：可以调整 Linux 内核的虚拟内存参数，让系统更加智能地处理这种场景。例如，可以调整页面调度算法，优先选择常用的页面放入内存中。
2.  增加内存：增加系统的物理内存可以减少对交换空间的需求，从而减轻 kswapd 的工作负载。
3.  调整文件缓存策略：可以调整文件系统的缓存策略，例如通过调整内核参数来限制对文件的缓存，减少不必要的文件加载操作。
4.  优化文件访问模式：可以通过优化应用程序的文件访问模式来减少不必要的文件加载。例如，可以将一些只访问一次的文件加载改为按需加载。


综上所述，通过调整虚拟内存和文件缓存策略，以及优化文件访问模式，可以减轻 kswapd 的工作负载，并规避大量只访问一次的文件访问带来的 "IO 风暴"。



### 在回收page cache时，对于dirty的 page cache，kswapd会马上回写吗?

不一定。kswapd是一个守护进程，负责回收不活跃的页缓存并释放内存。当kswapd发现有dirty的页缓存时，它会将这些页面标记为"clean"，这意味着它们将在稍后的时间点进行回写。回写是由后台的页写入进程或通过调用sync操作来触发的。因此，kswapd并不会立即回写dirty的页缓存。



### 内核有哪些页面会被kswapd 写回交换分区?

kswapd是Linux内核中的一个守护进程，负责处理内存压力情况下的内存回收和交换分区写回的任务。当系统内存不足时，kswapd会将不常用的页框（页面）移出物理内存，写回到交换分区（swap partition）以释放内存空间给其他进程使用。具体来说，任何被标记为可交换（swapable）的页面都有可能被kswapd写回到交换分区。这包括不活跃的页、未修改过的文件页和匿名页等。需要注意的是，只有在具有交换分区的系统中才会进行交换分区的写回。



### ARM32 Linux如何模拟这个Linux版本的L_PTE_YOUNG比特位呢?

在ARM32架构中，要模拟L_PTE_YOUNG比特位，需要通过设置相应的页表项来实现。以下是一个示例代码：

```
#include <stdio.h>
#include <stdint.h>
#include <unistd.h>
#include <sys/mman.h>
#define PTE_YOUNG_MASK (1 << 4)  // L_PTE_YOUNG比特位
int main() {
    uintptr_t addr = (uintptr_t) mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
    if (addr == (uintptr_t) MAP_FAILED) {
        perror("mmap failed");
        return -1;
	}
    uintptr_t pte = *(uintptr_t *) (addr & ~4095);  // 获取页表项的地址
    // 设置L_PTE_YOUNG比特位
    pte |= PTE_YOUNG_MASK;
    // 将修改后的页表项写回
    *(uintptr_t *) (addr & ~4095) = pte;
    printf("L_PTE_YOUNG bit simulated.\n");
    return 0;
}
```

在这个示例代码中，首先使用mmap函数分配一个4KB的内存页，并获取该地址所对应的页表项。然后将L_PTE_YOUNG比特位设置为1，最后将修改后的页表项写回到内存中。
需要注意的是，这段代码需要在特权模式下运行，因为ARM32 Linux系统的页表只能在特权模式下进行修改。



### 如何理解Refault Distance算法?

Linux的内存回收Refault Distance算法是一种用于管理和回收操作系统内存的算法。它基于Refault Distance（重故障距离）的概念，通过衡量页框在内存中的位置和使用情况，来确定最佳的内存回收策略。

该算法使用了Page Frame（页框）的访问频率和使用频率，通过统计每个页框的读取和写入次数，来计算Refault Distance。Refault Distance表示一个页框在内存中离被访问的最远距离，如果某个页框的Refault Distance较小，表示该页框被访问的频率较高，是活跃的页框，不应该被回收。相反，如果某个页框的Refault Distance较大，表示该页框很久没有被访问，可以考虑回收该页框来节省内存空间。

通过计算每个页框的Refault Distance，并根据一定的策略和阈值来决定是否回收该页框，从而实现内存的动态回收和管理。该算法可以提高内存的利用率，减少内存碎片，优化系统性能。

需要注意的是，Refault Distance算法只是内存回收的一部分，Linux系统还有其他的内存管理策略和算法，如LRU（最近最少使用）算法、页面置换算法等，这些算法共同工作，保证了系统的内存正常运行和优化。



### 请简述匿名页面的生命周期。在什么情况下会产生匿名页面?在什么条件下会释放匿名页面?

在Linux中，"Anonymous Page"是一种特殊的内存映射页面，用于存储进程运行过程中的临时数据。下面是Linux匿名页面的生命周期及相关情况：

-   创建匿名页面：当进程需要动态分配堆内存、栈空间或使用进程间通信机制时，系统会创建相应的"Anonymous Page"。
-   分配内存空间：系统为进程分配一块实际内存空间，用于存储"Anonymous Page"的数据。
-   使用和修改数据：进程可以通过访问"Anonymous Page"来读取和修改其中的数据，进行相应的数据操作。
-   不再需要页面：当进程不再需要"Anonymous Page"中存储的临时数据时，可以主动释放相关内存空间，通过释放内存空间来释放匿名页面。
-   进程退出：当进程结束时，系统会回收该进程使用的所有资源，包括"Anonymous Page"。此时，"Anonymous Page"会被释放。


总结来说，在Linux中，"Anonymous Page"是一种用于存储进程临时数据的内存页面，它的生命周期包括创建、分配和使用数据，以及释放和回收内存空间。"Anonymous Page"的主要产生情况是动态分配堆内存、栈空间分配和进程间通信，而释放匿名页面的条件包括不再需要页面和进程退出。



### KSM是基于什么原理来合并页面的?

KSM（Kernel Samepage Merging）是基于写时复制（Copy-on-Write）原理来合并页面的。写时复制是一种延迟复制的策略，它使得在进行页面合并时，只有在修改页面内容时才会进行实际的拷贝，而在不需要修改页面内容时，多个进程可以共享同一个页面。这样可以节省内存空间的使用，并提高系统的性能。KSM通过比较多个进程间的内存页面，找到内容相同的页面，并将它们合并为同一个页面，从而减少内存的使用。



### 在KSM机制里，合并过程中把page设置成写保护的函数 write_protect_page()有这样一个判断: `if(page_mapcount(page)+ 1 + swapped !=page_count(page)) ``{`	`goto out_unlock;}`

### 请问这个配置的依据是什么?

这是根据KSM机制的要求进行配置的。KSM机制通过合并相同的内存页来节省内存空间。在合并过程中，首先需要判断页的写保护状态，如果页已经被写保护，则不会进行合并操作。因此，该函数中的判断语句是用来确保页的写保护状态，以避免错误的合并操作。具体来说，判断语句中的条件是要求“页的映射计数+1+被交换的页数”等于“页的计数器”，即确保没有其他进程正在访问该页。如果不满足这个条件，那么当前页将不会被设置为写保护状态，并会跳转到代码标签“out_unlock”处，即取消写保护，确保实现正确的合并操作。



### 如果多个VMA 的虚拟页面同时映射了同一个匿名页面，那么此时page->index应该等于多少?

如果多个VMA的虚拟页面同时映射了同一个匿名页面，此时page->index应该是相同的。在Linux内核中，每个虚拟页面都有一个唯一的索引值，用于标识该页面在全局页面表中的位置。当多个VMA共享同一个匿名页面时，它们共享的是同一个索引值，因此page->index的值应该是相同的。



### 为什么Dirty COW小程序可以修改一个只读文件的内容?

Dirty COW小程序可以修改一个只读文件的内容，是因为Dirty COW（Copy-on-Write）是一个操作系统内核的漏洞，它允许攻击者获取对只读文件的写入权限。攻击者首先通过exploit程序在内核中构建一个悬空的内存映射，然后使用特定的方式修改该内存映射的权限，使其可写。一旦内存映射变为可写，攻击者就可以修改只读文件的内容。因此，Dirty COW漏洞允许攻击者绕过只读属性，对文件内容进行修改。
