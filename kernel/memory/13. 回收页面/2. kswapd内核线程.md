Linux内核中有一个非常重要的内核线程kswapd，负责在内存不足的情况下回收页面。
    kswapd内核线程初始化时会为系统中每个NUMA内存节点创建一个名为“kswapd%d”的内核线程。

```
[kswapd_init()->kswapd_run()]
int kswapd_run(int nid)
{
	pg_data_t *pgdat = NODE_DATA(nid);
	int ret = 0;

	if (pgdat->kswapd)
		return 0;

	pgdat->kswapd = kthread_run(kswapd, pgdat, "kswapd%d", nid);
	if (IS_ERR(pgdat->kswapd)) {
		/* failure at boot is fatal */
		BUG_ON(system_state == SYSTEM_BOOTING);
		pr_err("Failed to start kswapd on node %d\n", nid);
		ret = PTR_ERR(pgdat->kswapd);
		pgdat->kswapd = NULL;
	}
	return ret;
}
```

在NUMA系统中，每个node节点有一个pg_data_t数据结构来描述物理内存的布局。pg_data_t数据结构定义在include/linux/mmzone.h头文件中，kswapd传递的参数就是pg_data_t数据结构。

```
typedef struct pglist_data {
	struct zone node_zones[MAX_NR_ZONES];
	struct zonelist node_zonelists[MAX_ZONELISTS];
	int nr_zones;
#ifdef CONFIG_FLAT_NODE_MEM_MAP	/* means !SPARSEMEM */
	struct page *node_mem_map;
#ifdef CONFIG_PAGE_EXTENSION
	struct page_ext *node_page_ext;
#endif
#endif
#ifndef CONFIG_NO_BOOTMEM
	struct bootmem_data *bdata;
#endif
#ifdef CONFIG_MEMORY_HOTPLUG
	/*
	 * Must be held any time you expect node_start_pfn, node_present_pages
	 * or node_spanned_pages stay constant.  Holding this will also
	 * guarantee that any pfn_valid() stays that way.
	 *
	 * pgdat_resize_lock() and pgdat_resize_unlock() are provided to
	 * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG.
	 *
	 * Nests above zone->lock and zone->span_seqlock
	 */
	spinlock_t node_size_lock;
#endif
	unsigned long node_start_pfn;
	unsigned long node_present_pages; /* total number of physical pages */
	unsigned long node_spanned_pages; /* total size of physical page
					     range, including holes */
	int node_id;
	wait_queue_head_t kswapd_wait;
	wait_queue_head_t pfmemalloc_wait;
	struct task_struct *kswapd;	/* Protected by
					   mem_hotplug_begin/end() */
	int kswapd_max_order;
	enum zone_type classzone_idx;
#ifdef CONFIG_NUMA_BALANCING
	/* Lock serializing the migrate rate limiting window */
	spinlock_t numabalancing_migrate_lock;

	/* Rate limiting time interval */
	unsigned long numabalancing_migrate_next_window;

	/* Number of pages migrated during the rate limiting time interval */
	unsigned long numabalancing_migrate_nr_pages;
#endif
} pg_data_t;
```

和kswapd相关的参数有kswapd_max_order、kswapd_wait 和classzone_idx等。kswapd_wait 是一个等待队列，每个pg_data_t数据结构都有这样一个等待队列，它是在free_area_init_core()函数中初始化的。

页面分配路径上的唤醒函数 wakeup_kswapd()把kswapd_max_order和classzone_idx作为参数传递给kswapd内核线程。

在分配内存路径上，如果在低水位（ALLOC_WMARK_LOW）的情况下无法成功分配内存，那么会通过wakeup_kswapd()函数唤醒kswapd内核线程来回收页面，以便释放一些内存。

wakeup_kswapd()函数定义在mm/vmscan.c文件中。

```
[alloc_page()->alloc_pages_nodemask()->_alloc pages_slowpath()->wake_all_kswapds()]
void wakeup_kswapd(struct zone *zone, int order, enum zone_type classzone_idx)
{
	pg_data_t *pgdat;

	if (!populated_zone(zone))
		return;

	if (!cpuset_zone_allowed(zone, GFP_KERNEL | __GFP_HARDWALL))
		return;
	pgdat = zone->zone_pgdat;
	if (pgdat->kswapd_max_order < order) {
		pgdat->kswapd_max_order = order;	//其中kswapd_max_order不能小于alloc_page()分配内存的order,
		pgdat->classzone_idx = min(pgdat->classzone_idx, classzone_idx); //classzone_idx是在__alloc_pages_nodemask()函数中计算第一个最合适分配内存的zone序号
	}
	if (!waitqueue_active(&pgdat->kswapd_wait))
		return;
	if (zone_balanced(zone, order, 0, 0))
		return;

	trace_mm_vmscan_wakeup_kswapd(pgdat->node_id, zone_idx(zone), order);
	wake_up_interruptible(&pgdat->kswapd_wait);
}
```

这里需要赋值kswapd_max_order和classzone_idx。这两个参数会传递到kswapd内核线程中。

classzone_idx 是理解页面分配器和页面回收kswapd内核线程之间如何协同工作的一个关键点。

假设以GFP_HIGHUSER_MOVABLE为分配掩码分配内存，以在_alloc_pages_nodemask()->first_zones_zonelist()中计算出来的preferred_zone为ZONE_HIGHMEM，那么 ac.classzone_idx的值为1，详见第2.4.1节。当内存分配失败时，页面分配器会唤醒 kswapd 内核线程，并且传递ac.claszone_idx值到kswapd内核线程，最后传递给balance_pgdat() 函数的classzone_idx参数。

```
struct page *
__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order,
{
	...
	struct alloc_context ac = {
		.high_zoneidx = gfp_zone(gfp_mask),
		.nodemask = nodemask,
		.migratetype = gfpflags_to_migratetype(gfp_mask),
	};
	...
	ac.zonelist = zonelist;
	preferred_zoneref = first_zones_zonelist(ac.zonelist, ac.high_zoneidx,
				ac.nodemask ? : &cpuset_current_mems_allowed,
				&ac.preferred_zone);
	ac.classzone_idx = zonelist_zone_idx(preferred_zoneref);
	...
}
static inline struct page *
__alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
						struct alloc_context *ac)
{
....
retry:
	if (!(gfp_mask & __GFP_NO_KSWAPD))
		wake_all_kswapds(order, ac);
....
}
```

kswapd内核线程的执行函数如下：

```
static int kswapd(void *p)
{
	unsigned long order, new_order;
	unsigned balanced_order;
	int classzone_idx, new_classzone_idx;
	int balanced_classzone_idx;
	pg_data_t *pgdat = (pg_data_t*)p;
	struct task_struct *tsk = current;
	order = new_order = 0;
	balanced_order = 0;
	classzone_idx = new_classzone_idx = pgdat->nr_zones - 1;
	balanced_classzone_idx = classzone_idx;
	for ( ; ; ) {
		bool ret;

		/*
		 * If the last balance_pgdat was unsuccessful it's unlikely a
		 * new request of a similar or harder type will succeed soon
		 * so consider going to sleep on the basis we reclaimed at
		 */
		if (balanced_classzone_idx >= new_classzone_idx &&
					balanced_order == new_order) {
			new_order = pgdat->kswapd_max_order;
			new_classzone_idx = pgdat->classzone_idx;
			pgdat->kswapd_max_order =  0;
			pgdat->classzone_idx = pgdat->nr_zones - 1;
		}

		if (order < new_order || classzone_idx > new_classzone_idx) {
			/*
			 * Don't sleep if someone wants a larger 'order'
			 * allocation or has tigher zone constraints
			 */
			order = new_order;
			classzone_idx = new_classzone_idx;
		} else {
			kswapd_try_to_sleep(pgdat, balanced_order,
						balanced_classzone_idx);	//系统启动时会在kswapd_try_to _sleep()函数中睡眠并且让出CPU控制权。
			order = pgdat->kswapd_max_order;
			classzone_idx = pgdat->classzone_idx;
			new_order = order;
			new_classzone_idx = classzone_idx;
			pgdat->kswapd_max_order = 0;
			pgdat->classzone_idx = pgdat->nr_zones - 1;
		}

		ret = try_to_freeze();
		if (kthread_should_stop())
			break;

		/*
		 * We can speed up thawing tasks if we don't call balance_pgdat
		 * after returning from the refrigerator
		 */
		if (!ret) {
			trace_mm_vmscan_kswapd_wake(pgdat->node_id, order);
			balanced_classzone_idx = classzone_idx;
			balanced_order = balance_pgdat(pgdat, order,
						&balanced_classzone_idx);
		}
	}
	
	tsk->flags &= ~(PF_MEMALLOC | PF_SWAPWRITE | PF_KSWAPD);
	...
	return 0;
}
```

函数的核心部分集中在上述代码的for循环中。这里有很多的局部变量来控制程序的走向，其中最重要的变量是在前文介绍过的kswapd_max_order和classzone_idx。当系统内存紧张时，例如alloc_pages()在低水位（ALLOC_WMARK_LOW）中无法分配出内存，这时分配内存函数会调用wakeup_kswapd()来唤醒kswapd内核线程。kswapd内核线程初始化时会在kswapd_try_to_sleep()函数中睡眠，唤醒点在kswapd_try_to_sleepO函数中。kswapd内核线程被唤醒之后，调用balance_pgdat()来回收页面。调用逻辑如下：

```
alloc_pages:
    __alloc_pages_nodemask() 
    ->If fail on ALLOC_WMARK_LOW 
    ->alloc_pages_slowpath() 
    ->wakeup_kswapd() 
    ->wake_up(kswapd_wait) 
    	kswapd内核线程被唤醒 ->balance pgdat()
```

