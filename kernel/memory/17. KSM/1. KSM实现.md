KSM在初始化时会创建一个名为“ksmd”的内核线程。

```
[mm/ksm.c]

static int __init ksm_init(void)
{
	struct task_struct *ksm_thread;
	int err;

	err = ksm_slab_init();
	if (err)
		goto out;

	ksm_thread = kthread_run(ksm_scan_thread, NULL, "ksmd");
	if (IS_ERR(ksm_thread)) {
		pr_err("ksm: creating kthread failed\n");
		err = PTR_ERR(ksm_thread);
		goto out_free;
	}

#ifdef CONFIG_SYSFS
	err = sysfs_create_group(mm_kobj, &ksm_attr_group);
	if (err) {
		pr_err("ksm: register sysfs failed\n");
		kthread_stop(ksm_thread);
		goto out_free;
	}
#else
	ksm_run = KSM_RUN_MERGE;	/* no way for user to start it */

#endif /* CONFIG_SYSFS */

#ifdef CONFIG_MEMORY_HOTREMOVE
	/* There is no significance to this priority 100 */
	hotplug_memory_notifier(ksm_memory_callback, 100);
#endif
	return 0;

out_free:
	ksm_slab_free();
out:
	return err;
}
```

KSM只会处理通过madvise系统调用显式指定的用户进程空间内存，因此用户程序想使用这个功能就必须在分配内存时显式地调用“madvise(addr,length,MADV_MERGEABLE)”，如果用户想在KSM中取消某一个用户进程地址空间的合并功能，也需要显式地用“madvise(addr,length,MADV_UNMERGEABLE)"。

在Android系统中，在libc库（Android系统的libc库是bionic)中的mmap函数实现已经默认添加了此功能。

```
static bool kernel has MADV_MERGEABLE=true;
void* mmap64(void* addr,sizet size,int prot,int flags,int fd,off64_t offset){
	bool is private anonymous=(flags & (MAP_PRIVATE |MAP_ANONYMOUS))!=0; 
	void* result=mmap2(addr,size,prot,flags,fd,offset >>MMAP2_SHIFT); 
	if(result!=MAP FAILED && kernel has MADV MERGEABLE && is_private_anonymous
	{
		int rc =madvise(result,size,MADV_ MERGEABLE); 
		if (rc==-1 && errno==EINVAL){ 
			kernel_has_MADV_MERGEABLE=false;
		}
	}
    return result;
}
void* mmap(void* addr,size t size,int prot,int flags,int fd,off_t offset){
	return mmap64(addr,size,prot,flags,fd,static_cast<off64_t>((unsigned 1ong)offset));
}
    
```

第5-11行，判断mmap分配的内存，即进程用户空间地址是否私有映射（MAP_PRIVATE）或者匿名映射（MAP_ANONYMOUS），如果是，则显式调用madivese系统把进程用户空间地址区间添加到Linux内核KSM系统中。

```
int __ksm_enter(struct mm_struct *mm)
{
	struct mm_slot *mm_slot;
	int needs_wakeup;

	mm_slot = alloc_mm_slot();
	if (!mm_slot)
		return -ENOMEM;

	/* Check ksm_run too?  Would need tighter locking */
	needs_wakeup = list_empty(&ksm_mm_head.mm_list);

	spin_lock(&ksm_mmlist_lock);
	insert_to_mm_slots_hash(mm, mm_slot);
	/*
	 * When KSM_RUN_MERGE (or KSM_RUN_STOP),
	 * insert just behind the scanning cursor, to let the area settle
	 * down a little; when fork is followed by immediate exec, we don't
	 * want ksmd to waste time setting up and tearing down an rmap_list.
	 *
	 * But when KSM_RUN_UNMERGE, it's important to insert ahead of its
	 * scanning cursor, otherwise KSM pages in newly forked mms will be
	 * missed: then we might as well insert at the end of the list.
	 */
	if (ksm_run & KSM_RUN_UNMERGE)
		list_add_tail(&mm_slot->mm_list, &ksm_mm_head.mm_list);
	else
		list_add_tail(&mm_slot->mm_list, &ksm_scan.mm_slot->mm_list);
	spin_unlock(&ksm_mmlist_lock);

	set_bit(MMF_VM_MERGEABLE, &mm->flags);
	atomic_inc(&mm->mm_count);

	if (needs_wakeup)
		wake_up_interruptible(&ksm_thread_wait);

	return 0;
}
```

第6行代码,分配一个 struct mm_slot数据结构。

第13行代码,添加管理 ksm_mmlist链表的 spinlock锁

第14行代码,把当前的mm数据结构添加到mm_slots_hash哈希表中。

第25-28行代码,把 mm slot添加到 ksm_scan_mm slot-> mm_list链表中。

第31行代码,设置mm->fags中的 MMF_VM_MERGEABLE标志位,表示这个进程已经添加到KSM系统中。

第34~35行代码,如果之前 ksm_mm_head.mm_list链表为空,则唤醒ksmd内核线程。

```
[ksmd内核线程]
static int ksm_scan_thread(void *nothing)
{
	set_freezable();
	set_user_nice(current, 5);

	while (!kthread_should_stop()) {
		mutex_lock(&ksm_thread_mutex);
		wait_while_offlining();
		if (ksmd_should_run())
			ksm_do_scan(ksm_thread_pages_to_scan);
		mutex_unlock(&ksm_thread_mutex);

		try_to_freeze();

		if (ksmd_should_run()) {
			schedule_timeout_interruptible(
				msecs_to_jiffies(ksm_thread_sleep_millisecs));
		} else {
			wait_event_freezable(ksm_thread_wait,
				ksmd_should_run() || kthread_should_stop());
		}
	}
	return 0;
}
```

ksm_scan_thread是ksmd内核线程的主干,每次会执行 ksm_do_scan()函数去扫描和合并100个页面(见 ksm_thread_pages_to_scan变量),然后睡眠等待20毫秒(见 ksm_thread_sleepmillisecs变量),这两个参数可以在“/ sys/kernel/mm/ksm”目录下的相关参数中去设置和修改。

```
[ksmd内核线程]
static void ksm_do_scan(unsigned int scan_npages)
{
	struct rmap_item *rmap_item;
	struct page *uninitialized_var(page);

	while (scan_npages-- && likely(!freezing(current))) {
		cond_resched();
		rmap_item = scan_get_next_rmap_item(&page);
		if (!rmap_item)
			return;
		cmp_and_merge_page(page, rmap_item);
		put_page(page);
	}
}
```

ksm_do_scan()函数在 while循环中尝试去合并 scan_npages个页面, scan_get_next_rmap_item()获取一个合适的匿名页面page, cmp_and_merge_page()会让page 在在KSM中的stable和unstable 两棵红黑树中查找是否有合适合并的对象,并且尝试去合并它们。下面首先来看KSM的核心数据结构。

```
[mm/ksm.c]
struct rmap_item {
	struct rmap_item *rmap_list;
	union {
		struct anon_vma *anon_vma;	/* when stable */
#ifdef CONFIG_NUMA
		int nid;		/* when node of unstable tree */
#endif
	};
	struct mm_struct *mm;
	unsigned long address;		/* + low bits used for flags below */
	unsigned int oldchecksum;	/* when unstable */
	union {
		struct rb_node node;	/* when node of unstable tree */
		struct {		/* when listed from stable tree */
			struct stable_node *head;
			struct hlist_node hlist;
		};
	};
};

struct mm_slot {
	struct hlist_node link;
	struct list_head mm_list;
	struct rmap_item *rmap_list;
	struct mm_struct *mm;
};

struct ksm_scan {
	struct mm_slot *mm_slot;
	unsigned long address;
	struct rmap_item **rmap_list;
	unsigned long seqnr;
};
```

rmap_item 数据结构描述一个虚拟地址反向映射的条目(item)。

- rmap_list:所有的rmap_item连接成一个链表,链表头在ksm_scan.rmap_list中。
- anon_vma:当rmap_item加入stable树时，指向VMA的anon_vma数据结构。
- mm:进程的struct mm_struct数据结构。
- address: rmap_item所跟踪的用户空间地址，
- oldchecksum:虚拟地址对应的物理页面的旧校验值。
- node: rmap_item加入unstable红黑树的节点。
- head:加入stable红黑树的节点。
- hlist: stable链表。

mmslot数据结构描述添加到KSM系统中将要被扫描的进程mm struct数据结构。

- link:用于添加到mm_slot哈希表中。
- mm_list:用于添加到mm_slot链表中，银链表头在ksm_mm_head。
- rmap_list: rmap_item链表头。
- mm:进程的mm数据结构。

ksm_scan数据结构用于表示当前扫描的状态。

- mm_slot:当前正在扫描的mm_slot。
- address:下一次扫描地址。
- rmap_list:将要扫描rmap_item的指针。
- seqnr:全部扫描完成后会计数一次，用于删除 unstable节点。

```
[mm/ksm.c]
static struct mm_slot ksm_mm_head = {
	.mm_list = LIST_HEAD_INIT(ksm_mm_head.mm_list),
};
static struct ksm_scan ksm_scan = {
	.mm_slot = &ksm_mm_head,
};
```

ksm_mm_head是mm_slot链表的头。ksm_scan是静态全局的数据结构，用于描述当前扫描的 mm_slot.

下面来看ksm_do_scan()中scan_get_next_map_item()函数的实现。

```
[ksm_do_scan()->scan_get_next_rmap_item()]
static struct rmap_item *scan_get_next_rmap_item(struct page **page)
{
	struct mm_struct *mm;
	struct mm_slot *slot;
	struct vm_area_struct *vma;
	struct rmap_item *rmap_item;
	int nid;

	if (list_empty(&ksm_mm_head.mm_list))
		return NULL;

	slot = ksm_scan.mm_slot;
	if (slot == &ksm_mm_head) {
		/*
		 * A number of pages can hang around indefinitely on per-cpu
		 * pagevecs, raised page count preventing write_protect_page
		 * from merging them.  Though it doesn't really matter much,
		 * it is puzzling to see some stuck in pages_volatile until
		 * other activity jostles them out, and they also prevented
		 * LTP's KSM test from succeeding deterministically; so drain
		 * them here (here rather than on entry to ksm_do_scan(),
		 * so we don't IPI too often when pages_to_scan is set low).
		 */
		lru_add_drain_all();

		/*
		 * Whereas stale stable_nodes on the stable_tree itself
		 * get pruned in the regular course of stable_tree_search(),
		 * those moved out to the migrate_nodes list can accumulate:
		 * so prune them once before each full scan.
		 */
		if (!ksm_merge_across_nodes) {
			struct stable_node *stable_node;
			struct list_head *this, *next;
			struct page *page;

			list_for_each_safe(this, next, &migrate_nodes) {
				stable_node = list_entry(this,
						struct stable_node, list);
				page = get_ksm_page(stable_node, false);
				if (page)
					put_page(page);
				cond_resched();
			}
		}

		for (nid = 0; nid < ksm_nr_node_ids; nid++)
			root_unstable_tree[nid] = RB_ROOT;

		spin_lock(&ksm_mmlist_lock);
		slot = list_entry(slot->mm_list.next, struct mm_slot, mm_list);
		ksm_scan.mm_slot = slot;
		spin_unlock(&ksm_mmlist_lock);
		/*
		 * Although we tested list_empty() above, a racing __ksm_exit
		 * of the last mm on the list may have removed it since then.
		 */
		if (slot == &ksm_mm_head)
			return NULL;
next_mm:
		ksm_scan.address = 0;
		ksm_scan.rmap_list = &slot->rmap_list;
	}

	mm = slot->mm;
	down_read(&mm->mmap_sem);
	if (ksm_test_exit(mm))
		vma = NULL;
	else
		vma = find_vma(mm, ksm_scan.address);

	for (; vma; vma = vma->vm_next) {
		if (!(vma->vm_flags & VM_MERGEABLE))
			continue;
		if (ksm_scan.address < vma->vm_start)
			ksm_scan.address = vma->vm_start;
		if (!vma->anon_vma)
			ksm_scan.address = vma->vm_end;

		while (ksm_scan.address < vma->vm_end) {
			if (ksm_test_exit(mm))
				break;
			*page = follow_page(vma, ksm_scan.address, FOLL_GET);
			if (IS_ERR_OR_NULL(*page)) {
				ksm_scan.address += PAGE_SIZE;
				cond_resched();
				continue;
			}
			if (PageAnon(*page) ||
			    page_trans_compound_anon(*page)) {
				flush_anon_page(vma, *page, ksm_scan.address);
				flush_dcache_page(*page);
				rmap_item = get_next_rmap_item(slot,
					ksm_scan.rmap_list, ksm_scan.address);
				if (rmap_item) {
					ksm_scan.rmap_list =
							&rmap_item->rmap_list;
					ksm_scan.address += PAGE_SIZE;
				} else
					put_page(*page);
				up_read(&mm->mmap_sem);
				return rmap_item;
			}
			put_page(*page);
			ksm_scan.address += PAGE_SIZE;
			cond_resched();
		}
	}

	if (ksm_test_exit(mm)) {
		ksm_scan.address = 0;
		ksm_scan.rmap_list = &slot->rmap_list;
	}
	/*
	 * Nuke all the rmap_items that are above this current rmap:
	 * because there were no VM_MERGEABLE vmas with such addresses.
	 */
	remove_trailing_rmap_items(slot, ksm_scan.rmap_list);

	spin_lock(&ksm_mmlist_lock);
	ksm_scan.mm_slot = list_entry(slot->mm_list.next,
						struct mm_slot, mm_list);
	if (ksm_scan.address == 0) {
		/*
		 * We've completed a full scan of all vmas, holding mmap_sem
		 * throughout, and found no VM_MERGEABLE: so do the same as
		 * __ksm_exit does to remove this mm from all our lists now.
		 * This applies either when cleaning up after __ksm_exit
		 * (but beware: we can reach here even before __ksm_exit),
		 * or when all VM_MERGEABLE areas have been unmapped (and
		 * mmap_sem then protects against race with MADV_MERGEABLE).
		 */
		hash_del(&slot->link);
		list_del(&slot->mm_list);
		spin_unlock(&ksm_mmlist_lock);

		free_mm_slot(slot);
		clear_bit(MMF_VM_MERGEABLE, &mm->flags);
		up_read(&mm->mmap_sem);
		mmdrop(mm);
	} else {
		spin_unlock(&ksm_mmlist_lock);
		up_read(&mm->mmap_sem);
	}

	/* Repeat until we've completed scanning the whole list */
	slot = ksm_scan.mm_slot;
	if (slot != &ksm_mm_head)
		goto next_mm;

	ksm_scan.seqnr++;
	return NULL;
}
```

第10行代码, ksmmm_head链表为空,则不进行扫描。

第14~64 行代码，ksmd第一次跑的情况，初始化ksm_scan  数据结构中的成员ksm_scan.mm_slot、ksm_scan.address和ksm_scan.rmap_list。

第66~107行代码，扫描当前slot 对应的用户进程中的所有VMAs,寻寻找一个合适的匿名页面。

第73行代码，for循环遍历所有VMA。

第81~107行代码，扫描VMA中所有的虚拟页面，follow_page()函数从虚拟地址开始找回normal mapping页面的struct page数据结构，KSM只会处理匿名页面的情况

第90行代码,使用PageAnon()来判断该,是否为匿名页面。

第92~93行代码，，冲刷该页对应的cache。get_next_rmap_item()去找mm_slot->rmap_list链表上是否有该虚拟地址对应的rmap_item，没找到就新建一个。

第97行代码, ksm_scan.rmap_list指向刚找到或者新建的rmap_item,方便后续的扫描。找到合适的匿名页面后,释放mm->mmapsem信号量,这个信号量是在扫描VMA时加的,然后返回该页struct page数据结构。

第111行代码，运行到这里说明for循环里扫描该进程所有的VMA都没找到合适的匿名页面，，因为如果找到一个合适的匿名页面是会返回rmap_item的。如果被扫描的进程已经被销毁了(mm->mm_users=0)，那么设置ksm_scan.address=0，第124~141行代码会处理这个情况。

第122行代码，在该进程中没找到合适的匿名页面时，那么对应的rmap_item已经没有用处为了避免占用内存空间，直接全部删掉，

第122行代码，取下一个mm_slot, 这里操作了 mm_slot链表，所以用一个spinlock锁ksm_mmlist_lock来保护链表.

第124~141行代码，处理该进程被销毁的情况，把mm_slot从ksm_mm_ head链表删除，释放mm_slot数据结构，清空mm->flags中的MMF_VM_MERGEABLE标志位。

第148~150行代码,如果没有扫描完一轮所有的 mm_slot,那就继续扫描下一个 mm_slot

第152行代码,如果扫描完一轮 mm_slot,则增加 ksm_scan.seqnr计数。

下面回到ksm_do_scan()函数中的cmp_and_merge_page()函数。

```
static void cmp_and_merge_page(struct page *page, struct rmap_item *rmap_item)
{
	struct rmap_item *tree_rmap_item;
	struct page *tree_page = NULL;
	struct stable_node *stable_node;
	struct page *kpage;
	unsigned int checksum;
	int err;

	stable_node = page_stable_node(page);
	if (stable_node) {
		if (stable_node->head != &migrate_nodes &&
		    get_kpfn_nid(stable_node->kpfn) != NUMA(stable_node->nid)) {
			rb_erase(&stable_node->node,
				 root_stable_tree + NUMA(stable_node->nid));
			stable_node->head = &migrate_nodes;
			list_add(&stable_node->list, stable_node->head);
		}
		if (stable_node->head != &migrate_nodes &&
		    rmap_item->head == stable_node)
			return;
	}

	/* We first start with searching the page inside the stable tree */
	kpage = stable_tree_search(page);
	if (kpage == page && rmap_item->head == stable_node) {
		put_page(kpage);
		return;
	}

	remove_rmap_item_from_tree(rmap_item);

	if (kpage) {
		err = try_to_merge_with_ksm_page(rmap_item, page, kpage);
		if (!err) {
			/*
			 * The page was successfully merged:
			 * add its rmap_item to the stable tree.
			 */
			lock_page(kpage);
			stable_tree_append(rmap_item, page_stable_node(kpage));
			unlock_page(kpage);
		}
		put_page(kpage);
		return;
	}

	/*
	 * If the hash value of the page has changed from the last time
	 * we calculated it, this page is changing frequently: therefore we
	 * don't want to insert it in the unstable tree, and we don't want
	 * to waste our time searching for something identical to it there.
	 */
	checksum = calc_checksum(page);
	if (rmap_item->oldchecksum != checksum) {
		rmap_item->oldchecksum = checksum;
		return;
	}

	tree_rmap_item =
		unstable_tree_search_insert(rmap_item, page, &tree_page);
	if (tree_rmap_item) {
		kpage = try_to_merge_two_pages(rmap_item, page,
						tree_rmap_item, tree_page);
		put_page(tree_page);
		if (kpage) {
			/*
			 * The pages were successfully merged: insert new
			 * node in the stable tree and add both rmap_items.
			 */
			lock_page(kpage);
			stable_node = stable_tree_insert(kpage);
			if (stable_node) {
				stable_tree_append(tree_rmap_item, stable_node);
				stable_tree_append(rmap_item, stable_node);
			}
			unlock_page(kpage);

			/*
			 * If we fail to insert the page into the stable tree,
			 * we will have 2 virtual addresses that are pointing
			 * to a ksm page left outside the stable tree,
			 * in which case we need to break_cow on both.
			 */
			if (!stable_node) {
				break_cow(tree_rmap_item);
				break_cow(rmap_item);
			}
		}
	}
}
```

cmp_and_merge_page()函数有两个参数, page表示刚才扫描mmslot时找到的一个合格的匿名页面, rmap_item表示该page对应的rmap_item数据结构。

第10行代码，如果这个页面是stable_node，否则page_stable_node()返回这个page对应的stable_node，否则返回NULL。

第25行代码，stable_tree_search()函数在 stable红黑树中查找页面内容和page相同的stable页。

第26 行代码，如果找到的stable页kpage和的page是同一个页面，说明该页已经是KSM页面，不需要继续处理，直接返回。put_page()减少\_count引用计数，注意page在scanget_next_rmap_item()->follow_ page()时给该页增加了\_count_引用计数。

第33~46行代码,如果在 stable红黑树中找到一个页面内容相同的节点,那么调用try_to_merge_with_ksm_page()来尝试合并这个页面到节点上。合并成功后, stable_tree_append()会把 rmap_Item添加到 stable_node-> hist哈希链表上。

第54-58行代码,若在 stable红黑树中没能找到和page内容相同的节点,则重新计算该页的校验值。如果校验值发生变化,说明该页面的内容被频繁修改,这种页面不适合添加到 unstable红黑树中。

第60行代码，unstable_tree_search_insert()搜索unstable红黑树中是否有利和该页内容相同的节点。

第62~77行代码,若在unstable红黑树中能找到页面内容相同的节点tree_rmap_item和页面tree-page,那么调用try_to_merge_two_pages()去尝试合并该页page和tree_page成为一个KSM页面kpage. stable_tree_insert()会把kpage添加到stable红黑树中,创建一个新的stable节点。stable_tree_append()把tree_rmap_item和rmap_item添加到stable节点的哈希链表中,并更新统计计数ksm_pages_sharing和ksm_pages_shared.

第85~90行代码,如果 stable节点插入到 stable红黑树失败,那么调用 break_cow()主动触发一个缺页中断来分离这个ksm页面。

回到 cmp_and_merge_page()函数,首先来看第12行代码中的 stable_tree_search()函数

```
static struct page *stable_tree_search(struct page *page)
{
	int nid;
	struct rb_root *root;
	struct rb_node **new;
	struct rb_node *parent;
	struct stable_node *stable_node;
	struct stable_node *page_node;

	page_node = page_stable_node(page);
	if (page_node && page_node->head != &migrate_nodes) {
		/* ksm page forked */
		get_page(page);
		return page;
	}

	nid = get_kpfn_nid(page_to_pfn(page));
	root = root_stable_tree + nid;
again:
	new = &root->rb_node;
	parent = NULL;

	while (*new) {
		struct page *tree_page;
		int ret;

		cond_resched();
		stable_node = rb_entry(*new, struct stable_node, node);
		tree_page = get_ksm_page(stable_node, false);
		if (!tree_page)
			return NULL;

		ret = memcmp_pages(page, tree_page);
		put_page(tree_page);

		parent = *new;
		if (ret < 0)
			new = &parent->rb_left;
		else if (ret > 0)
			new = &parent->rb_right;
		else {
			/*
			 * Lock and unlock the stable_node's page (which
			 * might already have been migrated) so that page
			 * migration is sure to notice its raised count.
			 * It would be more elegant to return stable_node
			 * than kpage, but that involves more changes.
			 */
			tree_page = get_ksm_page(stable_node, true);
			if (tree_page) {
				unlock_page(tree_page);
				if (get_kpfn_nid(stable_node->kpfn) !=
						NUMA(stable_node->nid)) {
					put_page(tree_page);
					goto replace;
				}
				return tree_page;
			}
			/*
			 * There is now a place for page_node, but the tree may
			 * have been rebalanced, so re-evaluate parent and new.
			 */
			if (page_node)
				goto again;
			return NULL;
		}
	}

	if (!page_node)
		return NULL;

	list_del(&page_node->list);
	DO_NUMA(page_node->nid = nid);
	rb_link_node(&page_node->node, parent, new);
	rb_insert_color(&page_node->node, root);
	get_page(page);
	return page;

replace:
	if (page_node) {
		list_del(&page_node->list);
		DO_NUMA(page_node->nid = nid);
		rb_replace_node(&stable_node->node, &page_node->node, root);
		get_page(page);
	} else {
		rb_erase(&stable_node->node, root);
		page = NULL;
	}
	stable_node->head = &migrate_nodes;
	list_add(&stable_node->list, stable_node->head);
	return page;
}
```

stable_tree_search()函数会搜索stable红黑树并查找是否有和page页面内容一致的节点。

10-15行，如果page已经是stable_page,那不需要搜索了。

stable_tree_search()函数会搜索stable红黑树并查找是否有和page页面内容一致的节点。

从第18行代码开始搜索stable红黑树, rb-entry()取出一个节点元素stable node, get_ksmpage()函数把对应的stable节点转换为struct page数据结构。stable节点中有一个成员kpfn存放着页帧号,通过页帧号可以求出对应的page数据结构tree_page,注意这个函数会增加该节点tree_page的_count引用计数。

 第33行代码，通过memcmp_pages()来对比page和treepage的内容是否一致。

第34行代码,调用put_page()来减少tree_page的count引用计数,之前get_ksm_page()对该页增加了引用计数。如果不一致,则继续搜索红黑树的叶节点。

第49行代码, page和tree_page内容一致,重新用get_ksm_page()增加tree_page的引用计数,其实是让页面迁移模块(page migration)知道这里在使用这个页面,最后返回tree_page。

stable_tree_search()函数找到页面内容相同的ksm页后,下面来看cmp_and_merge_page()函数第34行代码中的try_to_merge_with_ksm_page()是如何合并page页面到ksm页面的。

```
[ksm_do_scan()->cmp_and_merge_page()->try_to_merge_with_ksm_page()]
static int try_to_merge_with_ksm_page(struct rmap_item *rmap_item,
				      struct page *page, struct page *kpage)
{
	struct mm_struct *mm = rmap_item->mm;
	struct vm_area_struct *vma;
	int err = -EFAULT;

	down_read(&mm->mmap_sem);
	if (ksm_test_exit(mm))
		goto out;
	vma = find_vma(mm, rmap_item->address);
	if (!vma || vma->vm_start > rmap_item->address)
		goto out;

	err = try_to_merge_one_page(vma, page, kpage);
	if (err)
		goto out;

	/* Unstable nid is in union with stable anon_vma: remove first */
	remove_rmap_item_from_tree(rmap_item);

	/* Must get reference to anon_vma while still holding mmap_sem */
	rmap_item->anon_vma = vma->anon_vma;
	get_anon_vma(vma->anon_vma);
out:
	up_read(&mm->mmap_sem);
	return err;
}

```

try_to_merge_with_ksm_page()函数中参数page是候选页，rmap_item是候选页对应的rmap_item结构，kpage 是stable树中的KSM页面，尝试把候选页page 1是合并到kpage中。
第9行代码，接下来需要操作VMA，因此加一个mm->mmap_sem读者锁。
第12行代码，根据虚拟地址来找到对应的VMA。
第 146行代码，调用try_to_merge_one_page()，尝试合并page到kpage中。
第24 行代码，，rmap_item->anon_vma指向VMA对应的 anon_vma数据结构。

第25行代码，增加anon_vma->refcount的引用计数， 防止anon_vma被释放。
第27行代码，释放mm->mmap_sem的读者锁。
接下来看try_to_merge_one_page()函数的实现。

```
[ksm_do_scan()->cmp_and_merge_page()->try_to_merge_with_ksm_page()->try_to_merge_one_page()]
static int try_to_merge_one_page(struct vm_area_struct *vma,
				 struct page *page, struct page *kpage)
{
	pte_t orig_pte = __pte(0);
	int err = -EFAULT;

	if (page == kpage)			/* ksm page forked */
		return 0;

	if (!(vma->vm_flags & VM_MERGEABLE))
		goto out;
	if (PageTransCompound(page) && page_trans_compound_anon_split(page))
		goto out;
	BUG_ON(PageTransCompound(page));
	if (!PageAnon(page))
		goto out;

	/*
	 * We need the page lock to read a stable PageSwapCache in
	 * write_protect_page().  We use trylock_page() instead of
	 * lock_page() because we don't want to wait here - we
	 * prefer to continue scanning and merging different pages,
	 * then come back to this page when it is unlocked.
	 */
	if (!trylock_page(page))
		goto out;
	/*
	 * If this anonymous page is mapped only here, its pte may need
	 * to be write-protected.  If it's mapped elsewhere, all of its
	 * ptes are necessarily already write-protected.  But in either
	 * case, we need to lock and check page_count is not raised.
	 */
	if (write_protect_page(vma, page, &orig_pte) == 0) {
		if (!kpage) {
			/*
			 * While we hold page lock, upgrade page from
			 * PageAnon+anon_vma to PageKsm+NULL stable_node:
			 * stable_tree_insert() will update stable_node.
			 */
			set_page_stable_node(page, NULL);
			mark_page_accessed(page);
			err = 0;
		} else if (pages_identical(page, kpage))
			err = replace_page(vma, page, kpage, orig_pte);
	}

	if ((vma->vm_flags & VM_LOCKED) && kpage && !err) {
		munlock_vma_page(page);
		if (!PageMlocked(kpage)) {
			unlock_page(page);
			lock_page(kpage);
			mlock_vma_page(kpage);
			page = kpage;		/* for final unlock */
		}
	}

	unlock_page(page);
out:
	return err;
}
```

​	try_to_merge_one_page()函数尝试合并page和kpage

​	第8行代码, page和kpage是同一个page

​	第11行代码, page对应的VMA属性是不可合并的,即没有包含VM_MERGEABLE标志位。
​    第16行代码,剔除不是匿名页面的部分。
​    第26行代码,这里为什么要使用trylock_page(page),而不使用lock page(page)呢?我们需要申请该页的页面锁以方便在稍后的write_protect_page()中读取稳定的PageSwapCache的状态,并且不需要在这里睡眠等待该页的页锁。如果该页被其他人加锁了,我们可以略过它,先处理其他页面。
​    第34行代码, write_protect page)对该页映射VMA的pte进行写保护操作。
​    第35~44行代码,在与unstable树节点合并时,参数kpage有可能传过来NULL,这主要是设置page为stable节点,并且设置该页的活动情况(mark page accessed)。
​    第44~46行代码, pages_identical()再一次比较page和kpage内容是否一致。如果一致,则调用replace_page()),把该page对应的pte设置对应的kpage中。

下面来看write_protect_page()函数的实现。

```
[ksm_do_scan()->cmp_and_merge_page()->try_to_merge_with_ksm_page()->try_to_merge_one_page()->write_protect_page()]
static int write_protect_page(struct vm_area_struct *vma, struct page *page,
			      pte_t *orig_pte)
{
	struct mm_struct *mm = vma->vm_mm;
	unsigned long addr;
	pte_t *ptep;
	spinlock_t *ptl;
	int swapped;
	int err = -EFAULT;
	unsigned long mmun_start;	/* For mmu_notifiers */
	unsigned long mmun_end;		/* For mmu_notifiers */

	addr = page_address_in_vma(page, vma);
	if (addr == -EFAULT)
		goto out;

	BUG_ON(PageTransCompound(page));

	mmun_start = addr;
	mmun_end   = addr + PAGE_SIZE;
	mmu_notifier_invalidate_range_start(mm, mmun_start, mmun_end);

	ptep = page_check_address(page, mm, addr, &ptl, 0);
	if (!ptep)
		goto out_mn;

	if (pte_write(*ptep) || pte_dirty(*ptep)) {
		pte_t entry;

		swapped = PageSwapCache(page);
		flush_cache_page(vma, addr, page_to_pfn(page));
		/*
		 * Ok this is tricky, when get_user_pages_fast() run it doesn't
		 * take any lock, therefore the check that we are going to make
		 * with the pagecount against the mapcount is racey and
		 * O_DIRECT can happen right after the check.
		 * So we clear the pte and flush the tlb before the check
		 * this assure us that no O_DIRECT can happen after the check
		 * or in the middle of the check.
		 */
		entry = ptep_clear_flush_notify(vma, addr, ptep);
		/*
		 * Check that no O_DIRECT or similar I/O is in progress on the
		 * page
		 */
		if (page_mapcount(page) + 1 + swapped != page_count(page)) {
			set_pte_at(mm, addr, ptep, entry);
			goto out_unlock;
		}
		if (pte_dirty(entry))
			set_page_dirty(page);
		entry = pte_mkclean(pte_wrprotect(entry));
		set_pte_at_notify(mm, addr, ptep, entry);
	}
	*orig_pte = *ptep;
	err = 0;

out_unlock:
	pte_unmap_unlock(ptep, ptl);
out_mn:
	mmu_notifier_invalidate_range_end(mm, mmun_start, mmun_end);
out:
	return err;
}
```

第14 行代码，通过VMA和page数据结构可以计算出page对应的虚拟地址address。

第24行代码, 由mm和虚拟地址address通过查询页表找到该地址对应的pte页表项。

第 28~55 行代码，因为该函数的作用是设置pte为写保护，因此对应pte页表项的属性是可写或者脏页面需要设置pte为写保护(对ARM处理器设置页表项的L_PTE_RDONLY比特位，对 x86处理器清_PAGE_BIT_RW 比特位)，)脏页面通过set_page_dirty()函数来调用该页的mapping>a_ops->set_page_dirty()函数并通知回写系统。第32行代码，刷新这个页面对应的cache。

第42 行代码，ptep_clear_flush_notify()清空pte 页表项内容并冲刷相应的 TLB，保证没有DIRECT_IO发生，函数返回该pte原来的内容。

第52-52行代码，新生成一个个具有只读属性的 PTE entry，并设置到硬件页面中。

为什么第26行代码中要有这样一个判断公式呢?(page_mapcount(page)+1+ swapped != page_count(page))。
    这是一个需要深入理解内存管理代码才能明确的问题，涉及到page的_count和_mapcount两个引用计数的巧妙运用。write_protect_ page()函数本身的目的是让页面变成只读，后续就可以做比较和合并的工作了。要把一个页面变成只读需要满足如下两个条件。

-   确认没有其他人获取了该页面。
-   将指向该页面的pte变成只读属性。

第二个条件容易处理,难点在第一个条件上。一般来说, page的_count计数有如下4种来源。

-   page cache在radix tree上, KSM不考虑page cache情况。
-   被用户态的pte引用, _count和mapcount都会增加计数。
-   page->private私用数据也会增加count计数,对于匿名页面,需要判断是否在swap cache中, 例如add_to_swap()函数。
-   内核中某些页面操作时会增加count计数,例如follow_page(), get_user_pages_fast()等。

假设没有其他内核路径操作该页面,并且该页面不在 swap cache中,两个引用计数的关系为:

```
(page->_mapcount + 1) = page->_ count
```

但是上述公式也有例外，例如该页面发生DIRECT_IO读写的情况，调用关系如下。

```
generic_file_direct_write()
->mapping->a_ops->direct_IO()
->ext4_direct_IO()
->__blockdev_direct_IO()
->do_blockdev_direct_IO()
->do_direct_IO()
->dio_get_page()
->dio_refill_pages()
->iov_iter_get_pages()
->get_user_pages_fast()

```

最后调用 get＿user＿pages＿fast()函数来分配内存，它会让page-＞＿count 引用计数加1，因此在没有DIRECT＿IO读写的情况下，上述公式变为：

```
(page->_mapcount +1)+1+PageSwapCache()==page->_count
```

因此第26行代码判断不相等,说明有内核代码路径(例如 DIRECT_IO读写)正在操作该页面,那么 write_ protect page()函数只能返回错误。

下面来看 replace_page()函数的实现。

```
[ksm_do_scan()->cmp_and_merge_page()->try_to_merge_with_ksm_page()->try_to_merge_one_page()->replace_page()]
static int replace_page(struct vm_area_struct *vma, struct page *page,
			struct page *kpage, pte_t orig_pte)
{
	struct mm_struct *mm = vma->vm_mm;
	pmd_t *pmd;
	pte_t *ptep;
	spinlock_t *ptl;
	unsigned long addr;
	int err = -EFAULT;
	unsigned long mmun_start;	/* For mmu_notifiers */
	unsigned long mmun_end;		/* For mmu_notifiers */

	addr = page_address_in_vma(page, vma);
	if (addr == -EFAULT)
		goto out;

	pmd = mm_find_pmd(mm, addr);
	if (!pmd)
		goto out;

	mmun_start = addr;
	mmun_end   = addr + PAGE_SIZE;
	mmu_notifier_invalidate_range_start(mm, mmun_start, mmun_end);

	ptep = pte_offset_map_lock(mm, pmd, addr, &ptl);
	if (!pte_same(*ptep, orig_pte)) {
		pte_unmap_unlock(ptep, ptl);
		goto out_mn;
	}

	get_page(kpage);
	page_add_anon_rmap(kpage, vma, addr);

	flush_cache_page(vma, addr, pte_pfn(*ptep));
	ptep_clear_flush_notify(vma, addr, ptep);
	set_pte_at_notify(mm, addr, ptep, mk_pte(kpage, vma->vm_page_prot));

	page_remove_rmap(page);
	if (!page_mapped(page))
		try_to_free_swap(page);
	put_page(page);

	pte_unmap_unlock(ptep, ptl);
	err = 0;
out_mn:
	mmu_notifier_invalidate_range_end(mm, mmun_start, mmun_end);
out:
	return err;
}
```

replace_page()函数的参数,其中page是旧的page, page是 stable树中找到的KSM页面, onig_pte用于判断在这期间page是否被修改了。简单来说就是使用 page的pfn加上原来page的一些属性构成一个新的pte页表项,然后写入到原来page的pte页表项中,这样原来的page页对应的VMA用户地址空间就和 page建立了映射关系。

第32行代码,给 page增加在_count引用计数。

第33行代码,看起来page_add_anon_rmap()是要把 page添加到RMAP系统中,因为kpage早已经添加到RMAP系统中,所以这里只是增加 mapcount计数。

第35~37行代码,冲刷addr和pte对应的 cache,然后清空pte的内容和对应的TLB后,写入新的pte内容。

回到cmp_and_merge_page()函数中, try_to_merge_with_ksm_page把page合并到kpage页面后,需要做一些统计相关工作,下面来看stable_tree_append函数。

```
static void stable_tree_append(struct rmap_item *rmap_item,
			       struct stable_node *stable_node)
{
	rmap_item->head = stable_node;
	rmap_item->address |= STABLE_FLAG;
	hlist_add_head(&rmap_item->hlist, &stable_node->hlist);

	if (rmap_item->hlist.next)
		ksm_pages_sharing++;
	else
		ksm_pages_shared++;
}
```

rmap_item是page页面对应的rmap_item数据结构, struct stable_node是KSM页面的mapping指向的数据结构,类似匿名页面中的anon_vma数据结构。参数中的stable_node是kpage指向的struct stable_node数据结构。

```
static inline void *page_rmapping(struct page *page)
{
	return (void *)((unsigned long)page->mapping & ~PAGE_MAPPING_FLAGS);
}
```

stable_tree_append()把rmap_item添加到kpage页面的stable_node中的哈希链表里,如果有多个页面同时映射到stable_node上,则增加ksm_pages_sharing计数,否则增加ksm_pages_shared计数,说明这是一个新成立的stable节点。ksm_pages_shared计数表示系统中有多个ksm节点, ksm_pages_sharing计数表示合并到ksm节点中的页面个数。

page页合并到 page页面后,退出 cmp_and_merge_page()便开始扫描下一个目标页面了。注意这里 cmp_and_merge_page()函数第27行代码中的 put_page(page)和 ksm_do_scan()函数以及第11行代码中的 put_page(page),大家需要想明白它们在何处增加了page的计数。

上面是在stable树中找到和候选者页面内容相同的情况。假设在stable树中没有找到合适页面,那么接下来会去查找unstable树。

```
[ksm_do_scan()->cmp_and_merge_page()->unstable_tree_search_insert()]
static
struct rmap_item *unstable_tree_search_insert(struct rmap_item *rmap_item,
					      struct page *page,
					      struct page **tree_pagep)
{
	struct rb_node **new;
	struct rb_root *root;
	struct rb_node *parent = NULL;
	int nid;

	nid = get_kpfn_nid(page_to_pfn(page));
	root = root_unstable_tree + nid;
	new = &root->rb_node;

	while (*new) {
		struct rmap_item *tree_rmap_item;
		struct page *tree_page;
		int ret;

		cond_resched();
		tree_rmap_item = rb_entry(*new, struct rmap_item, node);
		tree_page = get_mergeable_page(tree_rmap_item);
		if (IS_ERR_OR_NULL(tree_page))
			return NULL;

		/*
		 * Don't substitute a ksm page for a forked page.
		 */
		if (page == tree_page) {
			put_page(tree_page);
			return NULL;
		}

		ret = memcmp_pages(page, tree_page);

		parent = *new;
		if (ret < 0) {
			put_page(tree_page);
			new = &parent->rb_left;
		} else if (ret > 0) {
			put_page(tree_page);
			new = &parent->rb_right;
		} else if (!ksm_merge_across_nodes &&
			   page_to_nid(tree_page) != nid) {
			/*
			 * If tree_page has been migrated to another NUMA node,
			 * it will be flushed out and put in the right unstable
			 * tree next time: only merge with it when across_nodes.
			 */
			put_page(tree_page);
			return NULL;
		} else {
			*tree_pagep = tree_page;
			return tree_rmap_item;
		}
	}

	rmap_item->address |= UNSTABLE_FLAG;
	rmap_item->address |= (ksm_scan.seqnr & SEQNR_MASK);
	DO_NUMA(rmap_item->nid = nid);
	rb_link_node(&rmap_item->node, parent, new);
	rb_insert_color(&rmap_item->node, root);

	ksm_pages_unshared++;
	return NULL;
}
```

unstable_tree_search_insert()函数与stable_tree_search()的逻辑类似。查找unstable红黑树,这棵树的根在root_unstable_tree, get_mergeable_page()判断从树中取出来的页面是否合格,只有匿名页面才可以被合并。如果在树中没找到和候选页面相同的内容,那么会把候选页面也添加到该树中,见第59~63行代码。 rmap item-> address的低12比特位用于存放些标志位,例如 UNSTABLE_FLAG(0x100)表示 rmap_Item在 unstable树中,另外低8位用于存放全盘扫描的次数 seqnr 。unstable树的节点会在一次全盘扫描后被删掉,在下次全盘扫描重新加入到 unstable树中。 ksm_pages_unshared表示有在 unstable树中的节点个数。

当在 unstable树中找到和候选页面page内容相同的 tree page后,尝试把该page和tree_page合并成一个KSM页面。下面来看 try_to_merge_two_pages()函数的实现。

```
[ksm_do_scan()->cmp_and_merge_page()->try_to_merge_two_pages()]
static struct page *try_to_merge_two_pages(struct rmap_item *rmap_item,
					   struct page *page,
					   struct rmap_item *tree_rmap_item,
					   struct page *tree_page)
{
	int err;

	err = try_to_merge_with_ksm_page(rmap_item, page, NULL);
	if (!err) {
		err = try_to_merge_with_ksm_page(tree_rmap_item,
							tree_page, page);
		/*
		 * If that fails, we have a ksm page with only one pte
		 * pointing to it: so break it.
		 */
		if (err)
			break_cow(rmap_item);
	}
	return err ? NULL : page;
}
```

 这里调用了两次 try_to_merge_with_ksm_page(),注意这两次调用的参数不一样,实现的功能也不一样。

 第一次,参数是候选者page和对应的 rmap_item, page为NULL,因此第一次调用主要是把page的页表设置为写保护,并且把该页设置为KSM节点

第二次,参数变成了 tree_page和对应的 tree_rmap_item, page为候选者page,因此这里要实现的功能是把 tree_page的页表设置为写保护,然后再比较 tree_page和page之间的内容是否一致。在查找 unstable树时已经做过页面内容的比较,为什么这里还需要再比较一次呢?因为在这个过程中,页面有可能被别的进程修改了内容。当两个页面内容确保一致后,借用page的pfn来重新生成一个页表项并设置到 tree page的页表中,也就是tree_page对应的进程虚拟地址和物理页面page重新建立了映射关系, tree_page和page合并成了一个KSM页面,page作为KSM页面的联络点。

回到 cmp_and_merge_page()函数中,当候选者page荣升为KSM页面 page后, stable_tree_insert()会把KSM页 page添加到 stable树中。
