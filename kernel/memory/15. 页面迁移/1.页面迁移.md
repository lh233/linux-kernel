Linux为页面迁移提供了一个系统调用migrate_pages，最早是在Linux2.6.16版本加入的，它可以迁移一个进程的所有页面到指定内存节点上。该系统调用在用户空间的函数接口如下：

```
#include <numaif.h>
long migrate_page(struct address_space *,
			struct page *, struct page *, enum migrate_mode);
```

该系统调用最早是为了在NUMA系统上提供一种能迁移进程到任意内存节点的能力。现在内核除了为NUMA系统提供页迁移能力外，其他的一些模块也可以利用页迁移功能做一些事情，例如内存规整和内存热插拔等。

**migrate_pages()函数**

```
//migrate_pages()函数的参数from表示将要迁移的页面链表，get_new_page是内存函数指针，put_new_page是迁移失败时释放目标页面的函数指针，private 是传递给get_new_page的参数，mode是迁移模式，reason表示迁移原因。
int migrate_pages(struct list_head *from, new_page_t get_new_page,
		free_page_t put_new_page, unsigned long private,
		enum migrate_mode mode, int reason)
{
	int retry = 1;
	int nr_failed = 0;
	int nr_succeeded = 0;
	int pass = 0;
	struct page *page;
	struct page *page2;
	int swapwrite = current->flags & PF_SWAPWRITE;
	int rc;

	if (!swapwrite)
		current->flags |= PF_SWAPWRITE;
	
	//for循环表示这里会尝试10次，从from链表摘取一个页面，然后调用unmap_and_move()函数进行页的迁移，返回MIGRATEPAGE_SUCCESS表示页迁移成功
	for(pass = 0; pass < 10 && retry; pass++) {
		retry = 0;

		list_for_each_entry_safe(page, page2, from, lru) {
			cond_resched();

			if (PageHuge(page))
				rc = unmap_and_move_huge_page(get_new_page,
						put_new_page, private, page,
						pass > 2, mode);
			else
				rc = unmap_and_move(get_new_page, put_new_page,
						private, page, pass > 2, mode);

			switch(rc) {
			case -ENOMEM:
				goto out;
			case -EAGAIN:
				retry++;
				break;
			case MIGRATEPAGE_SUCCESS:
				nr_succeeded++;
				break;
			default:
				/*
				 * Permanent failure (-EBUSY, -ENOSYS, etc.):
				 * unlike -EAGAIN case, the failed page is
				 * removed from migration page list and not
				 * retried in the next outer loop.
				 */
				nr_failed++;
				break;
			}
		}
	}
	rc = nr_failed + retry;
out:
	if (nr_succeeded)
		count_vm_events(PGMIGRATE_SUCCESS, nr_succeeded);
	if (nr_failed)
		count_vm_events(PGMIGRATE_FAIL, nr_failed);
	trace_mm_migrate_pages(nr_succeeded, nr_failed, mode, reason);

	if (!swapwrite)
		current->flags &= ~PF_SWAPWRITE;

	return rc;
}
```



```
[migrate_pages()->unmap_and_move()]
static int unmap_and_move(new_page_t get_new_page, free_page_t put_new_page,
			unsigned long private, struct page *page, int force,
			enum migrate_mode mode)
{
	int rc = 0;
	int *result = NULL;
	
	//调用get_new_page()分配一个新的页面newpage，接下来调用__unmap_and_move()去尝试迁移页面page到新分配的页面newpage中。
	struct page *newpage = get_new_page(page, private, &result);

	if (!newpage)
		return -ENOMEM;

	if (page_count(page) == 1) {
		/* page was freed from under us. So we are done. */
		goto out;
	}

	if (unlikely(PageTransHuge(page)))
		if (unlikely(split_huge_page(page)))
			goto out;

	rc = __unmap_and_move(page, newpage, force, mode);

out:
	//返回-EAGAIN表示页迁移失败，会把这个页面重新放回LRU链表中。如果页迁移不成功，那么会把新分配的页面释放。
	if (rc != -EAGAIN) {
		/*
		 * A page that has been migrated has all references
		 * removed and will be freed. A page that has not been
		 * migrated will have kepts its references and be
		 * restored.
		 */
		list_del(&page->lru);
		dec_zone_page_state(page, NR_ISOLATED_ANON +
				page_is_file_cache(page));
		putback_lru_page(page);
	}

	/*
	 * If migration was not successful and there's a freeing callback, use
	 * it.  Otherwise, putback_lru_page() will drop the reference grabbed
	 * during isolation.
	 */
	if (rc != MIGRATEPAGE_SUCCESS && put_new_page) {
		ClearPageSwapBacked(newpage);
		put_new_page(newpage, private);
	} else if (unlikely(__is_movable_balloon_page(newpage))) {
		/* drop our reference, page already in the balloon */
		put_page(newpage);
	} else
		//表示迁移成功，新分配的页也会加入到LRU链表中
		putback_lru_page(newpage);

	if (result) {
		if (rc)
			*result = rc;
		else
			*result = page_to_nid(newpage);
	}
	return rc;
}
```

具体实现页的迁移是在__unmap_and_move()函数中，返回MIGRATEPAGE_SUCCESS表示迁移成功。

```
[migrate_pages()->unmap_and_move()->_unmap_and_move()]

static int __unmap_and_move(struct page *page, struct page *newpage,
				int force, enum migrate_mode mode)
{
	int rc = -EAGAIN;
	int page_was_mapped = 0;
	struct anon_vma *anon_vma = NULL;

	//trylock_page()尝试给page加锁，trylock_page()返回false，表示已经有别的进程给page加过锁，返回true表示当前进程可以成功获取锁。
	//如果尝试获取页面锁不成功，当前不是强制迁移（force=0）或迁移模式等于异步（mode=MIGRATE_ASYNC),会直接忽略这个page，因为这种情况下没有必要睡眠等待页面释放页锁。
	//如果当前进程设置了PF_MEMALLOC标志位，表示可能是在直接内存压缩（direct compaction)的内核路径上，睡眠等待页面锁是不安全的，所以直接忽略page。举个例子，在文件预读中，预读的所有页面都会加页锁（PG_lock)并添加到LRU链表中，等到预读完成后，这些页面会标记PG_uptodate并释放页锁，这个过程中块设备层会把多个页面合并到一个BIO中（mpage_readpages（))。如果在分配第2或者第3个页面时发生内存短缺，内核会运行到直接内存压缩（direct compaction)内核路径上，导致一个页面已经加锁了又去等待这个锁，产生死锁，因此在直接内存压缩（direct compaction)的内核路径会标记PF_MEMALLOC。
    //PF_MEMALLOC标志位一般是在直径内存压缩、直接内存回收和kswapd中设置，这些场景下也可能会有少量的内存分配行为，因此设置PF_MEMALLOC标志位，表示允许它们使用系统预留的内存，即不用考虑Water Mark水位。可以参见perform_reclaim)、alloc pages direct_compact()和kswapd)等函数。
    //除了上述情况，其余情况只能调用lock_page()函数来等待页面锁被释放可以体会到trylock_page()和lock_page()这两个函数的区别。
	if (!trylock_page(page)) {
		if (!force || mode == MIGRATE_ASYNC)
			goto out;

		/*
		 * It's not safe for direct compaction to call lock_page.
		 * For example, during page readahead pages are added locked
		 * to the LRU. Later, when the IO completes the pages are
		 * marked uptodate and unlocked. However, the queueing
		 * could be merging multiple pages for one bio (e.g.
		 * mpage_readpages). If an allocation happens for the
		 * second or third page, the process can end up locking
		 * the same page twice and deadlocking. Rather than
		 * trying to be clever about what pages can be locked,
		 * avoid the use of lock_page for direct compaction
		 * altogether.
		 */
		if (current->flags & PF_MEMALLOC)
			goto out;

		lock_page(page);
	}

	//处理正在回写的页面即PG_writeback标志位的页面，这里只有当页面迁移的模式为MIGRATE_SYNC且设置强制迁移(force = 1)时才会去等待这个页面回写完成，否则直接忽略该页面。wait_on_page_writeback()会等待页面回写完成。
	if (PageWriteback(page)) {
		/*
		 * Only in the case of a full synchronous migration is it
		 * necessary to wait for PageWriteback. In the async case,
		 * the retry loop is too short and in the sync-light case,
		 * the overhead of stalling is too much
		 */
		if (mode != MIGRATE_SYNC) {
			rc = -EBUSY;
			goto out_unlock;
		}
		if (!force)
			goto out_unlock;
		wait_on_page_writeback(page);
	}
	/*
	 * By try_to_unmap(), page->mapcount goes down to 0 here. In this case,
	 * we cannot notice that anon_vma is freed while we migrates a page.
	 * This get_anon_vma() delays freeing anon_vma pointer until the end
	 * of migration. File cache pages are no problem because of page_lock()
	 * File Caches may use write_page() or lock_page() in migration, then,
	 * just care Anon page here.
	 */
	 //处理匿名页面的anon_vma可能被释放的特殊情况，因为接下来try_to_unmap()函数执行完成时，
	if (PageAnon(page) && !PageKsm(page)) {
		/*
		 * Only page_lock_anon_vma_read() understands the subtleties of
		 * getting a hold on an anon_vma from outside one of its mms.
		 */
		anon_vma = page_get_anon_vma(page);
		if (anon_vma) {
			/*
			 * Anon page
			 */
		} else if (PageSwapCache(page)) {
			/*
			 * We cannot be sure that the anon_vma of an unmapped
			 * swapcache page is safe to use because we don't
			 * know in advance if the VMA that this page belonged
			 * to still exists. If the VMA and others sharing the
			 * data have been freed, then the anon_vma could
			 * already be invalid.
			 *
			 * To avoid this possibility, swapcache pages get
			 * migrated but are not remapped when migration
			 * completes
			 */
		} else {
			goto out_unlock;
		}
	}

	if (unlikely(isolated_balloon_page(page))) {
		/*
		 * A ballooned page does not need any special attention from
		 * physical to virtual reverse mapping procedures.
		 * Skip any attempt to unmap PTEs or to remap swap cache,
		 * in order to avoid burning cycles at rmap level, and perform
		 * the page migration right away (proteced by page lock).
		 */
		rc = balloon_page_migrate(newpage, page, mode);
		goto out_unlock;
	}

	/*
	 * Corner case handling:
	 * 1. When a new swap-cache page is read into, it is added to the LRU
	 * and treated as swapcache but it has no rmap yet.
	 * Calling try_to_unmap() against a page->mapping==NULL page will
	 * trigger a BUG.  So handle it here.
	 * 2. An orphaned page (see truncate_complete_page) might have
	 * fs-private metadata. The page can be picked up due to memory
	 * offlining.  Everywhere else except page reclaim, the page is
	 * invisible to the vm, so the page can not be migrated.  So try to
	 * free the metadata, so the page can be freed.
	 */
	if (!page->mapping) {
		VM_BUG_ON_PAGE(PageAnon(page), page);
		if (page_has_private(page)) {
			try_to_free_buffers(page);
			goto out_unlock;
		}
		goto skip_unmap;
	}

	/* Establish migration ptes or remove ptes */
	if (page_mapped(page)) {
		try_to_unmap(page,
			TTU_MIGRATION|TTU_IGNORE_MLOCK|TTU_IGNORE_ACCESS);
		page_was_mapped = 1;
	}

skip_unmap:
	if (!page_mapped(page))
		rc = move_to_new_page(newpage, page, page_was_mapped, mode);

	if (rc && page_was_mapped)
		remove_migration_ptes(page, page);

	/* Drop an anon_vma reference if we took one */
	if (anon_vma)
		put_anon_vma(anon_vma);

out_unlock:
	unlock_page(page);
out:
	return rc;
}
```

在migrate_page()中，当尝试次数大于2时，会设置force=1；

